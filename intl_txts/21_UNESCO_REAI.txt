Recommendation on  
the Ethics 
of Artificial 
Intelligence
Adopted on 23 November 2021Published in 2022 by the United Nations Educational, Scientific and Cultural Organization,  
7, place de Fontenoy, 75352 Paris 07 SP, France
 
© UNESCO 2022
SHS/BIO/PI/2021/1
 
All rights reserved.
This publication is available in Open Access under the Attribution-NonCommercial-
ShareAlike 3.0 IGO (CC-BY-NC-SA 3.0 IGO) license (http://creativecommons.org/licenses/
by-nc-sa/3.0/igo/). By using the content of this publication, the users accept to be bound 
by the terms of use of the UNESCO Open Access Repository (www.unesco.org/open-
access/terms-use-ccbyncsa-en).
Cover photo:  
Irina Bg/Shutterstock.com; Artistdesign29/Shutterstock.com; kynny/gettyimages; 
gorodenkoffy/gettyimages; Gorodenkoff/Shutterstock.com; dieddin/Shutterstock.com; 
Gorodenkoff/Shutterstock.com; PopTika/Shutterstock.com; Horth Rasur/Shutterstock.com.
Inside photo:  
p.8: ESB Professional/Shutterstock.com 
p.11: Ruslana Iurchenko/Shutterstock.com 
p.12: metamorworks/Shutterstock.com 
p.14/15: Alexander Supertramp/Shutterstock.com 
p.16: Wazzkii/Shutterstock.com 
p.19: Mukesh Kumar Jwala/Shutterstock.com 
p.21: supparsorn/Shutterstock.com 
p.24: everything possible/Shutterstock.com 
p.29: Gorodenkoff/Shutterstock.com 
p.31: only_kim/Shutterstock.com 
p.33: SeventyFour/Shutterstock.com 
p.34: ESB Professional/Shutterstock.com 
p.36: KlingSup/Shutterstock.com 
p.38: Miriam Doerr Martin Frommherz/Shutterstock.com
Graphic design: Aurélia Mazoyer
 
Printed by UNESCO
 
Printed in France Recommendation o n
 the Ethics
 of Artificial
Intelligence
Adopted on 23 November 2021Table of contents
Preamble   5
I.  Scope of  application  9
II.  Aims and objectives  13
III.  Values and principles  17
III.1  VALUES  18
III.2  PRINCIPLES  20
IV.  Areas of policy action   25
POLICY AREA 1: ETHICAL IMPACT ASSESSMENT  26
POLICY AREA 2: ETHICAL GOVERNANCE AND STEWARDSHIP  27
POLICY AREA 3: DATA POLICY  29
POLICY AREA 4: DEVELOPMENT AND INTERNATIONAL COOPERATION  30
POLICY AREA 5: ENVIRONMENT AND ECOSYSTEMS  30
POLICY AREA 6: GENDER  32
POLICY AREA 7: CULTURE  32
POLICY AREA 8: EDUCATION AND RESEARCH  33
POLICY AREA 9: COMMUNICATION AND INFORMATION   35
POLICY AREA 10: ECONOMY AND LABOUR   36
POLICY AREA 11: HEALTH AND SOCIAL WELL-BEING  37
V.  Monitoring and evaluation  39
VI.  Utilization and exploitation of the present Recommendation  41
VII.  Promotion of the present Recommendation  42
VIII. Final provisions  43
3Preamble 
The General Conference of the United Nations Educational,  Also  recognizing  that  AI  technologies  can  deepen 
Scientific and Cultural Organization (UNESCO), meeting in  existing divides and inequalities in the world, within and 
Paris from 9 to 24 November 2021, at its 41st session,  between countries, and that justice, trust and fairness must be 
upheld so that no country and no one should be left behind, 
Recognizing  the  profound  and  dynamic  positive  and 
either by having fair access to AI technologies and enjoying 
negative impacts of artificial intelligence (AI) on societies, 
their  benefits  or  in  the  protection  against  their  negative 
environment,  ecosystems  and  human  lives,  including  the 
implications, while recognizing the different circumstances of 
human mind, in part because of the new ways in which its use 
different countries and respecting the desire of some people 
influences human thinking, interaction and decision-making 
not to take part in all technological developments,
and affects education, human, social and natural sciences, 
culture, and communication and information, Conscious of the fact that all countries are facing an 
acceleration in the use of information and communication 
Recalling that, by the terms of its Constitution, UNESCO 
technologies and AI technologies, as well as an increasing 
seeks to contribute to peace and security by promoting 
need  for  media  and  information  literacy,  and  that  the 
collaboration among nations through education, the sciences, 
digital economy presents important societal, economic and 
culture, and communication and information, in order to 
environmental  challenges  and  opportunities  of  benefit-
further universal respect for justice, for the rule of law and 
sharing,  especially  for  low-  and  middle-income  countries 
for the human rights and fundamental freedoms which are 
(LMICs), including but not limited to least developed countries 
affirmed for the peoples of the world,
(LDCs), landlocked developing countries (LLDCs) and small 
Convinced that the Recommendation presented here, as  island developing States (SIDS), requiring the recognition, 
protection and promotion of endogenous cultures, values and 
a standard-setting instrument developed through a global 
knowledge in order to develop sustainable digital economies,
approach, based on international law, focusing on human 
dignity and human rights, as well as gender equality, social  Further  recognizing  that  AI  technologies  have  the 
and economic justice and development, physical and mental 
potential to be beneficial to the environment and ecosystems, 
well-being,  diversity,  interconnectedness,  inclusiveness, 
and in order for those benefits to be realized, potential harms 
and environmental and ecosystem protection can guide AI 
to and negative impacts on the environment and ecosystems 
technologies in a responsible direction,
should not be ignored but instead addressed,
Guided by the purposes and principles of the Charter of the  Noting that addressing risks and ethical concerns should not 
United Nations, 
hamper innovation and development but rather provide new 
Considering that AI technologies can be of great service  opportunities and stimulate ethically-conducted research and 
innovation that anchor AI technologies in human rights and 
to humanity and all countries can benefit from them, but also 
fundamental freedoms, values and principles, and moral and 
raise fundamental ethical concerns, for instance regarding 
ethical reflection,
the  biases  they  can  embed  and  exacerbate,  potentially 
resulting in discrimination, inequality, digital divides, exclusion  Also  recalling  that  in  November  2019,  the  General 
and a threat to cultural, social and biological diversity and 
Conference of UNESCO, at its 40th session, adopted 40 C/
social or economic divides; the need for transparency and 
Resolution 37, by which it mandated the Director-General 
understandability of the workings of algorithms and the data 
“to  prepare  an  international  standard-setting  instrument 
with which they have been trained; and their potential impact 
on the ethics of artificial intelligence (AI) in the form of a 
on, including but not limited to, human dignity, human rights 
recommendation”, which is to be submitted to the General 
and  fundamental  freedoms,  gender  equality,  democracy, 
Conference at its 41st session in 2021,
social, economic, political and cultural processes, scientific and 
engineering practices, animal welfare, and the environment  Recognizing that the development of AI technologies 
and ecosystems, necessitates a commensurate increase in data, media and 
information  literacy  as  well  as  access  to  independent, 
5pluralistic, trusted sources of information, including as part of  of  Indigenous  Peoples  (2007);  the  United  Nations  General 
efforts to mitigate risks of misinformation, disinformation and  Assembly resolution on the review of the World Summit on the 
hate speech, and harm caused through the misuse of personal  Information Society (A/RES/70/125) (2015); the United Nations 
data, General  Assembly  Resolution  on  Transforming  our  world: 
the 2030 Agenda for Sustainable Development (A/RES/70/1) 
Observing that a normative framework for AI technologies 
(2015);  the  Recommendation  Concerning  the  Preservation 
and its social implications finds its basis in international and 
of, and Access to, Documentary Heritage Including in Digital 
national legal frameworks, human rights and fundamental 
Form (2015); the Declaration of Ethical Principles in relation to 
freedoms,  ethics,  need  for  access  to  data,  information 
Climate Change (2017); the Recommendation on Science and 
and knowledge, the freedom of research and innovation, 
Scientific Researchers (2017); the Internet Universality Indicators 
human and environmental and ecosystem well-being, and 
(endorsed  by  UNESCO’s  International  Programme  for  the 
connects ethical values and principles to the challenges and 
Development of Communication in 2018), including the ROAM 
opportunities linked to AI technologies, based on common 
principles (endorsed by UNESCO’s General Conference in 2015); 
understanding and shared aims,
the Human Rights Council’s resolution on “The right to privacy 
Also recognizing that ethical values and principles can  in the digital age” (A/HRC/RES/42/15) (2019); and the Human 
Rights  Council’s  resolution  on “New  and  emerging  digital 
help develop and implement rights-based policy measures 
technologies and human rights” (A/HRC/RES/41/11) (2019),
and legal norms, by providing guidance with a view to the fast 
pace of technological development, Emphasizing that specific attention must be paid to 
Also convinced that globally accepted ethical standards  LMICs, including but not limited to LDCs, LLDCs and SIDS, as 
they have their own capacity but have been underrepresented 
for AI technologies, in full respect of international law, in 
in the AI ethics debate, which raises concerns about neglecting 
particular human rights law, can play a key role in developing 
local knowledge, cultural pluralism, value systems and the 
AI-related norms across the globe,
demands of global fairness to deal with the positive and 
Bearing in mind the Universal Declaration of Human  negative impacts of AI technologies,
Rights (1948), the instruments of the international human 
Also conscious of the many existing national policies, 
rights framework, including the Convention Relating to the 
other frameworks and initiatives elaborated by relevant United 
Status of Refugees (1951), the Discrimination (Employment and 
Nations entities, intergovernmental organizations, including 
Occupation) Convention (1958), the International Convention 
regional organizations, as well as those by the private sector, 
on the Elimination of All Forms of Racial Discrimination (1965), 
professional organizations, non-governmental organizations, 
the International Covenant on Civil and Political Rights (1966), 
and  the  scientific  community,  related  to  the  ethics  and 
the International Covenant on Economic, Social and Cultural 
regulation of AI technologies,
Rights (1966), the Convention on the Elimination of All Forms 
of Discrimination against Women (1979), the Convention on  Further  convinced  that  AI  technologies  can  bring 
the Rights of the Child (1989), and the Convention on the 
important benefits, but that achieving them can also amplify 
Rights of Persons with Disabilities (2006), the Convention 
tension around innovation, asymmetric access to knowledge 
against Discrimination in Education (1960), the Convention 
and technologies, including the digital and civic literacy deficit 
on the Protection and Promotion of the Diversity of Cultural 
that limits the public’s ability to engage in topics related to 
Expressions (2005), as well as any other relevant international 
AI, as well as barriers to access to information and gaps in 
instruments, recommendations and declarations,
capacity, human and institutional capacities, barriers to access 
Also noting the United Nations Declaration on the Right to  to technological innovation, and a lack of adequate physical 
and digital infrastructure and regulatory frameworks, including 
Development (1986); the Declaration on the Responsibilities 
those related to data, all of which need to be addressed,
of  the  Present  Generations  Towards  Future  Generations 
(1997); the Universal Declaration on Bioethics and Human 
Rights (2005); the United Nations Declaration on the Rights 
6Underlining that the strengthening of global cooperation 
and solidarity, including through multilateralism, is needed 
to facilitate fair access to AI technologies and address the 
challenges that they bring to diversity and interconnectivity of 
cultures and ethical systems, to mitigate potential misuse, to 
realize the full potential that AI can bring, especially in the area 
of development, and to ensure that national AI strategies are 
guided by ethical principles,
Taking fully into account that the rapid development 
of AI technologies challenges their ethical implementation 
and governance, as well as the respect for and protection of 
cultural diversity, and has the potential to disrupt local and 
regional ethical standards and values,
1.  Adopts the present Recommendation on the Ethics 
of  Artificial  Intelligence  on  this  twenty-third  day  of 
November 2021;
2.  Recommends  that  Member  States  apply  on  a 
voluntary basis the provisions of this Recommendation by 
taking appropriate steps, including whatever legislative 
or other measures may be required, in conformity with 
the  constitutional  practice  and  governing  structures 
of each State, to give effect within their jurisdictions to 
the principles and norms of the Recommendation in 
conformity with international law, including international 
human rights law;
3.  Also  recommends  that  Member  States  engage 
all  stakeholders,  including  business  enterprises,  to 
ensure  that  they  play  their  respective  roles  in  the 
implementation  of  this  Recommendation;  and 
bring  the  Recommendation  to  the  attention  of  the 
authorities, bodies, research and academic organizations, 
institutions and organizations in public, private and civil 
society sectors involved in AI technologies, so that the 
development and use of AI technologies are guided by 
both sound scientific research as well as ethical analysis 
and evaluation.
78I. 
Scope of  
application
91.  This Recommendation addresses ethical issues related to  to range from research, design and development 
the domain of Artificial Intelligence to the extent that they  to deployment and use, including maintenance, 
are within UNESCO’s mandate. It approaches AI ethics as  operation,  trade,  financing,  monitoring  and 
a systematic normative reflection, based on a holistic,  evaluation, validation, end-of-use, disassembly and 
comprehensive, multicultural and evolving framework  termination. In addition, AI actors can be defined 
of interdependent values, principles and actions that can  as any actor involved in at least one stage of the AI 
guide societies in dealing responsibly with the known  system life cycle, and can refer both to natural and 
and unknown impacts of AI technologies on human  legal persons, such as researchers, programmers, 
beings, societies and the environment and ecosystems,  engineers,  data  scientists,  end-users,  business 
and offers them a basis to accept or reject AI technologies.  enterprises,  universities  and  public  and  private 
It considers ethics as a dynamic basis for the normative  entities, among others.
evaluation and guidance of AI technologies, referring to 
(c)  AI systems raise new types of ethical issues that 
human dignity, well-being and the prevention of harm 
include, but are not limited to, their impact on 
as a compass and as rooted in the ethics of science and 
decision-making, employment and labour, social 
technology.
interaction, health care, education, media, access 
2.  This Recommendation does not have the ambition to  to information, digital divide, personal data and 
provide one single definition of AI, since such a definition  consumer  protection,  environment,  democracy, 
would need to change over time, in accordance with  rule  of  law,  security  and  policing,  dual  use, 
technological developments. Rather, its ambition is to  and  human  rights  and  fundamental  freedoms, 
address those features of AI systems that are of central  including freedom of expression, privacy and non-
ethical  relevance.  Therefore,  this  Recommendation  discrimination. Furthermore, new ethical challenges 
approaches  AI  systems  as  systems  which  have  the  are created by the potential of AI algorithms to 
capacity to process data and information in a way that  reproduce and reinforce existing biases, and thus to 
resembles intelligent behaviour, and typically includes  exacerbate already existing forms of discrimination, 
aspects of reasoning, learning, perception, prediction,  prejudice and stereotyping. Some of these issues 
planning or control. Three elements have a central place  are related to the capacity of AI systems to perform 
in this approach: tasks which previously only living beings could 
do, and which were in some cases even limited to 
(a)  AI systems are information-processing technologies 
human beings only. These characteristics give AI 
that integrate models and algorithms that produce 
systems a profound, new role in human practices 
a  capacity  to  learn  and  to  perform  cognitive 
and society, as well as in their relationship with 
tasks  leading  to  outcomes  such  as  prediction 
the environment and ecosystems, creating a new 
and  decision-making  in  material  and  virtual 
context for children and young people to grow 
environments. AI systems are designed to operate 
up  in,  develop  an  understanding  of  the  world 
with varying degrees of autonomy by means of 
and themselves, critically understand media and 
knowledge modelling and representation and by 
information, and learn to make decisions. In the 
exploiting  data  and  calculating  correlations.  AI 
long term, AI systems could challenge humans’ 
systems may include several methods, such as but 
special sense of experience and agency, raising 
not limited to:
additional concerns about, inter alia, human self-
understanding, social, cultural and environmental 
(i)  machine  learning,  including  deep  learning 
interaction, autonomy, agency, worth and dignity.
and reinforcement learning; 
3.  This Recommendation pays specific attention to the 
(ii)  machine  reasoning,  including  planning, 
broader ethical implications of AI systems in relation 
scheduling,  knowledge  representation  and 
to the central domains of UNESCO: education, science, 
reasoning, search, and optimization.
culture, and communication and information, as explored 
  AI systems can be used in cyber-physical systems,  in the 2019 Preliminary Study on the Ethics of Artificial 
including the Internet of things, robotic systems,  Intelligence by the UNESCO World Commission on Ethics 
social robotics, and human-computer interfaces,  of Scientific Knowledge and Technology (COMEST):
which involve control, perception, the processing 
(a)  Education, because living in digitalizing societies 
of data collected by sensors, and the operation of 
requires  new  educational  practices,  ethical 
actuators in the environment in which AI systems 
reflection,  critical  thinking,  responsible  design 
work.
practices and new skills, given the implications 
(b)  Ethical questions regarding AI systems pertain to all  for  the  labour  market,  employability  and  civic 
stages of the AI system life cycle, understood here  participation.
10(b)  Science,  in  the  broadest  sense  and  including  structuring and provision of information; the issues 
all  academic  fields  from  the  natural  sciences  of  automated  journalism  and  the  algorithmic 
and medical sciences to the social sciences and  provision of news and moderation and curation of 
humanities, as AI technologies bring new research  content on social media and search engines are just 
capacities  and  approaches,  have  implications  a few examples raising issues related to access to 
for our concepts of scientific understanding and  information, disinformation, misinformation, hate 
explanation, and create a new basis for decision- speech, the emergence of new forms of societal 
making. narratives, discrimination, freedom of expression, 
privacy and media and information literacy, among 
(c)  Cultural identity and diversity, as AI technologies 
others.
can enrich cultural and creative industries, but can 
also lead to an increased concentration of supply of  4.  This Recommendation is addressed to Member States, 
cultural content, data, markets and income in the  both  as  AI  actors  and  as  authorities  responsible  for 
hands of only a few actors, with potential negative  developing legal and regulatory frameworks throughout 
implications  for  the  diversity  and  pluralism  of  the entire AI system life cycle, and for promoting business 
languages, media, cultural expressions, participation  responsibility. It also provides ethical guidance to all AI 
and equality. actors,  including  the  public  and  private  sectors,  by 
providing a basis for an ethical impact assessment of AI 
(d)  Communication and information, as AI technologies 
systems throughout their life cycle.
play an increasingly important role in the processing, 
1112II.
 
Aims and 
objectives
135.  This Recommendation aims to provide a basis to make  7.  Because  the  complexity  of  the  ethical  issues 
AI systems work for the good of humanity, individuals,  surrounding AI necessitates the cooperation of multiple 
societies and the environment and ecosystems, and to  stakeholders across the various levels and sectors of 
prevent harm. It also aims at stimulating the peaceful use  international, regional and national communities, this 
of AI systems. Recommendation aims to enable stakeholders to take 
shared responsibility based on a global and intercultural 
6.  In addition to the existing ethical frameworks regarding 
dialogue.
AI around the world, this Recommendation aims to bring 
a globally accepted normative instrument that focuses  8.  The objectives of this Recommendation are:
not only on the articulation of values and principles, 
(a)  to provide a universal framework of values, principles 
but  also  on  their  practical  realization,  via  concrete 
and actions to guide States in the formulation 
policy recommendations, with a strong emphasis on 
of their legislation, policies or other instruments 
inclusion issues of gender equality and protection of the 
regarding AI, consistent with international law;
environment and ecosystems.
14(b)  to  guide  the  actions  of  individuals,  groups,  (d)  to foster multi-stakeholder, multidisciplinary and 
communities,  institutions  and  private  sector  pluralistic dialogue and consensus building about 
companies to ensure the embedding of ethics in all  ethical issues relating to AI systems; 
stages of the AI system life cycle;
(e)  to promote equitable access to developments and 
(c)  to  protect,  promote  and  respect  human  rights  knowledge in the field of AI and the sharing of 
and fundamental freedoms, human dignity and  benefits, with particular attention to the needs and 
equality, including gender equality; to safeguard  contributions of LMICs, including LDCs, LLDCs and 
the interests of present and future generations;  SIDS.
to  preserve  the  environment,  biodiversity  and 
ecosystems; and to respect cultural diversity in all 
stages of the AI system life cycle;
1516III.
 
Values and 
principles
179.  The values and principles included below should be  human rights and fundamental freedoms. In all cases, any 
respected by all actors in the AI system life cycle, in the first  possible limitations on human rights and fundamental 
place and, where needed and appropriate, be promoted  freedoms must have a lawful basis, and be reasonable, 
through amendments to the existing and elaboration  necessary and proportionate, and consistent with States’ 
of new legislation, regulations and business guidelines.  obligations under international law. To navigate such 
This must comply with international law, including the  scenarios judiciously will typically require engagement 
United Nations Charter and Member States’ human rights  with a broad range of appropriate stakeholders, making 
obligations, and should be in line with internationally  use of social dialogue, as well as ethical deliberation, due 
agreed  social,  political,  environmental,  educational,  diligence and impact assessment.
scientific and economic sustainability objectives, such 
12.  The trustworthiness and integrity of the life cycle of AI 
as the United Nations Sustainable Development Goals 
systems is essential to ensure that AI technologies will 
(SDGs).
work for the good of humanity, individuals, societies 
10.  Values play a powerful role as motivating ideals in shaping  and the environment and ecosystems, and embody the 
policy measures and legal norms. While the set of values  values and principles set out in this Recommendation. 
outlined below thus inspires desirable behaviour and  People should have good reason to trust that AI systems 
represents the foundations of principles, the principles  can bring individual and shared benefits, while adequate 
unpack the values underlying them more concretely so  measures  are  taken  to  mitigate  risks.  An  essential 
that the values can be more easily operationalized in  requirement for trustworthiness is that, throughout their 
policy statements and actions. life cycle, AI systems are subject to thorough monitoring 
by  the  relevant  stakeholders  as  appropriate.  As 
11. While all the values and principles outlined below are 
trustworthiness is an outcome of the operationalization 
desirable per se, in any practical contexts, there may be 
of the principles in this document, the policy actions 
tensions between these values and principles. In any 
proposed in this Recommendation are all directed at 
given situation, a contextual assessment will be necessary 
promoting trustworthiness in all stages of the AI system 
to manage potential tensions, taking into account the 
life cycle.
principle  of  proportionality  and  in  compliance  with 
III.1 VALUES
Respect, protection and promotion of human  life” should be left open to individuals or groups, as long 
rights and fundamental freedoms and human  as there is no violation or abuse of human rights and 
dignity
fundamental freedoms, or the dignity of humans in terms 
of this definition.
13.  The inviolable and inherent dignity of every human 
constitutes the foundation for the universal, indivisible,  15.  Persons may interact with AI systems throughout their 
inalienable, interdependent and interrelated system of  life cycle and receive assistance from them, such as 
human  rights  and  fundamental  freedoms. Therefore,  care  for  vulnerable  people  or  people  in  vulnerable 
respect, protection and promotion of human dignity  situations, including but not limited to children, older 
and rights as established by international law, including  persons, persons with disabilities or the ill. Within such 
international human rights law, is essential throughout  interactions, persons should never be objectified, nor 
the life cycle of AI systems. Human dignity relates to  should their dignity be otherwise undermined, or human 
the  recognition  of  the  intrinsic  and  equal  worth  of  rights and fundamental freedoms violated or abused.
each individual human being, regardless of race, colour, 
descent, gender, age, language, religion, political opinion,  16.  Human  rights  and  fundamental  freedoms  must  be 
national origin, ethnic origin, social origin, economic  respected,  protected  and  promoted  throughout  the 
or social condition of birth, or disability and any other  life cycle of AI systems. Governments, private sector, 
grounds. civil  society,  international  organizations,  technical 
communities and academia must respect human rights 
14.  No human being or human community should be harmed  instruments and frameworks in their interventions in the 
or  subordinated,  whether  physically,  economically,  processes surrounding the life cycle of AI systems. New 
socially,  politically,  culturally  or  mentally  during  any  technologies need to provide new means to advocate, 
phase of the life cycle of AI systems. Throughout the life  defend and exercise human rights and not to infringe 
cycle of AI systems, the quality of life of human beings  them.
should be enhanced, while the definition of “quality of 
18Environment and ecosystem flourishing race, colour, descent, gender, age, language, religion, 
political opinion, national origin, ethnic origin, social 
17.  Environmental  and  ecosystem  flourishing  should  be 
origin, economic or social condition of birth, or disability 
recognized, protected and promoted through the life 
and any other grounds.
cycle  of  AI  systems.  Furthermore,  environment  and 
ecosystems are the existential necessity for humanity  20.  The  scope  of  lifestyle  choices,  beliefs,  opinions, 
and other living beings to be able to enjoy the benefits  expressions  or  personal  experiences,  including  the 
of advances in AI. optional use of AI systems and the co-design of these 
architectures should not be restricted during any phase 
18.  All actors involved in the life cycle of AI systems must 
of the life cycle of AI systems. 
comply with applicable international law and domestic 
legislation, standards and practices, such as precaution,  21.  Furthermore, efforts, including international cooperation, 
designed for environmental and ecosystem protection  should be made to overcome, and never take advantage 
and  restoration,  and  sustainable  development.  They  of, the lack of necessary technological infrastructure, 
should reduce the environmental impact of AI systems,  education  and  skills,  as  well  as  legal  frameworks, 
including but not limited to its carbon footprint, to ensure  particularly in LMICs, LDCs, LLDCs and SIDS, affecting 
the minimization of climate change and environmental  communities.
risk factors, and prevent the unsustainable exploitation, 
use and transformation of natural resources contributing 
Living in peaceful, just and interconnected 
to  the  deterioration  of  the  environment  and  the 
societies
degradation of ecosystems.
22.  AI actors should play a participative and enabling role 
to ensure peaceful and just societies, which is based on 
Ensuring diversity and inclusiveness
an interconnected future for the benefit of all, consistent 
19.  Respect,  protection  and  promotion  of  diversity  and  with  human  rights  and  fundamental  freedoms.  The 
inclusiveness should be ensured throughout the life cycle  value of living in peaceful and just societies points to the 
of AI systems, consistent with international law, including  potential of AI systems to contribute throughout their 
human rights law. This may be done by promoting active  life cycle to the interconnectedness of all living creatures 
participation of all individuals or groups regardless of  with each other and with the natural environment.
1923.  The notion of humans being interconnected is based  24.  This  value  demands  that  peace,  inclusiveness  and 
on  the  knowledge  that  every  human  belongs  to  a  justice,  equity  and  interconnectedness  should  be 
greater whole, which thrives when all its constituent  promoted throughout the life cycle of AI systems, in 
parts are enabled to thrive. Living in peaceful, just and  so far as the processes of the life cycle of AI systems 
interconnected societies requires an organic, immediate,  should not segregate, objectify or undermine freedom 
uncalculated  bond  of  solidarity,  characterized  by  a  and autonomous decision-making as well as the safety 
permanent  search  for  peaceful  relations,  tending  of human beings and communities, divide and turn 
towards care for others and the natural environment in  individuals and groups against each other, or threaten 
the broadest sense of the term. the coexistence between humans, other living beings 
and the natural environment. 
III.2 PRINCIPLES
Proportionality and Do No Harm Fairness and non-discrimination
25.  It should be recognized that AI technologies do not  28.  AI actors should promote social justice and safeguard 
necessarily, per se, ensure human and environmental  fairness and non-discrimination of any kind in compliance 
and ecosystem flourishing. Furthermore, none of the  with international law. This implies an inclusive approach 
processes related to the AI system life cycle shall exceed  to ensuring that the benefits of AI technologies are 
what is necessary to achieve legitimate aims or objectives  available and accessible to all, taking into consideration 
and should be appropriate to the context. In the event  the specific needs of different age groups, cultural systems, 
of possible occurrence of any harm to human beings,  different  language  groups,  persons  with  disabilities, 
human rights and fundamental freedoms, communities  girls and women, and disadvantaged, marginalized and 
and society at large or the environment and ecosystems,  vulnerable people or people in vulnerable situations. 
the implementation of procedures for risk assessment  Member States should work to promote inclusive access 
and the adoption of measures in order to preclude the  for all, including local communities, to AI systems with 
occurrence of such harm should be ensured. locally relevant content and services, and with respect 
for multilingualism and cultural diversity. Member States 
26.  The choice to use AI systems and which AI method to 
should work to tackle digital divides and ensure inclusive 
use should be justified in the following ways: (a) the AI 
access to and participation in the development of AI. At 
method chosen should be appropriate and proportional 
the national level, Member States should promote equity 
to achieve a given legitimate aim; (b) the AI method 
between rural and urban areas, and among all persons 
chosen should not infringe upon the foundational values 
regardless of race, colour, descent, gender, age, language, 
captured in this document, in particular, its use must not 
religion, political opinion, national origin, ethnic origin, 
violate or abuse human rights; and (c) the AI method 
social origin, economic or social condition of birth, or 
should be appropriate to the context and should be 
disability and any other grounds, in terms of access 
based on rigorous scientific foundations. In scenarios 
to and participation in the AI system life cycle. At the 
where decisions are understood to have an impact that 
international level, the most technologically advanced 
is irreversible or difficult to reverse or may involve life 
countries have a responsibility of solidarity with the least 
and death decisions, final human determination should 
advanced to ensure that the benefits of AI technologies 
apply. In particular, AI systems should not be used for 
are shared such that access to and participation in the 
social scoring or mass surveillance purposes.
AI system life cycle for the latter contributes to a fairer 
world order with regard to information, communication, 
culture, education, research and socio-economic and 
Safety and security
political stability.
27.  Unwanted harms (safety risks), as well as vulnerabilities 
29.  AI actors should make all reasonable efforts to minimize 
to attack (security risks) should be avoided and should 
and  avoid  reinforcing  or  perpetuating  discriminatory 
be addressed, prevented and eliminated throughout the 
or biased applications and outcomes throughout the 
life cycle of AI systems to ensure human, environmental 
life cycle of the AI system to ensure fairness of such 
and ecosystem safety and security. Safe and secure AI will 
systems. Effective remedy should be available against 
be enabled by the development of sustainable, privacy-
discrimination and biased algorithmic determination.
protective data access frameworks that foster better 
training and validation of AI models utilizing quality data. 
2030.  Furthermore, digital and knowledge divides within and  Right to Privacy, and Data Protection
between countries need to be addressed throughout 
32.  Privacy, a right essential to the protection of human 
an AI system life cycle, including in terms of access and 
dignity, human autonomy and human agency, must 
quality of access to technology and data, in accordance 
be respected, protected and promoted throughout the 
with  relevant  national,  regional  and  international 
life cycle of AI systems. It is important that data for AI 
legal frameworks, as well as in terms of connectivity, 
systems be collected, used, shared, archived and deleted 
knowledge and skills and meaningful participation of the 
in ways that are consistent with international law and 
affected communities, such that every person is treated 
in line with the values and principles set forth in this 
equitably.
Recommendation, while respecting relevant national, 
regional and international legal frameworks.
Sustainability
33.  Adequate data protection frameworks and governance 
31.  The  development  of  sustainable  societies  relies  on  mechanisms should be established in a multi-stakeholder 
the achievement of a complex set of objectives on a  approach at the national or international level, protected 
continuum of human, social, cultural, economic and  by judicial systems, and ensured throughout the life 
environmental dimensions. The advent of AI technologies  cycle of AI systems. Data protection frameworks and 
can  either  benefit  sustainability  objectives  or  hinder  any  related  mechanisms  should  take  reference  from 
their realization, depending on how they are applied  international data protection principles and standards 
across countries with varying levels of development. The  concerning the collection, use and disclosure of personal 
continuous assessment of the human, social, cultural,  data and exercise of their rights by data subjects while 
economic and environmental impact of AI technologies  ensuring a legitimate aim and a valid legal basis for the 
should therefore be carried out with full cognizance of  processing of personal data, including informed consent.
the  implications  of  AI  technologies  for  sustainability 
34.  Algorithmic systems require adequate privacy impact 
as a set of constantly evolving goals across a range of 
assessments,  which  also  include  societal  and  ethical 
dimensions, such as currently identified in the Sustainable 
considerations of their use and an innovative use of the 
Development Goals (SDGs) of the United Nations. 
21privacy by design approach. AI actors need to ensure that  sector  company  or  public  sector  institution  able  to 
they are accountable for the design and implementation  review and correct the decision. AI actors should inform 
of AI systems in such a way as to ensure that personal  users when a product or service is provided directly or 
information is protected throughout the life cycle of the  with the assistance of AI systems in a proper and timely 
AI system. manner. 
39.  From  a  socio-technical  lens,  greater  transparency 
Human oversight and determination  contributes  to  more  peaceful,  just,  democratic  and 
inclusive societies. It allows for public scrutiny that can 
35.  Member States should ensure that it is always possible to 
decrease corruption and discrimination, and can also 
attribute ethical and legal responsibility for any stage of 
help detect and prevent negative impacts on human 
the life cycle of AI systems, as well as in cases of remedy 
rights.  Transparency  aims  at  providing  appropriate 
related to AI systems, to physical persons or to existing 
information to the respective addressees to enable their 
legal  entities.  Human  oversight  refers  thus  not  only 
understanding and foster trust. Specific to the AI system, 
to individual human oversight, but to inclusive public 
transparency can enable people to understand how 
oversight, as appropriate.
each stage of an AI system is put in place, appropriate 
to the context and sensitivity of the AI system. It may 
36.  It  may  be  the  case  that  sometimes  humans  would 
also include insight into factors that affect a specific 
choose to rely on AI systems for reasons of efficacy, but 
prediction or decision, and whether or not appropriate 
the decision to cede control in limited contexts remains 
assurances (such as safety or fairness measures) are in 
that of humans, as humans can resort to AI systems in 
place. In cases of serious threats of adverse human rights 
decision-making and acting, but an AI system can never 
impacts, transparency may also require the sharing of 
replace ultimate human responsibility and accountability. 
code or datasets.
As a rule, life and death decisions should not be ceded to 
AI systems.
40.  Explainability refers to making intelligible and providing 
insight into the outcome of AI systems. The explainability 
of AI systems also refers to the understandability of the 
Transparency and explainability
input, output and the functioning of each algorithmic 
37.  The transparency and explainability of AI systems are  building block and how it contributes to the outcome 
often  essential  preconditions  to  ensure  the  respect,  of the systems. Thus, explainability is closely related to 
protection and promotion of human rights, fundamental  transparency, as outcomes and sub-processes leading 
freedoms  and  ethical  principles.  Transparency  is  to  outcomes  should  aim  to  be  understandable  and 
necessary for relevant national and international liability  traceable, appropriate to the context. AI actors should 
regimes to work effectively. A lack of transparency could  commit to ensuring that the algorithms developed are 
also undermine the possibility of effectively challenging  explainable. In the case of AI applications that impact the 
decisions based on outcomes produced by AI systems  end user in a way that is not temporary, easily reversible 
and may thereby infringe the right to a fair trial and  or otherwise low risk, it should be ensured that the 
effective remedy, and limits the areas in which these  meaningful explanation is provided with any decision 
systems can be legally used. that resulted in the action taken in order for the outcome 
to be considered transparent.
38.  While efforts need to be made to increase transparency 
and explainability of AI systems, including those with  41.  Transparency and explainability relate closely to adequate 
extra-territorial impact, throughout their life cycle to  responsibility and accountability measures, as well as to 
support democratic governance, the level of transparency  the trustworthiness of AI systems.
and explainability should always be appropriate to the 
context and impact, as there may be a need to balance 
Responsibility and accountability
between  transparency  and  explainability  and  other 
principles such as privacy, safety and security. People 
42.  AI actors and Member States should respect, protect and 
should be fully informed when a decision is informed 
promote human rights and fundamental freedoms, and 
by or is made on the basis of AI algorithms, including 
should also promote the protection of the environment 
when it affects their safety or human rights, and in those 
and ecosystems, assuming their respective ethical and 
circumstances should have the opportunity to request 
legal  responsibility,  in  accordance  with  national  and 
explanatory information from the relevant AI actor or 
international law, in particular Member States’ human 
public sector institutions. In addition, individuals should 
rights  obligations,  and  ethical  guidance  throughout 
be able to access the reasons for a decision affecting 
the life cycle of AI systems, including with respect to AI 
their rights and freedoms, and have the option of making 
actors within their effective territory and control. The 
submissions to a designated staff member of the private 
ethical responsibility and liability for the decisions and 
22actions based in any way on an AI system should always  their impact on human rights and access to rights, as well 
ultimately be attributable to AI actors corresponding to  as on the environment and ecosystems.
their role in the life cycle of the AI system. 
43.  Appropriate  oversight,  impact  assessment,  audit  and  Multi-stakeholder and adaptive governance and 
due diligence mechanisms, including whistle-blowers’  collaboration
protection, should be developed to ensure accountability 
46.  International  law  and  national  sovereignty  must  be 
for AI systems and their impact throughout their life 
respected in the use of data. That means that States, 
cycle. Both technical and institutional designs should 
complying with international law, can regulate the data 
ensure auditability and traceability of (the working of) AI 
generated within or passing through their territories, 
systems in particular to address any conflicts with human 
and take measures towards effective regulation of data, 
rights norms and standards and threats to environmental 
including data protection, based on respect for the right 
and ecosystem well-being.
to privacy in accordance with international law and other 
human rights norms and standards.
Awareness and literacy 
47.  Participation  of  different  stakeholders  throughout 
44.  Public awareness and understanding of AI technologies  the  AI  system  life  cycle  is  necessary  for  inclusive 
and the value of data should be promoted through open  approaches  to  AI  governance,  enabling  the  benefits 
and  accessible  education,  civic  engagement,  digital  to be shared by all, and to contribute to sustainable 
skills  and  AI  ethics  training,  media  and  information  development. Stakeholders include but are not limited 
literacy  and  training  led  jointly  by  governments,  to  governments,  intergovernmental  organizations, 
intergovernmental organizations, civil society, academia,  the technical community, civil society, researchers and 
the media, community leaders and the private sector,  academia,  media,  education,  policy-makers,  private 
and considering the existing linguistic, social and cultural  sector companies, human rights institutions and equality 
diversity, to ensure effective public participation so that  bodies,  anti-discrimination  monitoring  bodies,  and 
all members of society can take informed decisions  groups for youth and children. The adoption of open 
about their use of AI systems and be protected from  standards and interoperability to facilitate collaboration 
undue influence. should be in place. Measures should be adopted to take 
into account shifts in technologies, the emergence of 
45.  Learning about the impact of AI systems should include 
new groups of stakeholders, and to allow for meaningful 
learning  about,  through  and  for  human  rights  and 
participation by marginalized groups, communities and 
fundamental freedoms, meaning that the approach and 
individuals and, where relevant, in the case of Indigenous 
understanding of AI systems should be grounded by 
Peoples, respect for the self-governance of their data.
2324IV.
 
Areas of 
policy action 
2548.  The policy actions described in the following policy  49.  UNESCO  recognizes  that  Member  States  will  be 
areas operationalize the values and principles set out in  at  different  stages  of  readiness  to  implement  this 
this Recommendation. The main action is for Member  Recommendation, in terms of scientific, technological, 
States to put in place effective measures, including, for  economic, educational, legal, regulatory, infrastructural, 
example,  policy  frameworks  or  mechanisms,  and  to  societal, cultural and other dimensions. It is noted that 
ensure that other stakeholders, such as private sector  “readiness” here is a dynamic status. In order to enable 
companies,  academic  and  research  institutions,  and  the effective implementation of this Recommendation, 
civil society adhere to them by, among other actions,  UNESCO will therefore: (1) develop a readiness assessment 
encouraging all stakeholders to develop human rights,  methodology  to  assist  interested  Member  States  in 
rule of law, democracy, and ethical impact assessment  identifying  their  status  at  specific  moments  of  their 
and due diligence tools in line with guidance including  readiness trajectory along a continuum of dimensions; 
the United Nations Guiding Principles on Business and  and (2) ensure support for interested Member States in 
Human Rights. The process for developing such policies  terms of developing a UNESCO methodology for Ethical 
or mechanisms should be inclusive of all stakeholders  Impact  Assessment  (EIA)  of  AI  technologies,  sharing 
and should take into account the circumstances and  of  best  practices,  assessment  guidelines  and  other 
priorities of each Member State. UNESCO can be a partner  mechanisms and analytical work.
and support Member States in the development as well 
as monitoring and evaluation of policy mechanisms.
POLICY AREA 1: ETHICAL IMPACT ASSESSMENT
50.  Member States should introduce frameworks for impact  including in real-world conditions if needed, as part of 
assessments,  such  as  ethical  impact  assessment,  to  the Ethical Impact Assessment, before releasing them in 
identify and assess benefits, concerns and risks of AI  the market.
systems, as well as appropriate risk prevention, mitigation 
52.  Member  States  and  business  enterprises  should 
and  monitoring  measures,  among  other  assurance 
implement appropriate measures to monitor all phases 
mechanisms. Such impact assessments should identify 
of an AI system life cycle, including the functioning of 
impacts on human rights and fundamental freedoms, in 
algorithms used for decision-making, the data, as well 
particular but not limited to the rights of marginalized 
as AI actors involved in the process, especially in public 
and vulnerable people or people in vulnerable situations, 
services and where direct end-user interaction is needed, 
labour  rights,  the  environment  and  ecosystems  and 
as part of ethical impact assessment. Member States’ 
ethical  and  social  implications,  and  facilitate  citizen 
human rights law obligations should form part of the 
participation in line with the values and principles set 
ethical aspects of AI system assessments.
forth in this Recommendation.
53.  Governments should adopt a regulatory framework that 
51.  Member States and private sector companies should 
sets out a procedure, particularly for public authorities, 
develop  due  diligence  and  oversight  mechanisms 
to carry out ethical impact assessments on AI systems 
to  identify,  prevent,  mitigate  and  account  for  how 
to predict consequences, mitigate risks, avoid harmful 
they address the impact of AI systems on the respect 
consequences,  facilitate  citizen  participation  and 
for human rights, rule of law and inclusive societies. 
address societal challenges. The assessment should also 
Member States should also be able to assess the socio-
establish appropriate oversight mechanisms, including 
economic impact of AI systems on poverty and ensure 
auditability, traceability and explainability, which enable 
that  the  gap  between  people  living  in  wealth  and 
the assessment of algorithms, data and design processes, 
poverty, as well as the digital divide among and within 
as well as include external review of AI systems. Ethical 
countries, are not increased with the massive adoption 
impact assessments should be transparent and open to 
of  AI  technologies  at  present  and  in  the  future.  In 
the public, where appropriate. Such assessments should 
order to do this, in particular, enforceable transparency 
also be multidisciplinary, multi-stakeholder, multicultural, 
protocols should be implemented, corresponding to the 
pluralistic and inclusive. The public authorities should be 
access to information, including information of public 
required to monitor the AI systems implemented and/or 
interest held by private entities. Member States, private 
deployed by those authorities by introducing appropriate 
sector companies and civil society should investigate 
mechanisms and tools.
the sociological and psychological effects of AI-based 
recommendations on humans in their decision-making 
autonomy. AI systems identified as potential risks to 
human rights should be broadly tested by AI actors, 
26POLICY AREA 2: ETHICAL GOVERNANCE AND STEWARDSHIP
54.  Member  States  should  ensure  that  AI  governance  58.  Member States should encourage public entities, private 
mechanisms are inclusive, transparent, multidisciplinary,  sector  companies  and  civil  society  organizations  to 
multilateral (this includes the possibility of mitigation and  involve different stakeholders in their AI governance 
redress of harm across borders) and multi-stakeholder.  and to consider adding the role of an independent AI 
In  particular,  governance  should  include  aspects  of  Ethics Officer or some other mechanism to oversee 
anticipation,  and  effective  protection,  monitoring  of  ethical  impact  assessment,  auditing  and  continuous 
impact, enforcement and redress. monitoring efforts and ensure ethical guidance of AI 
systems. Member States, private sector companies and 
55.  Member States should ensure that harms caused through 
civil society organizations, with the support of UNESCO, 
AI systems are investigated and redressed, by enacting 
are encouraged to create a network of independent AI 
strong enforcement mechanisms and remedial actions, 
Ethics Officers to give support to this process at national, 
to make certain that human rights and fundamental 
regional and international levels.
freedoms and the rule of law are respected in the digital 
world  and  in  the  physical  world.  Such  mechanisms  59.  Member States should foster the development of, and 
and actions should include remediation mechanisms  access to, a digital ecosystem for ethical and inclusive 
provided by private and public sector companies. The  development of AI systems at the national level, including 
auditability and traceability of AI systems should be  to address gaps in access to the AI system life cycle, while 
promoted to this end. In addition, Member States should  contributing  to  international  collaboration.  Such  an 
strengthen their institutional capacities to deliver on this  ecosystem includes, in particular, digital technologies 
commitment and should collaborate with researchers  and  infrastructure,  and  mechanisms  for  sharing  AI 
and  other  stakeholders  to  investigate,  prevent  and  knowledge, as appropriate. 
mitigate any potentially malicious uses of AI systems.
60.  Member  States  should  establish  mechanisms,  in 
56.  Member  States  are  encouraged  to  develop  national  collaboration  with  international  organizations, 
and regional AI strategies and to consider forms of soft  transnational  corporations,  academic  institutions  and 
governance such as a certification mechanism for AI  civil society, to ensure the active participation of all 
systems and the mutual recognition of their certification,  Member  States,  especially  LMICs,  in  particular  LDCs, 
according to the sensitivity of the application domain  LLDCs and SIDS, in international discussions concerning 
and expected impact on human rights, the environment  AI governance. This can be through the provision of 
and ecosystems, and other ethical considerations set  funds,  ensuring  equal  regional  participation,  or  any 
forth  in  this  Recommendation.  Such  a  mechanism  other mechanisms. Furthermore, in order to ensure the 
might include different levels of audit of systems, data,  inclusiveness of AI fora, Member States should facilitate 
and adherence to ethical guidelines and to procedural  the  travel  of  AI  actors  in  and  out  of  their  territory, 
requirements in view of ethical aspects. At the same  especially from LMICs, in particular LDCs, LLDCs and SIDS, 
time, such a mechanism should not hinder innovation or  for the purpose of participating in these fora.
disadvantage small and medium enterprises or start-ups, 
61.  Amendments  to  the  existing  or  elaboration  of  new 
civil society as well as research and science organizations, 
national legislation addressing AI systems must comply 
as a result of an excessive administrative burden. These 
with Member States’ human rights law obligations and 
mechanisms should also include a regular monitoring 
promote  human  rights  and  fundamental  freedoms 
component to ensure system robustness and continued 
throughout the AI system life cycle. Promotion thereof 
integrity and adherence to ethical guidelines over the 
should  also  take  the  form  of  governance  initiatives, 
entire life cycle of the AI system, requiring re-certification 
good exemplars of collaborative practices regarding AI 
if necessary.
systems, and national and international technical and 
57.  Member States and public authorities should carry out  methodological guidelines as AI technologies advance. 
transparent self-assessment of existing and proposed  Diverse sectors, including the private sector, in their 
AI  systems,  which,  in  particular,  should  include  the  practices regarding AI systems must respect, protect and 
assessment of whether the adoption of AI is appropriate  promote human rights and fundamental freedoms using 
and, if so, should include further assessment to determine  existing and new instruments in combination with this 
what the appropriate method is, as well as assessment as  Recommendation.
to whether such adoption would result in violations or 
62.  Member States that acquire Al systems for human rights-
abuses of Member States’ human rights law obligations, 
sensitive use cases, such as law enforcement, welfare, 
and if that is the case, prohibit its use.
employment, media and information providers, health 
care and the independent judiciary system should provide 
27mechanisms to monitor the social and economic impact  67.  Member States should implement policies to promote 
of such systems by appropriate oversight authorities,  and  increase  diversity  and  inclusiveness  that  reflect 
including  independent  data  protection  authorities,  their populations in AI development teams and training 
sectoral  oversight  and  public  bodies  responsible  for  datasets, and to ensure equal access to AI technologies 
oversight. and their benefits, particularly for marginalized groups, 
both from rural and urban zones.
63.  Member States should enhance the capacity of the 
judiciary to make decisions related to AI systems as per  68.  Member  States  should  develop,  review  and  adapt, 
the rule of law and in line with international law and  as  appropriate,  regulatory  frameworks  to  achieve 
standards, including in the use of AI systems in their  accountability and responsibility for the content and 
deliberations, while ensuring that the principle of human  outcomes of AI systems at the different phases of their life 
oversight is upheld. In case AI systems are used by the  cycle. Member States should, where necessary, introduce 
judiciary, sufficient safeguards are needed to guarantee  liability frameworks or clarify the interpretation of existing 
inter alia the protection of fundamental human rights, the  frameworks to ensure the attribution of accountability 
rule of law, judicial independence as well as the principle  for the outcomes and the functioning of AI systems. 
of human oversight, and to ensure a trustworthy, public  Furthermore, when developing regulatory frameworks, 
interest-oriented and human-centric development and  Member States should, in particular, take into account that 
use of AI systems in the judiciary.  ultimate responsibility and accountability must always lie 
with natural or legal persons and that AI systems should 
64.  Member States should ensure that governments and 
not be given legal personality themselves. To ensure 
multilateral organizations play a leading role in ensuring 
this, such regulatory frameworks should be consistent 
the  safety  and  security  of  AI  systems,  with  multi-
with the principle of human oversight and establish a 
stakeholder participation. Specifically, Member States, 
comprehensive approach focused on AI actors and the 
international organizations and other relevant bodies 
technological processes involved across the different 
should develop international standards that describe 
stages of the AI system life cycle.
measurable, testable levels of safety and transparency, 
so that systems can be objectively assessed and levels  69.  In order to establish norms where these do not exist, 
of compliance determined. Furthermore, Member States  or  to  adapt  the  existing  legal  frameworks,  Member 
and business enterprises should continuously support  States should involve all AI actors (including, but not 
strategic research on potential safety and security risks  limited to, researchers, representatives of civil society 
of AI technologies and should encourage research into  and law enforcement, insurers, investors, manufacturers, 
transparency and explainability, inclusion and literacy by  engineers, lawyers and users). The norms can mature into 
putting additional funding into those areas for different  best practices, laws and regulations. Member States are 
domains and at different levels, such as technical and  further encouraged to use mechanisms such as policy 
natural language. prototypes  and  regulatory  sandboxes  to  accelerate 
the  development  of  laws,  regulations  and  policies, 
65.  Member States should implement policies to ensure that 
including regular reviews thereof, in line with the rapid 
the actions of AI actors are consistent with international 
development of new technologies and ensure that laws 
human rights law, standards and principles throughout 
and regulations can be tested in a safe environment 
the  life  cycle  of  AI  systems,  while  taking  into  full 
before being officially adopted. Member States should 
consideration the current cultural and social diversities, 
support local governments in the development of local 
including local customs and religious traditions, with 
policies, regulations and laws in line with national and 
due regard to the precedence and universality of human 
international legal frameworks.
rights. 
70.  Member States should set clear requirements for AI 
66.  Member  States  should  put  in  place  mechanisms  to 
system transparency and explainability so as to help 
require AI actors to disclose and combat any kind of 
ensure the trustworthiness of the full AI system life 
stereotyping in the outcomes of AI systems and data, 
cycle. Such requirements should involve the design and 
whether by design or by negligence, and to ensure that 
implementation of impact mechanisms that take into 
training data sets for AI systems do not foster cultural, 
consideration the nature of application domain, intended 
economic or social inequalities, prejudice, the spreading 
use, target audience and feasibility of each particular AI 
of disinformation and misinformation, and disruption 
system.
of freedom of expression and access to information. 
Particular attention should be given to regions where the 
data are scarce. 
28POLICY AREA 3: DATA POLICY
71.  Member States should work to develop data governance  appropriate safeguards for the processing of sensitive 
strategies that ensure the continual evaluation of the  data; an appropriate level of data protection; effective and 
quality of training data for AI systems including the  meaningful accountability schemes and mechanisms; 
adequacy of the data collection and selection processes,  the full enjoyment of the data subjects’ rights and the 
proper data security and protection measures, as well as  ability to access and erase their personal data in AI 
feedback mechanisms to learn from mistakes and share  systems, except for certain circumstances in compliance 
best practices among all AI actors. with international law; an appropriate level of protection 
in full compliance with data protection legislation where 
72.  Member States should put in place appropriate safeguards 
data are being used for commercial purposes such as 
to  protect  the  right  to  privacy  in  accordance  with 
enabling micro-targeted advertising, transferred cross-
international law, including addressing concerns such 
border; and an effective independent oversight as part of 
as surveillance. Member States should, among others, 
a data governance mechanism which keeps individuals 
adopt or enforce legislative frameworks that provide 
in control of their personal data and fosters the benefits 
appropriate  protection,  compliant  with  international 
of a free flow of information internationally, including 
law. Member States should strongly encourage all AI 
access to data.
actors, including business enterprises, to follow existing 
international standards and, in particular, to carry out  74.  Member States should establish their data policies or 
adequate privacy impact assessments, as part of ethical  equivalent frameworks, or reinforce existing ones, to 
impact assessments, which take into account the wider  ensure full security for personal data and sensitive data, 
socio-economic impact of the intended data processing,  which, if disclosed, may cause exceptional damage, injury 
and  to  apply  privacy  by  design  in  their  systems.  or hardship to individuals. Examples include data relating 
Privacy should be respected, protected and promoted  to offences, criminal proceedings and convictions, and 
throughout the life cycle of AI systems. related security measures; biometric, genetic and health 
data; and -personal data such as that relating to race, 
73.  Member States should ensure that individuals retain 
colour, descent, gender, age, language, religion, political 
rights over their personal data and are protected by 
opinion,  national  origin,  ethnic  origin,  social  origin, 
a  framework,  which  notably  foresees:  transparency; 
29economic or social condition of birth, or disability and  basis, including consent of data subjects, when required 
any other characteristics. by law. Standards for annotating datasets should be 
encouraged, including disaggregating data on gender 
75.  Member States should promote open data. In this regard, 
and other bases, so it can easily be determined how a 
Member States should consider reviewing their policies 
dataset is gathered and what properties it has.
and  regulatory  frameworks,  including  on  access  to 
information and open government to reflect AI-specific  77.  Member  States,  as  also  suggested  in  the  report  of 
requirements and promoting mechanisms, such as open  the  United  Nations  Secretary-General’s  High-level 
repositories for publicly funded or publicly held data and  Panel on Digital Cooperation, with the support of the 
source code and data trusts, to support the safe, fair, legal  United Nations and UNESCO, should adopt a digital 
and ethical sharing of data, among others. commons approach to data where appropriate, increase 
interoperability of tools and datasets and interfaces of 
76.  Member States should promote and facilitate the use 
systems  hosting  data,  and  encourage  private  sector 
of quality and robust datasets for training, development 
companies  to  share  the  data  they  collect  with  all 
and  use  of  AI  systems,  and  exercise  vigilance  in 
stakeholders, as appropriate, for research, innovation or 
overseeing their collection and use. This could, if possible 
public benefits. They should also promote public and 
and feasible, include investing in the creation of gold 
private efforts to create collaborative platforms to share 
standard  datasets,  including  open  and  trustworthy 
quality data in trusted and secured data spaces.
datasets, which are diverse, constructed on a valid legal 
POLICY AREA 4: DEVELOPMENT AND INTERNATIONAL COOPERATION
78.  Member  States  and  transnational  corporations  research  and  innovation  centres  and  networks  that 
should prioritize AI ethics by including discussions of  promote  greater  participation  and  leadership  of 
AI-related  ethical  issues  into  relevant  international,  researchers from LMICs and other countries, including 
intergovernmental and multi-stakeholder fora. LDCs, LLDCs and SIDS.
79.  Member States should ensure that the use of AI in areas  82.  Member States should promote AI ethics research by 
of  development  such  as  education,  science,  culture,  engaging  international  organizations  and  research 
communication and information, health care, agriculture  institutions, as well as transnational corporations, that can 
and  food  supply,  environment,  natural  resource  and  be a basis for the ethical use of AI systems by public and 
infrastructure  management,  economic  planning  and  private entities, including research into the applicability 
growth,  among  others,  adheres  to  the  values  and  of specific ethical frameworks in specific cultures and 
principles set forth in this Recommendation. contexts, and the possibilities to develop technologically 
feasible solutions in line with these frameworks.
80.  Member  States  should  work  through  international 
organizations  to  provide  platforms  for  international  83.  Member  States  should  encourage  international 
cooperation  on  AI  for  development,  including  by  cooperation and collaboration in the field of AI to bridge 
contributing expertise, funding, data, domain knowledge,  geo-technological lines. Technological exchanges and 
infrastructure,  and  facilitating  multi-stakeholder  consultations should take place between Member States 
collaboration  to  tackle  challenging  development  and their populations, between the public and private 
problems, especially for LMICs, in particular LDCs, LLDCs  sectors, and between and among the most and least 
and SIDS. technologically advanced countries in full respect of 
international law.
81.  Member States should work to promote international 
collaboration on AI research and innovation, including 
POLICY AREA 5: ENVIRONMENT AND ECOSYSTEMS
84.  Member  States  and  business  enterprises  should  for supporting the manufacturing of AI technologies, 
assess  the  direct  and  indirect  environmental  impact  and reduce the environmental impact of AI systems 
throughout the AI system life cycle, including, but not  and data infrastructures. Member States should ensure 
limited to, its carbon footprint, energy consumption and  compliance  of  all  AI  actors  with  environmental  law, 
the environmental impact of raw material extraction  policies and practices.
3085.  Member  States  should  introduce  incentives,  when  (e)  Enable  and  promote  the  mainstreaming  of 
needed and appropriate, to ensure the development  sustainable  infrastructure,  sustainable  business 
and adoption of rights-based and ethical AI-powered  models  and  sustainable  finance  for  sustainable 
solutions  for  disaster  risk  resilience;  the  monitoring,  development.
protection and regeneration of the environment and 
(f)  Detect pollutants or predict levels of pollution and 
ecosystems; and the preservation of the planet. These 
thus help relevant stakeholders identify, plan and 
AI  systems  should  involve  the  participation  of  local 
put in place targeted interventions to prevent and 
and indigenous communities throughout the life cycle 
reduce pollution and exposure.
of AI systems and should support circular economy 
type  approaches  and  sustainable  consumption  and 
86.  When choosing AI methods, given the potential data-
production patterns. Some examples include using AI 
intensive  or  resource-intensive  character  of  some  of 
systems, when needed and appropriate, to:
them and the respective impact on the environment, 
Member States should ensure that AI actors, in line with 
(a)  Support  the  protection,  monitoring  and 
the principle of proportionality, favour data, energy and 
management of natural resources.
resource-efficient  AI  methods.  Requirements  should 
(b)  Support the prediction, prevention, control and  be developed to ensure that appropriate evidence is 
mitigation of climate-related problems. available to show that an AI application will have the 
intended effect, or that safeguards accompanying an 
(c)  Support  a  more  efficient  and  sustainable  food 
AI application can support the justification for its use. 
ecosystem.
If  this  cannot  be  done,  the  precautionary  principle 
must be favoured, and in instances where there are 
(d)  Support the acceleration of access to and mass 
disproportionate negative impacts on the environment, 
adoption of sustainable energy.
AI should not be used.
31POLICY AREA 6: GENDER
87.  Member States should ensure that the potential for digital  90.  Member States should ensure that gender stereotyping 
technologies and artificial intelligence to contribute to  and  discriminatory  biases  are  not  translated  into  AI 
achieving gender equality is fully maximized, and must  systems, and instead identify and proactively redress 
ensure that the human rights and fundamental freedoms  these. Efforts are necessary to avoid the compounding 
of girls and women, and their safety and integrity are not  negative effect of technological divides in achieving 
violated at any stage of the AI system life cycle. Moreover,  gender  equality  and  avoiding  violence  such  as 
Ethical Impact Assessment should include a transversal  harassment, bullying or trafficking of girls and women 
gender perspective. and under-represented groups, including in the online 
domain.
88.  Member States should have dedicated funds from their 
public budgets linked to financing gender-responsive  91.  Member States should encourage female entrepreneurship, 
schemes, ensure that national digital policies include a  participation and engagement in all stages of an AI system 
gender action plan, and develop relevant policies, for  life cycle by offering and promoting economic, regulatory 
example, on labour education, targeted at supporting  incentives, among other incentives and support schemes, as 
girls and women to make sure they are not left out of  well as policies that aim at a balanced gender participation 
the digital economy powered by AI. Special investment  in AI research in academia, gender representation on digital 
in  providing  targeted  programmes  and  gender- and AI companies’ top management positions, boards of 
specific  language,  to  increase  the  opportunities  of  directors and research teams. Member States should ensure 
girls’ and women’s participation in science, technology,  that public funds (for innovation, research and technologies) 
engineering,  and  mathematics  (STEM),  including  are channelled to inclusive programmes and companies, 
information  and  communication  technologies  (ICT)  with clear gender representation, and that private funds are 
disciplines,  preparedness,  employability,  equal  career  similarly encouraged through affirmative action principles. 
development  and  professional  growth  of  girls  and  Policies  on  harassment-free  environments  should  be 
women, should be considered and implemented. developed and enforced, together with the encouragement 
of the transfer of best practices on how to promote diversity 
89.  Member States should ensure that the potential of AI 
throughout the AI system life cycle.
systems to advance the achievement of gender equality 
is realized. They should ensure that these technologies  92.  Member  States  should  promote  gender  diversity 
do  not  exacerbate  the  already  wide  gender  gaps  in AI research in academia and industry by offering 
existing in several fields in the analogue world, and  incentives to girls and women to enter the field, putting 
instead eliminate those gaps. These gaps include: the  in place mechanisms to fight gender stereotyping and 
gender wage gap; the unequal representation in certain  harassment  within  the  AI  research  community,  and 
professions  and  activities;  the  lack  of  representation  encouraging academic and private entities to share best 
at top management positions, boards of directors, or  practices on how to enhance gender diversity.
research teams in the AI field; the education gap; the 
93.  UNESCO can help form a repository of best practices 
digital and AI access, adoption, usage and affordability 
for incentivizing the participation of girls, women and 
gap; and the unequal distribution of unpaid work and of 
under-represented groups in all stages of the AI system 
the caring responsibilities in our societies.
life cycle.
POLICY AREA 7: CULTURE
94.  Member  States  are  encouraged  to  incorporate  AI  95.  Member  States  are  encouraged  to  examine  and 
systems,  where  appropriate,  in  the  preservation,  address the cultural impact of AI systems, especially 
enrichment,  understanding,  promotion,  management  natural  language  processing  (NLP)  applications  such 
and accessibility of tangible, documentary and intangible  as automated translation and voice assistants, on the 
cultural heritage, including endangered languages as well  nuances  of  human  language  and  expression.  Such 
as indigenous languages and knowledges, for example  assessments should provide input for the design and 
by introducing or updating educational programmes  implementation of strategies that maximize the benefits 
related to the application of AI systems in these areas,  from  these  systems  by  bridging  cultural  gaps  and 
where  appropriate,  and  by  ensuring  a  participatory  increasing human understanding, as well as addressing 
approach, targeted at institutions and the public. the negative implications such as the reduction of use, 
which could lead to the disappearance of endangered 
32languages, local dialects, and tonal and cultural variations  98.  Member States should engage technology companies 
associated with human language and expression. and other stakeholders to promote a diverse supply of 
and plural access to cultural expressions, and in particular 
96.  Member States should promote AI education and digital 
to ensure that algorithmic recommendation enhances 
training for artists and creative professionals to assess the 
the visibility and discoverability of local content.
suitability of AI technologies for use in their profession, 
and contribute to the design and implementation of  99.  Member  States  should  foster  new  research  at  the 
suitable AI technologies, as AI technologies are being  intersection between AI and intellectual property (IP), for 
used  to  create,  produce,  distribute,  broadcast  and  example to determine whether or how to protect with 
consume a variety of cultural goods and services, bearing  IP rights the works created by means of Al technologies. 
in mind the importance of preserving cultural heritage,  Member States should also assess how AI technologies 
diversity and artistic freedom. are affecting the rights or interests of IP owners, whose 
works are used to research, develop, train or implement 
97.  Member  States  should  promote  awareness  and 
AI applications.
evaluation of AI tools among local cultural industries and 
small and medium enterprises working in the field of  100. Member States should encourage museums, galleries, 
culture, to avoid the risk of concentration in the cultural  libraries and archives at the national level to use AI 
market. systems to highlight their collections and enhance their 
libraries,  databases  and  knowledge  base,  while  also 
providing access to their users.
POLICY AREA 8: EDUCATION AND RESEARCH
101. Member  States  should  work  with  international  102. Member  States  should  promote  the  acquisition  of 
organizations,  educational  institutions  and  private  “prerequisite  skills”  for  AI  education,  such  as  basic 
and  non-governmental  entities  to  provide  adequate  literacy, numeracy, coding and digital skills, and media 
AI literacy education to the public on all levels in all  and information literacy, as well as critical and creative 
countries in order to empower people and reduce the  thinking,  teamwork,  communication,  socio-emotional 
digital divides and digital access inequalities resulting  and AI ethics skills, especially in countries and in regions 
from the wide adoption of AI systems. or areas within countries where there are notable gaps in 
the education of these skills.
33103. Member  States  should  promote  general  awareness  should be considered when discussing the adoption of 
programmes  about  AI  developments,  including  on  AI technologies in education. AI systems used in learning 
data  and  the  opportunities  and  challenges  brought  should be subject to strict requirements when it comes 
about by AI technologies, the impact of AI systems on  to the monitoring, assessment of abilities, or prediction 
human rights and their implications, including children’s  of  the  learners’  behaviours.  AI  should  support  the 
rights. These programmes should be accessible to non- learning process without reducing cognitive abilities and 
technical as well as technical groups. without extracting sensitive information, in compliance 
with relevant personal data protection standards. The 
104. Member States should encourage research initiatives 
data  handed  over  to  acquire  knowledge  collected 
on the responsible and ethical use of AI technologies 
during the learner’s interactions with the AI system must 
in  teaching,  teacher  training  and  e-learning,  among 
not be subject to misuse, misappropriation or criminal 
other issues, to enhance opportunities and mitigate the 
exploitation, including for commercial purposes.
challenges and risks involved in this area. The initiatives 
should be accompanied by an adequate assessment of  105. Member States should promote the participation and 
the quality of education and impact on students and  leadership of girls and women, diverse ethnicities and 
teachers of the use of AI technologies. Member States  cultures,  persons  with  disabilities,  marginalized  and 
should  also  ensure  that  AI  technologies  empower  vulnerable people or people in vulnerable situations, 
students and teachers and enhance their experience,  minorities and all persons not enjoying the full benefits of 
bearing in mind that relational and social aspects and  digital inclusion, in AI education programmes at all levels, 
the value of traditional forms of education are vital in  as well as the monitoring and sharing of best practices in 
teacher-student and student-student relationships and  this regard with other Member States.
34106. Member States should develop, in accordance with their  109. Member  States  should  encourage  private  sector 
national education programmes and traditions, AI ethics  companies  to  facilitate  the  access  of  the  scientific 
curricula for all levels, and promote cross-collaboration  community  to  their  data  for  research,  especially  in 
between AI technical skills education and humanistic,  LMICs, in particular LDCs, LLDCs and SIDS. This access 
ethical and social aspects of AI education. Online courses  should conform to relevant privacy and data protection 
and digital resources of AI ethics education should be  standards.
developed  in  local  languages,  including  indigenous 
110. To  ensure  a  critical  evaluation  of  AI  research  and 
languages,  and  take  into  account  the  diversity  of 
proper  monitoring  of  potential  misuses  or  adverse 
environments, especially ensuring accessibility of formats 
effects, Member States should ensure that any future 
for persons with disabilities.
developments with regards to AI technologies should be 
107. Member States should promote and support AI research,  based on rigorous and independent scientific research, 
notably AI ethics research, including for example through  and promote interdisciplinary AI research by including 
investing in such research or by creating incentives for  disciplines other than science, technology, engineering 
the public and private sectors to invest in this area,  and  mathematics  (STEM),  such  as  cultural  studies, 
recognizing  that  research  contributes  significantly  education, ethics, international relations, law, linguistics, 
to the further development and improvement of AI  philosophy, political science, sociology and psychology.
technologies with a view to promoting international 
111. Recognizing  that  AI  technologies  present  great 
law  and  the  values  and  principles  set  forth  in  this 
opportunities  to  help  advance  scientific  knowledge 
Recommendation. Member States should also publicly 
and  practice,  especially  in  traditionally  model-driven 
promote the best practices of, and cooperation with, 
disciplines, Member States should encourage scientific 
researchers and companies who develop AI in an ethical 
communities to be aware of the benefits, limits and 
manner.
risks of their use; this includes attempting to ensure that 
108. Member States should ensure that AI researchers are  conclusions drawn from data-driven approaches, models 
trained in research ethics and require them to include  and  treatments  are  robust  and  sound.  Furthermore, 
ethical considerations in their designs, products and  Member States should welcome and support the role of 
publications, especially in the analyses of the datasets  the scientific community in contributing to policy and in 
they use, how they are annotated, and the quality and  cultivating awareness of the strengths and weaknesses of 
scope of the results with possible applications. AI technologies.
POLICY AREA 9: COMMUNICATION AND INFORMATION 
112. Member States should use AI systems to improve access  of content, and appeal mechanisms that allow users to 
to information and knowledge. This can include support  seek redress. 
to researchers, academia, journalists, the general public 
114. Member States should invest in and promote digital and 
and  developers,  to  enhance  freedom  of  expression, 
media and information literacy skills to strengthen critical 
academic and scientific freedoms, access to information, 
thinking and competencies needed to understand the 
and increased proactive disclosure of official data and 
use and implication of AI systems, in order to mitigate and 
information.
counter disinformation, misinformation and hate speech. 
113. Member States should ensure that AI actors respect  A  better  understanding  and  evaluation  of  both  the 
and promote freedom of expression as well as access  positive and potentially harmful effects of recommender 
to  information  with  regard  to  automated  content  systems should be part of those efforts.
generation,  moderation  and  curation.  Appropriate 
115. Member States should create enabling environments 
frameworks,  including  regulation,  should  enable 
for media to have the rights and resources to effectively 
transparency of online communication and information 
report on the benefits and harms of AI systems, and also 
operators and ensure users have access to a diversity of 
encourage media to make ethical use of AI systems in 
viewpoints, as well as processes for prompt notification to 
their operations.
the users on the reasons for removal or other treatment 
35POLICY AREA 10: ECONOMY AND LABOUR 
116. Member States should assess and address the impact  stakeholders, including workers and unions to ensure a 
of AI systems on labour markets and its implications for  fair transition for at-risk employees. This includes putting 
education requirements, in all countries and with special  in place upskilling and reskilling programmes, finding 
emphasis on countries where the economy is labour- effective  mechanisms  of  retaining  employees  during 
intensive. This can include the introduction of a wider  those  transition  periods,  and  exploring  “safety  net” 
range of “core” and interdisciplinary skills at all education  programmes for those who cannot be retrained. Member 
levels to provide current workers and new generations a  States  should  develop  and  implement  programmes 
fair chance of finding jobs in a rapidly changing market,  to research and address the challenges identified that 
and to ensure their awareness of the ethical aspects  could include upskilling and reskilling, enhanced social 
of AI systems. Skills such as “learning how to learn”,  protection, proactive industry policies and interventions, 
communication, critical thinking, teamwork, empathy,  tax benefits, new taxation forms, among others. Member 
and  the  ability  to  transfer  one’s  knowledge  across  States should ensure that there is sufficient public funding 
domains, should be taught alongside specialist, technical  to  support  these  programmes.  Relevant  regulations, 
skills, as well as low-skilled tasks. Being transparent about  such as tax regimes, should be carefully examined and 
what skills are in demand and updating curricula around  changed if needed to counteract the consequences of 
these are key. unemployment caused by AI-based automation.
117. Member States should support collaboration agreements  119. Member  States  should  encourage  and  support 
among governments, academic institutions, vocational  researchers to analyse the impact of AI systems on the 
education and training institutions, industry, workers’  local labour environment in order to anticipate future 
organizations and civil society to bridge the gap of skillset  trends and challenges. These studies should have an 
requirements to align training programmes and strategies  interdisciplinary approach and investigate the impact of 
with the implications of the future of work and the needs  AI systems on economic, social and geographic sectors, 
of industry, including small and medium enterprises.  as well as on human-robot interactions and human-
Project-based teaching and learning approaches for AI  human relationships, in order to advise on reskilling and 
should be promoted, allowing for partnerships between  redeployment best practices.
public institutions, private sector companies, universities 
120. Member  States  should  take  appropriate  steps  to 
and research centres.
ensure competitive markets and consumer protection, 
118. Member  States  should  work  with  private  sector  considering  possible  measures  and  mechanisms  at 
companies,  civil  society  organizations  and  other  national, regional and international levels, to prevent 
36abuse  of  dominant  market  positions,  including  by  human capacity and regulations, among other factors. AI 
monopolies, in relation to AI systems throughout their  actors developing AI systems in countries which have 
life cycle, whether these are data, research, technology,  established or adopted ethical standards on AI should 
or market. Member States should prevent the resulting  respect these standards when exporting these products, 
inequalities,  assess  relevant  markets  and  promote  developing or applying their AI systems in countries 
competitive markets. Due consideration should be given  where such standards may not exist, while respecting 
to LMICs, in particular LDCs, LLDCs and SIDS, which are  applicable international law and domestic legislation, 
more exposed and vulnerable to the possibility of abuses  standards and practices of these countries.
of market dominance as a result of a lack of infrastructure, 
POLICY AREA 11: HEALTH AND SOCIAL WELL-BEING
121. Member States should endeavour to employ effective  (e)  ensuring the human care and final decision of 
AI systems for improving human health and protecting  diagnosis  and  treatment  are  taken  always  by 
the right to life, including mitigating disease outbreaks,  humans while acknowledging that AI systems can 
while building and maintaining international solidarity to  also assist in their work; 
tackle global health risks and uncertainties, and ensure 
(f)  ensuring, where necessary, the review of AI systems 
that their deployment of AI systems in health care be 
by an ethical research committee prior to clinical 
consistent with international law and their human rights 
use.
law obligations. Member States should ensure that actors 
involved in health care AI systems take into consideration 
124. Member States should establish research on the effects 
the importance of a patient’s relationships with their 
and regulation of potential harms to mental health related 
family and with health care staff.
to AI systems, such as higher degrees of depression, 
anxiety, social isolation, developing addiction, trafficking, 
122. Member States should ensure that the development and 
radicalization and misinformation, among others.
deployment of AI systems related to health in general 
and mental health in particular, paying due attention to 
125. Member States should develop guidelines for human-
children and youth, is regulated to the effect that they are 
robot interactions and their impact on human-human 
safe, effective, efficient, scientifically and medically proven 
relationships, based on research and directed at the future 
and  enable  evidence-based  innovation  and  medical 
development of robots, and with special attention to the 
progress. Moreover, in the related area of digital health 
mental and physical health of human beings. Particular 
interventions, Member States are strongly encouraged to 
attention should be given to the use of robots in health 
actively involve patients and their representatives in all 
care and the care for older persons and persons with 
relevant steps of the development of the system. 
disabilities, in education, and robots for use by children, 
toy robots, chatbots and companion robots for children 
123. Member States should pay particular attention in 
and adults. Furthermore, assistance of AI technologies 
regulating  prediction,  detection  and  treatment 
should be applied to increase the safety and ergonomic 
solutions for health care in AI applications by:
use  of  robots,  including  in  a  human-robot  working 
(a)  ensuring oversight to minimize and mitigate bias; environment. Special attention should be paid to the 
possibility of using AI to manipulate and abuse human 
(b)  ensuring that the professional, the patient, caregiver 
cognitive biases.
or service user is included as a “domain expert” in 
the team in all relevant steps when developing the  126. Member  States  should  ensure  that  human-robot 
algorithms; interactions comply with the same values and principles 
that apply to any other AI systems, including human 
(c)  paying due attention to privacy because of the 
rights and fundamental freedoms, the promotion of 
potential need for being medically monitored and 
diversity, and the protection of vulnerable people or 
ensuring that all relevant national and international 
people in vulnerable situations. Ethical questions related 
data protection requirements are met;
to AI-powered systems for neurotechnologies and brain-
computer interfaces should be considered in order to 
(d)  ensuring effective mechanisms so that those whose 
preserve human dignity and autonomy.
personal data is being analysed are aware of and 
provide informed consent for the use and analysis 
127. Member  States  should  ensure  that  users  can  easily 
of their data, without preventing access to health 
identify  whether  they  are  interacting  with  a  living 
care;
being, or with an AI system imitating human or animal 
37characteristics, and can effectively refuse such interaction  attention to the psychological and cognitive impact that 
and request human intervention.  these systems can have on children and young people. 
This should be done using multiple norms, principles, 
128. Member  States  should  implement  policies  to  raise 
protocols,  disciplinary  approaches,  and  assessment 
awareness  about  the  anthropomorphization  of  AI 
of the modification of behaviours and habits, as well 
technologies  and  technologies  that  recognize  and 
as careful evaluation of the downstream cultural and 
mimic  human  emotions,  including  in  the  language 
societal impacts. Furthermore, Member States should 
used to mention them, and assess the manifestations, 
encourage research on the effect of AI technologies on 
ethical  implications  and  possible  limitations  of  such 
health system performance and health outcomes.
anthropomorphization, in particular in the context of 
robot-human interaction and especially when children  130. Member States, as well as all stakeholders, should put in 
are involved.  place mechanisms to meaningfully engage children and 
young people in conversations, debates and decision-
129. Member  States  should  encourage  and  promote 
making with regard to the impact of AI systems on their 
collaborative  research  into  the  effects  of  long-term 
lives and futures.
interaction of people with AI systems, paying particular 
38V.
 
Monitoring 
and evaluation
131. Member  States  should,  according  to  their  specific  (d)  strengthening the research- and evidence-based 
conditions,  governing  structures  and  constitutional  analysis of and reporting on policies regarding AI 
provisions,  credibly  and  transparently  monitor  and  ethics; 
evaluate policies, programmes and mechanisms related 
(e)  collecting and disseminating progress, innovations, 
to ethics of AI, using a combination of quantitative and 
research reports, scientific publications, data and 
qualitative  approaches.  To  support  Member  States, 
statistics regarding policies for AI ethics, including 
UNESCO can contribute by:
through existing initiatives, to support sharing best 
(a)  developing  a  UNESCO  methodology  for  Ethical  practices and mutual learning, and to advance the 
Impact Assessment (EIA) of AI technologies based  implementation of this Recommendation.
on rigorous scientific research and grounded in 
132. Processes for monitoring and evaluation should ensure 
international human rights law, guidance for its 
broad participation of all stakeholders, including, but 
implementation in all stages of the AI system life 
not limited to, vulnerable people or people in vulnerable 
cycle, and capacity-building materials to support 
situations. Social, cultural and gender diversity should be 
Member States’ efforts to train government officials, 
ensured, with a view to improving learning processes 
policy-makers and other relevant AI actors on EIA 
and strengthening the connections between findings, 
methodology;
decision-making,  transparency  and  accountability  for 
(b)  developing  a  UNESCO  readiness  assessment  results.
methodology to assist Member States in identifying 
133. In the interests of promoting best policies and practices 
their status at specific moments of their readiness 
related to ethics of AI, appropriate tools and indicators 
trajectory along a continuum of dimensions;
should be developed for assessing the effectiveness and 
(c)  developing a UNESCO methodology to evaluate ex  efficiency thereof against agreed standards, priorities and 
ante and ex post the effectiveness and efficiency  targets, including specific targets for persons belonging 
of the policies for AI ethics and incentives against  to  disadvantaged,  marginalized  populations,  and 
defined objectives; vulnerable people or people in vulnerable situations, as 
well as the impact of AI systems at individual and societal 
levels. The monitoring and assessment of the impact of 
39AI systems and related AI ethics policies and practices  134. In  particular,  Member  States  may  wish  to  consider 
should  be  carried  out  continuously  in  a  systematic  possible  mechanisms  for  monitoring  and  evaluation, 
way proportionate to the relevant risks. This should be  such as an ethics commission, AI ethics observatory, 
based on internationally agreed frameworks and involve  repository covering human rights-compliant and ethical 
evaluations of private and public institutions, providers  development of AI systems, or contributions to existing 
and programmes, including self-evaluations, as well as  initiatives by addressing adherence to ethical principles 
tracer studies and the development of sets of indicators.  across UNESCO’s areas of competence, an experience-
Data collection and processing should be conducted in  sharing mechanism, AI regulatory sandboxes, and an 
accordance with international law, national legislation  assessment  guide  for  all  AI  actors  to  evaluate  their 
on data protection and data privacy, and the values and  adherence to policy recommendations mentioned in 
principles outlined in this Recommendation. this document.
40VI.
 
Utilization and 
exploitation 
of the present 
Recommendation
135. Member States and all other stakeholders as identified  cooperating with all relevant national and international 
in this Recommendation should respect, promote and  governmental  and  non-governmental  organizations, 
protect  the  ethical  values,  principles  and  standards  as  well  as  transnational  corporations  and  scientific 
regarding AI that are identified in this Recommendation,  organizations, whose activities fall within the scope and 
and should take all feasible steps to give effect to its  objectives of this Recommendation. The development of 
policy recommendations. a UNESCO Ethical Impact Assessment methodology and 
the establishment of national commissions for the ethics 
136. Member States should strive to extend and complement 
of AI can be important instruments for this.
their own action in respect of this Recommendation, by 
41VII.
 
Promotion of 
the present 
Recommendation
137. UNESCO has the vocation to be the principal United  139. Even though, within UNESCO, the mandate to promote 
Nations  agency  to  promote  and  disseminate  this  and protect falls within the authority of governments 
Recommendation,  and  accordingly  will  work  in  and intergovernmental bodies, civil society will be an 
collaboration with other relevant United Nations entities,  important  actor  to  advocate  for  the  public  sector’s 
while respecting their mandate and avoiding duplication  interests and therefore UNESCO needs to ensure and 
of work. promote its legitimacy.
138. UNESCO,  including  its  bodies,  such  as  the  World 
Commission  on  the  Ethics  of  Scientific  Knowledge 
and Technology (COMEST), the International Bioethics 
Committee (IBC) and the Intergovernmental Bioethics 
Committee  (IGBC),  will  also  work  in  collaboration 
with  other  international,  regional  and  sub-regional 
governmental and non-governmental organizations.
42VIII.
 
Final 
provisions
140. This Recommendation needs to be understood as a 
whole, and the foundational values and principles are to 
be understood as complementary and interrelated.
141. Nothing in this Recommendation may be interpreted 
as replacing, altering or otherwise prejudicing States’ 
obligations  or  rights  under  international  law,  or  as 
approval for any State, other political, economic or social 
actor, group or person to engage in any activity or perform 
any act contrary to human rights, fundamental freedoms, 
human dignity and concern for the environment and 
ecosystems, both living and non-living.
43Social and Human Sciences Sector
7, place de Fontenoy
75352 Paris 07 SP France
  ai-ethics@unesco.org
  on.unesco.org/EthicsAI
Follow us 
@UNESCO #AI #HumanAI