ANNEX 
 
G20 AI Principles 1 
 
The G20 supports the Principles for responsible stewardship of Trustworthy AI in Section 1 
and takes note of the Recommendations in Section 2. 
 
Section 1: Principles for responsible stewardship of trustworthy AI 
 
1.1. Inclusive growth, sustainable development and well-being 
Stakeholders should proactively engage in responsible stewardship of trustworthy AI in pursuit of 
beneficial outcomes for people and the planet, such as augmenting human capabilities and 
enhancing creativity, advancing inclusion of underrepresented populations, reducing economic, 
social, gender and other inequalities, and protecting natural environments, thus invigorating 
inclusive growth, sustainable development and well-being. 
 
1.2. Human-centered values and fairness 
a) AI actors should respect the rule of law, human rights and democratic values, throughout the AI 
system lifecycle. These include freedom, dignity and autonomy, privacy and data protection, 
non-discrimination and equality, diversity, fairness, social justice, and internationally recognized 
labor rights. 
b) To this end, AI actors should implement mechanisms and safeguards, such as capacity for 
human determination, that are appropriate to the context and consistent with the state of art. 
 
1.3. Transparency and explainability 
AI Actors should commit to transparency and responsible disclosure regarding AI systems. To this 
end, they should provide meaningful information, appropriate to the context, and consistent with the 
state of art: 
i. to foster a general understanding of AI systems; 
ii. to make stakeholders aware of their interactions with AI systems, including in the workplace; 
iii. to enable those affected by an AI system to understand the outcome; and, 
iv. to enable those adversely affected by an AI system to challenge its outcome based on plain 
and easy-to-understand information on the factors, and the logic that served as the basis for the 
prediction, recommendation or decision. 
 
1.4. Robustness, security and safety 
a) AI systems should be robust, secure and safe throughout their entire lifecycle so that, in 
                                                   
1 This Annex draws from the OECD principles and recommendations. 
1 
 conditions of normal use, foreseeable use or misuse, or other adverse conditions, they function 
appropriately and do not pose unreasonable safety risk. 
b) To this end, AI actors should ensure traceability, including in relation to datasets, processes 
and decisions made during the AI system lifecycle, to enable analysis of the AI systemâ€™s 
outcomes and responses to inquiry, appropriate to the context and consistent with the state of 
art. 
c) AI actors should, based on their roles, the context, and their ability to act, apply a systematic 
risk management approach to each phase of the AI system lifecycle on a continuous basis to 
address risks related to AI systems, including privacy, digital security, safety and bias. 
 
1.5. Accountability 
AI actors should be accountable for the proper functioning of AI systems and for the respect of the 
above principles, based on their roles, the context, and consistent with the state of art. 
   
2 
  
Section 2: National policies and international co-operation for trustworthy AI 
 
2.1. Investing in AI research and development 
a) Governments should consider long-term public investment, and encourage private investment, 
in research and development, including inter-disciplinary efforts, to spur innovation in 
trustworthy AI that focus on challenging technical issues and on AI-related social, legal and 
ethical implications and policy issues. 
b) Governments should also consider public investment and encourage private investment in 
open datasets that are representative and respect privacy and data protection to support an 
environment for AI research and development that is free of inappropriate bias and to improve 
interoperability and use of standards. 
 
2.2. Fostering a digital ecosystem for AI 
Governments should foster the development of, and access to, a digital ecosystem for trustworthy 
AI. Such an ecosystem includes in particular digital technologies and infrastructure, and 
mechanisms for sharing AI knowledge, as appropriate. In this regard, governments should consider 
promoting mechanisms, such as data trusts, to support the safe, fair, legal and ethical sharing of 
data. 
 
2.3 Shaping an enabling policy environment for AI 
a) Governments should promote a policy environment that supports an agile transition from the 
research and development stage to the deployment and operation stage for trustworthy AI 
systems. To this effect, they should consider using experimentation to provide a controlled 
environment in which AI systems can be tested, and scaled-up, as appropriate. 
b) Governments should review and adapt, as appropriate, their policy and regulatory frameworks 
and assessment mechanisms as they apply to AI systems to encourage innovation and 
competition for trustworthy AI. 
 
2.4. Building human capacity and preparing for labor market transformation 
a) Governments should work closely with stakeholders to prepare for the transformation of the 
world of work and of society. They should empower people to effectively use and interact with 
AI systems across the breadth of applications, including by equipping them with the necessary 
skills. 
b) Governments should take steps, including through social dialogue, to ensure a fair transition for 
workers as AI is deployed, such as through training programs along the working life, support for 
those affected by displacement, and access to new opportunities in the labor market. 
3 
 c) Governments should also work closely with stakeholders to promote the responsible use of AI 
at work, to enhance the safety of workers and the quality of jobs, to foster entrepreneurship and 
productivity, and aim to ensure that the benefits from AI are broadly and fairly shared. 
 
2.5. International co-operation for trustworthy AI 
a) Governments, including developing countries and with stakeholders, should actively cooperate 
to advance these principles and to progress on responsible stewardship of trustworthy AI. 
b) Governments should work together in the OECD and other global and regional fora to foster 
the sharing of AI knowledge, as appropriate. They should encourage international, cross-
sectoral and open multi-stakeholder initiatives to garner long-term expertise on AI. 
c) Governments should promote the development of multi-stakeholder, consensus-driven global 
technical standards for interoperable and trustworthy AI. 
d) Governments should also encourage the development, and their own use, of internationally 
comparable metrics to measure AI research, development and deployment, and gather the 
evidence base to assess progress in the implementation of these principles. 
4 
 