Version 2 - For Public Discussion
ETHICALLY  
ALIGNED DESIGN
A Vision for Prioritizing Human Well-being 
with Autonomous and Intelligent SystemsThe IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Ethically Aligned Design – Version II 
Request for Input
Public comments are invited on the second version of Ethically Aligned Design: A Vision for 
Prioritizing Human Well-being with Autonomous and Intelligent Systems (A/IS) that encourages 
technologists to prioritize ethical considerations in the creation of such systems. 
This document has been created by committees of The IEEE Global Initiative on Ethics of 
Autonomous and Intelligent Systems, (“The IEEE Global Initiative”) composed of several hundred 
participants from six continents, who are thought leaders from academia, industry, civil society,  
policy and government in the related technical and humanistic disciplines to identify and find 
consensus on timely issues.
The document’s purpose is to: 
• Advance a public discussion about how we can establish ethical and social implementations
for intelligent and autonomous systems and technologies, aligning them to defined values and
ethical principles that prioritize human well-being in a given cultural context.
• Inspire the creation of Standards (IEEE P7000™ series and beyond) and associated
certification programs.
• Facilitate the emergence of national and global policies that align with these principles.
By inviting comments for Version 2 of Ethically Aligned Design, The IEEE Global Initiative provides the 
opportunity to bring together multiple voices from the related scientific and engineering communities 
with the general public to identify and find broad consensus on pressing ethical and social issues and 
candidate recommendations regarding development and implementations of these technologies.
Input about Ethically Aligned Design should be sent by email no later than 7 May 2018 and  
will be made publicly available at the website of The IEEE Global Initiative on Ethics of Autonomous 
and Intelligent Systems no later than 4 June 2018. Details on how to submit public comments  
are available via our Submission Guidelines.
Publicly available comments in response to this request for input will be considered by committees 
of The IEEE Global Initiative for potential inclusion in the final version of Ethically Aligned Design  
to be released in 2019. 
For further information, learn more at the website of The IEEE Global Initiative.
If you’re a journalist and would like to know more about The IEEE Global Initiative on Ethics 
of Autonomous and Intelligent Systems, please contact the IEEE-SA PR team. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License.The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Table of Contents
Executive Summary 
Introduction 2
The Mission of The IEEE Global Initiative  3-4
Who We Are  5 
Ethically Aligned Design, v2 (Overview)  6-9
Our Process  10-12 
How to Cite Ethically Aligned Design 13
Our Appreciation  14-16 
Disclaimers 17-19
Committees featured in EADv1 (with updated content)
General Principles  20-32 
Embedding Values into Autonomous Intelligent Systems  33-54
Methodologies to Guide Ethical Research and Design  55-72
Safety and Beneficence of Artificial General Intelligence 
(AGI) and Artificial Superintelligence (ASI)  73-82
Personal Data and Individual Access Control  83-112 
Reframing Autonomous Weapons Systems  113-130
Economics/Humanitarian Issues  131-145
Law   146-161
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 1The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Table of Contents
New Committees for EADv2 (with new content) 
Affective Computing  162-181 
Policy 182-192
Classical Ethics in A/IS  193-216
Mixed Reality in ICT  217-239
Well-being 240-263
Important Links 
• Website of The IEEE Global Initiative
• Full Listing of The IEEE Global Initiative Membership
• Ethically Aligned Design Version 1
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 2The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Introduction
As the use and impact of autonomous and intelligent systems (A/IS) become pervasive,  
we need to establish societal and policy guidelines in order for such systems to remain 
human-centric, serving humanity’s values and ethical principles. These systems have 
to behave in a way that is beneficial to people beyond reaching functional goals and 
addressing technical problems. This will allow for an elevated level of trust between  
people and technology that is needed for its fruitful, pervasive use in our daily lives. 
To be able to contribute in a positive, non-dogmatic way, we, the techno-scientific 
communities, need to enhance our self-reflection, we need to have an open and  
honest debate around our imaginary, our sets of explicit or implicit values, our  
institutions, symbols and representations.
Eudaimonia, as elucidated by Aristotle, is a practice that defines human well-being  
as the highest virtue for a society. Translated roughly as “flourishing,” the benefits  
of eudaimonia begin by conscious contemplation, where ethical considerations  
help us define how we wish to live. 
Whether our ethical practices are Western (Aristotelian, Kantian), Eastern (Shinto, 
Confucian), African (Ubuntu), or from a different tradition, by creating autonomous  
and intelligent systems that explicitly honor inalienable human rights and the beneficial 
values of their users, we can prioritize the increase of human well-being as our metric for 
progress in the algorithmic age. Measuring and honoring the potential of holistic economic 
prosperity should become more important than pursuing one-dimensional goals like 
productivity increase or GDP growth.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 2The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
The Mission of The IEEE Global  
Initiative on Ethics of Autonomous  
and Intelligent Systems
To ensure every stakeholder involved in the design and development of 
autonomous and intelligent systems is educated, trained, and empowered  
to prioritize ethical considerations so that these technologies are advanced  
for the benefit of humanity.  
By “stakeholder” we mean anyone involved in the research, design, manufacture, or 
messaging around intelligent and autonomous systems, including universities, organizations, 
governments, and corporations making these technologies a reality for society.
Our goal is that Ethically Aligned Design will provide insights and recommendations 
that provide a key reference for the work of technologists in the related fields of science 
and technology in the coming years. To achieve this goal, in the current version of 
Ethically Aligned Design (EAD2v2), we identify pertinent “Issues” and “Candidate 
Recommendations” we hope will facilitate the emergence of national and global  
policies that align with these principles.
The IEEE Global Initiative brings together several hundred participants from six continents, 
who are thought leaders from academia, industry, civil society, policy and government in the 
related technical and humanistic disciplines to identify and find consensus on timely issues.
A second goal of The IEEE Global Initiative is to provide recommendations for IEEE 
Standards based on Ethically Aligned Design. Ethically Aligned Design (v1 and v2) and 
members of The IEEE Global Initiative are the inspiration behind the suite of IEEE P7000™ 
Standards Working Groups that are free and open for anyone to join. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 3The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
For more information or to join any Working Group,  
please click on the links below: 
IEEE P7000™ - Model Process for Addressing Ethical Concerns During System Design
IEEE P7001™ - Transparency of Autonomous Systems
IEEE P7002™ - Data Privacy Process
IEEE P7003™ - Algorithmic Bias Considerations
IEEE P7004™ - Standard on Child and Student Data Governance
IEEE P7005™ - Standard for Transparent Employer Data Governance
IEEE P7006™ - Standard for Personal Data Artificial Intelligence (AI) Agent
IEEE P7007™ - Ontological Standard for Ethically Driven Robotics and Automation Systems
IEEE P7008™ - Standard for Ethically Driven Nudging for Robotic, Intelligent, and Automation Systems
IEEE P7009™ - Standard for Fail-Safe Design of Autonomous and Semi-Autonomous Systems
IEEE P7010™ - Wellbeing Metrics Standard for Ethical Artificial Intelligence and Autonomous Systems
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable.  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 4The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Who We Are
IEEE will make all versions of Ethically Aligned 
The IEEE Global Initiative on Ethics of  Design (EAD) available under the Creative 
Autonomous and Intelligent Systems (“The IEEE  Commons Attribution-Non-Commercial 3.0 
Global Initiative”) is a program of The Institute of  United States License.
Electrical and Electronics Engineers (“IEEE”), the 
world’s largest technical professional organization  Subject to the terms of that license, organizations 
dedicated to advancing technology for the benefit  or individuals can adopt aspects of this work at 
of humanity with over 420,000 members in  their discretion at any time. It is also expected 
more than 160 countries. that EAD content and subject matter will 
be selected for submission into formal IEEE 
The IEEE Global Initiative provides the  processes, including for standards development.
opportunity to bring together multiple voices 
in the related technological and scientific  The IEEE Global Initiative and EAD contribute to a 
communities to identify and find consensus   broader effort at IEEE to foster open, broad, and 
on timely issues. inclusive conversation about ethics in technology, 
known as the IEEE TechEthics™ program.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 5The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Ethically Aligned Design v2 — Overview
•  Transparency: Ensure they operate in a 
I. Purpose 
transparent manner
Intelligent and autonomous technical systems 
•  Awareness of misuse: Minimize the risks 
are specifically designed to reduce human 
of their misuse
intervention in our day-to-day lives. In so doing, 
these new fields are raising concerns about their 
impact on individuals and societies. Current  III. Objectives
discussions include advocacy for the positive 
impact, as well as warnings, based on the  Personal Data Rights and Individual 
potential harm to privacy, discrimination, loss  Access Control
of skills, economic impacts, security of critical 
A fundamental need is that people have the right 
infrastructure, and the long-term effects on 
to define access and provide informed consent 
social well-being. Because of their nature, the full 
with respect to the use of their personal digital 
benefit of these technologies will be attained only 
data. Individuals require mechanisms to help 
if they are aligned with our defined values and 
curate their unique identity and personal data  
ethical principles. We must therefore establish 
in conjunction with policies and practices that 
frameworks to guide and inform dialogue and 
make them explicitly aware of consequences 
debate around the non-technical implications  
resulting from the bundling or resale of their 
of these technologies.
personal information.
II. Goals
Well-being Promoted  
The ethical design, development, and  by Economic Effects
implementation of these technologies should be 
Through affordable and universal access to 
guided by the following General Principles:
communications networks and the Internet, 
intelligent and autonomous technical systems 
•  Human Rights: Ensure they do not infringe 
can be made available to and benefit populations 
on internationally recognized human rights
anywhere. They can significantly alter institutions 
•  Well-being: Prioritize metrics of well-being  and institutional relationships toward more 
in their design and use human-centric structures and they can benefit 
humanitarian and development issues resulting  
•  Accountability: Ensure that their  
in increased individual and societal well-being.
designers and operators are responsible  
and accountable
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 6The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Legal Frameworks for Accountability •  The logic and rules embedded in the system 
must be available to overseers thereof, if 
The convergence of intelligent systems and 
possible, and subject to risk assessments and 
robotics technologies has led to the development 
rigorous testing
of systems with attributes that simulate those 
of human beings in terms of partial autonomy,  •  The systems should generate audit trails 
ability to perform specific intellectual tasks, and  recording the facts and law supporting 
may even have a human physical appearance.  decisions and they should be amenable to 
The issue of the legal status of complex intelligent  third-party verification
and autonomous technical systems thus 
intertwines with broader legal questions regarding  •  The general public should know who is 
how to ensure accountability and allocate liability  making or supporting ethical decisions of 
when such systems cause harm. Some examples  such systems through investment
of general frameworks to consider include the 
following: Policies for Education and Awareness
•  Intelligent and autonomous technical systems  Effective policy addresses the protection and 
should be subject to the applicable regimes  promotion of safety, privacy, intellectual property 
of property law rights, human rights, and cybersecurity, as well as 
the public understanding of the potential impact 
•  Government and industry stakeholders  of intelligent and autonomous technical systems 
should identify the types of decisions and  on society. To ensure that they best serve the 
operations that should never be delegated to  public interest, policies should:
such systems and adopt rules and standards 
that ensure effective human control over  •  Support, promote, and enable internationally 
those decisions and how to allocate legal  recognized legal norms
responsibility for harm caused by them
•  Develop workforce expertise in related 
technologies
Transparency and Individual Rights
•  Attain research and development leadership
Although self-improving algorithms and data 
analytics can enable the automation of decision- •  Regulate to ensure public safety and 
making impacting citizens, legal requirements  responsibility
mandate transparency, participation, and 
•  Educate the public on societal impacts  
accuracy, including the following objectives:
of related technologies
•  Parties, their lawyers, and courts must have 
reasonable access to all data and information 
generated and used by such systems 
employed by governments and other  
state authorities
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 7The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Embedding Values  
IV. Foundations
into Autonomous Systems
If machines engage in human communities as 
Classical Ethics
quasi-autonomous agents, then those agents will 
By drawing from over two thousand years’ 
be expected to follow the community’s social and 
worth of classical ethics traditions, The IEEE 
moral norms. Embedding norms in such systems 
Global Initiative explores established ethics 
requires a clear delineation of the community 
systems, addressing both scientific and religious 
in which they are to be deployed. Further, even 
approaches, including secular philosophical 
within a particular community, different types of 
traditions, to address human morality in the 
technical embodiments will demand different 
digital age. Through reviewing the philosophical 
sets of norms. The first step is to identify the 
foundations that define autonomy and ontology, 
norms of the specific community in which the 
The IEEE Global Initiative addresses the alleged 
systems are to be deployed and, in particular, 
potential for autonomous capacity of intelligent 
norms relevant to the kinds of tasks that they  
technical systems, morality in amoral systems, 
are designed to perform.
and asks whether decisions made by amoral 
systems can have moral consequences. 
Methodologies to Guide Ethical 
Research and Design
Well-being Metrics
To create intelligent technical systems that 
For extended intelligence and automation 
enhance and extend human well-being and 
based thereupon to provably advance a specific 
freedom, value-based design methodologies 
benefit for humanity, there needs to be clear 
put human advancement at the core of 
indicators of that benefit. Common metrics of 
development of technical systems, in concert 
success include profit, occupational safety, and 
with the recognition that machines should serve 
fiscal health. While important, these metrics 
humans and not the other way around. System 
fail to encompass the full spectrum of well-
developers should employ value-based design 
being for individuals or society. Psychological, 
methodologies in order to create sustainable 
social, and environmental factors matter. Well-
systems that can be evaluated in terms of 
being metrics capture such factors, allowing the 
both social costs and also advantages that may 
benefits arising from technological progress to 
increase economic value for organizations.
be more comprehensively evaluated, providing 
opportunities to test for unintended negative 
consequences that could diminish human well-
being. Conversely, these metrics could help 
identify where intelligent technical systems would 
increase human well-being as well, providing new 
routes to societal and technological innovation. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 8The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
potentially self-improving technical systems 
V. Future Technology Concerns
involves considerable risk, either because of 
misuse or poor design. However, according 
Reframing Autonomous Weapons
to some theories, as systems approach and 
Autonomous systems designed to cause   surpass AGI, unanticipated or unintended system 
physical harm have additional ethical dimensions  behavior will become increasingly dangerous and 
as compared to both traditional weapons   difficult to correct. It is likely that not all AGI-
and/or autonomous systems not designed to  level architectures can be aligned with human 
cause harm. These ethical dimensions include,   interests, and as such, care should be taken 
at least, the following:  to determine how different architectures will 
perform as they become more capable.
•  Ensuring meaningful human control  
of weapons systems 
Affective Computing
•  Designing automated weapons with  
audit trails to help guarantee accountability  Affect is a core aspect of intelligence. Drives and 
and control  emotions such as anger, fear, and joy are often 
the foundations of actions throughout our life. 
•  Including adaptive and learning systems that 
To ensure that intelligent technical systems will 
can explain their reasoning and decisions 
be used to help humanity to the greatest extent 
to human operators in a transparent and 
possible in all contexts, artifacts participating in 
understandable way
or facilitating human society should not cause 
•  Training responsible human operators  
harm either by amplifying or damping human 
of autonomous systems who are  
emotional experience. Even the rudimentary 
clearly identifiable
versions of synthetic emotions already deployed 
•  Achieving behavior of autonomous functions  in some systems impact how they are perceived 
that is predictable to their operators by policy makers and the general public.
•  Ensuring that the creators of these 
technologies understanding the implications  Mixed Reality
of their work Mixed reality could alter our concepts of identity 
•  Developing professional ethical codes   and reality as these technologies become more 
to appropriately address the development   common in our work, education, social lives, and 
of autonomous systems intended to   commercial transactions. The ability for real-time 
cause harm personalization of this mixed-reality world raises 
ethical questions concerning the rights of the 
Safety and Beneficence of Alleged  individual and control over one’s multifaceted 
Artificial General Intelligence (AGI)  identity, especially as the technology moves  
and Artificial Superintelligence (ASI) from headsets to more subtle and integrated 
sensory enhancements. 
Similar to other powerful technologies, the 
development and use of intelligent and 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 9The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Our Process
To ensure greatest cultural relevance and  in accordance with the Mission Statement of 
intellectual rigor in our work, The IEEE Global  The IEEE Global Initiative. This voting process 
Initiative has been globally crowdsourcing  will be based on the consensus-based 
feedback for Versions 1 and 2 of Ethically   protocols provided by IEEE-SA.
Aligned Design. 
•  Create a rigorous methodology to best 
We released Ethically Aligned Design Version 1   incorporate feedback received from EADv1 
as a Request for Input on December of 2016   and EADv2, working to holistically consider 
and received over two hundred pages of in-depth  global and diversity-based considerations  
feedback about the draft. As a way to highlight  for content inclusion. 
insights inspired by the feedback we received, 
•  Use the glossary we have produced as a key 
Sara Mattingly-Jordan of The IEEE Global Initiative 
tool for synthesizing content for final version 
also wrote the report, Becoming a Leader in 
of EAD, unifying terms as much as possible. 
Global Ethics. 
We are releasing Ethically Aligned Design Version  Final Version of Ethically Aligned 
2 (EADv2) as a Request for Input once again  Design — Format and Goals
to gain further insights about the eight original 
The final version of Ethically Aligned Design will 
sections from EADv1, along with unique/new 
be made available in the following formats: 
feedback for the five new sections included  
in EADv2. 
•  Handbook. While specific formatting is 
still under consideration, the final version 
Next Steps of Ethically Aligned Design will feature 
“Recommendations” (versus “Candidate 
The IEEE Global Initiative is currently creating 
Recommendations”) for all existing and 
an organizational committee composed of 
future “Issues” voted on by Members of 
representatives of all our Committees and IEEE 
The IEEE Global Initiative. It is very likely 
P7000™ Working Groups to do the following 
the final version of EAD will not be broken 
in order to prepare the final version of Ethically 
into sections according to Committees (as 
Aligned Design to be released in 2019: 
with EADv1 and EADv2) but according to 
•  Create criteria for Committees to vote on all  themes or principles to be decided on by 
“Candidate Recommendations” becoming  the organizational committee mentioned 
“Recommendations” based on the General  above. While not an official IEEE position 
Principles of Ethically Aligned Design that are  statement, “Recommendations” will be 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 10The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
created to be easily utilized by technologists  based on aggregated feedback to all sections 
and policy makers focusing on autonomous  of EAD (Versions 1 and 2), we can standardize 
and intelligent systems design, usage, and  definitions that reflect a global and holistic set of 
governance. definitions to be implemented by all Committees 
in the final version of EAD. 
•  Educational materials. The IEEE Global 
Initiative would like to convert the handbook 
More Global Representation/Diversity
version of Ethically Aligned Design into an 
academically oriented book/educational  We received a great deal of feedback noting 
materials. Evergreen in nature, these would  that EADv1 was fairly “Western” in its cultural 
be targeted to academics, engineers, and  orientation. This makes sense, as the initial 100 
technologists looking for global guidance  members working on EADv1 where largely from 
to be used in university, post-grad, or  North America and the European Union. Since 
other educational settings where ethics in  the release of EADv1, however, we have: 
technology or the issues EAD comprises 
•  Added members from China, Korea, Japan, 
would be taught. 
Brazil, Mexico, the Russian Federation, Iran, 
Thailand, and Israel along with new people 
Incorporating Feedback 
from the United States and the European 
While it was our intention to directly accept or  Union. In addition to the 250 members of 
review all feedback we received for EADv1, we  the Initiative, there are also now more than 
were (happily) overwhelmed with the fantastic  400 global members in the IEEE P7000™ 
response we received. However, to most  Working Groups that EAD inspired. 
holistically include feedback from EADv1 and 
•  Supported the members translating  
EADv2 into our overall process we have created 
the Executive Summary of EADv1 into 
a Glossary and are working to increase more 
multiple languages. 
global representation and diversity in our work.  
Specifically:
•  Added our new “Classical Ethics in A/IS” 
Committee.
Glossary
•  Created the Becoming a Leader in Global 
We received a great deal of feedback on the 
Ethics report. 
need for aligned recommendations for key 
terms in Ethically Aligned Design. To that  •  Commissioned a report from our newer 
end, we created a Glossary Committee and  global members about the state of A/IS 
launched the first draft of our Glossary at the  Ethics in their regions. 
same time we released EADv2. Our goal is 
•  Created an Outreach Committee to help 
to refine our Glossary so that by mid-2018, 
identify and incorporate work being done 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 11The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
in A/IS ethics by women, people of color,  engineering, robotics, etc.) throughout Ethically 
students, and other groups representing the  Aligned Design, Version 2 to ensure the broadest 
full spectrum of society that we are hoping  application of ethical considerations in  
to positively influence with our work. We  the design of these technologies as possible.
are currently working with members of The 
Reboot Retreat, AI4ALL, and other leaders  How the Document Was Prepared
within IEEE to help us ensure that The IEEE 
This document was prepared using an open, 
Global Initiative and the final version of 
collaborative, and consensus building approach, 
Ethically Aligned Design are as holistically 
following the processes of the Industry 
representative and relevant as possible. 
Connections program, a program of the  
IEEE Standards Association.
Terminology Update
Industry Connections facilitates collaboration 
There is no need to use the term artificial 
among organizations and individuals as they 
intelligence in order to conceptualize and speak 
hone and refine their thinking on emerging 
of technologies and systems that are meant to 
technology issues, helping to incubate potential 
extend our human intelligence or be used in 
new standards activities and standards-related 
robotics applications. For this reason, we use  
products and services.
the term, autonomous and intelligent systems 
(or A/IS) in the course of our work. We chose 
to use this phrase encapsulating multiple 
fields (machine learning, intelligent systems 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 12The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
How to Cite Ethically Aligned Design
Please cite Version 2 of Ethically Aligned Design  Aligned Design: A Vision for Prioritizing Human 
in the following manner: Well-being with Autonomous and Intelligent 
Systems, Version 2. IEEE, 2017. http://standards.
The IEEE Global Initiative on Ethics of 
ieee.org/develop/indconn/ec/autonomous_
Autonomous and Intelligent Systems. Ethically 
systems.html.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 13The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Our Appreciation 
We wish to thank our Executive Committee   • Personal Data and Individual Access 
and Chair of The IEEE Global Initiative:  Control: Katryna Dow and John C. Havens
• Reframing Autonomous Weapons 
Executive Committee Officers Systems: Peter Asaro
Raja Chatila, Chair • Economics/Humanitarian Issues:  
Kay Firth-Butterfield and Raj Madhavan
Kay Firth-Butterfield, Vice-Chair
• Law: Kay Firth-Butterfield and Derek Jinks
John C. Havens, Executive Director 
• Affective Computing: Ronald C. Arkin and 
Executive Committee Members Joanna J. Bryson
Dr. Greg Adamson, Ronald C. Arkin, Virginia  • Classical Ethics in A/IS: Jared Bielby
Dignum, Danit Gal, Philip Hall, Malavika Jayaram, 
• Policy: Kay Firth-Butterfield and Philip Hall
Sven Koenig, Raj Madhavan, Richard Mallah, Hagit 
• Mixed Reality: Monique Morrow and Jay Iorio
Messer Yaron, AJung Moon, Monique Morrow, 
Francesca Rossi, Alan Winfield  • Well-being: Laura Musikanski and John C. 
Havens
Committee Chairs • Drafting: Kay Firth-Butterfield and Deven Desai
• General Principles: Alan Winfield and Mark  • Industry: Virginia Dignum and Malavika Jayaram  
Halverson
• Communications: Leanne Seeto  
• Embedding Values into Autonomous  and Mark Halverson
Intelligent Systems: Francesca Rossi and 
• Glossary: Sara M. Jordan
Bertram F. Malle  
• Outreach: Danit Gal
• Methodologies to Guide Ethical Research 
and Design: Raja Chatila and Corinne J.N. Cath
• Safety and Beneficence of Artificial 
General Intelligence (AGI) and Artificial 
Superintelligence (ASI): Malo Bourgon and 
Richard Mallah
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 14The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
We wish to express our appreciation for the  Japan’s Basic Rules for AI Research, Éthique de 
reports, organizations, and individuals that   la Recherche en Robotique (CERNA), Charta 
have contributed research and insights helping   der Digitalen Grundrechte der Europäischen 
to increase awareness around ethical issues   Union (Charter of the Digital Fundamental Rights 
in the realm of intelligent and autonomous  of the European Union), Telecommunications 
systems, including (but not limited to, and   Research Laboratory, “AI Network Kentōkai 
in no particular order):  Kaigi Hōkokusho 2016: AI Network no Eikyōto 
Risk — Chiren Shakai (WINS) no Jitsugen ni 
Reports Muketa Kadai” (AIネットワーク化検討会議 報
告書2016 ō公表－「AIネットワーク化の影響とリ
The Future of Life Institute’s Asilomar AI 
スク －智連社会（WINS(ウインズ)）の実現に向
Principles, The AI Now 2017 Report, Human 
けた課題－」) [The Conference on Networking 
Rights in the Robot Age Report from The 
among AIs Report (2016): Impacts and Risks 
Rathenau Instituut, Report of COMEST on 
of AI Networking Issues for the Realization of 
Robotics Ethics from UNESCO, The European 
Wisdom Network Society, (WINS)], Japanese 
Parliament’s Recommendations to the 
Ministry of Internal Affairs and Communications, 
Commission on Civil Law Rules on Robotics, 
The Information Technology Industry Council’s 
Artificial intelligence — The Consequences of 
AI Policy Principles, Intel’s Artificial Intelligence 
Artificial Intelligence on the (Digital) Single 
— The Public Policy Opportunity, IEEE European 
Market, Production, Consumption, Employment 
Public Policy Initiative’s position statement, 
and Society report from the European Economic 
Artificial Intelligence: Calling on Policy Makers 
and Social Committee (Rapporteur: Catelijne 
to Take a Leading Role in Setting a Long Term 
MULLER), OECD’s report, Going Digital: Making 
AI Strategy, IEEE-USA’s position statement on 
the Transformation Work for Growth and Well-
Artificial Intelligence Research, Development and 
Being, USACM’s Statement on Algorithmic 
Regulation, The IEEE Global Initiative’s Prioritizing 
Transparency and Accountability, Guide to the 
Human Well-being in the Age of Artificial 
Ethical Design and Application of Robots and 
Intelligence.
Robotic Systems (British Standards Institute), 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 15The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Organizations People
The Association for the Advancement of Artificial 
We would like to warmly recognize the leadership 
Intelligence and their formative work on AI Ethics, 
and constant support of The IEEE Global Initiative 
The Future of Life Institute, The Partnership on 
by Dr. Ing. Konstantinos Karachalios, Managing 
AI to Benefit People and Society, The Foundation 
Director of the IEEE Standards Association and a 
for Responsible Robotics, AI & Society, Machine 
member of the IEEE Management Council. 
Intelligence Research Institute, The International 
Center for Information Ethics, The African Center  We would especially like to thank Eileen M. Lach, 
of Excellence for Information Ethics, The 4TU  the IEEE General Counsel and Chief Compliance 
Center for Ethics and Technology, The Center  Officer, who invested her time and expertise in 
for the Study of Existential Risk, The Leverhulme  fully reviewing  this entire document, with the 
Center for the Future of Intelligence, The Future  heartfelt conviction that there is a pressing need 
of Humanity Institute, The Japanese Society  to focus the global community on highlighting 
for Artificial Intelligence, The Association for  ethical considerations in the development of 
Computing Machinery, Future Advocacy, ACM  autonomous and intelligent systems. 
Special Interest Group on Artificial Intelligence, 
Special thanks to Dr. Peter S. Brooks for his 
The World Economic Forum’s Global Future 
contributions to the Overview of EADv2.
Council of Artificial Intelligence and Robotics, 
The Digital Asia Hub, The AI Initiative, The Open 
Roboethics Institute, The Dalai Lama Center for  Thank You to Our Members  
Ethics and Transformative Values at MIT, The  and IEEE Team 
Ethics Initiative at MIT Media Lab, The IEEE- Our progress and the ongoing positive influence 
USA Government Relations Council Artificial  of this work is due to the volunteer experts 
Intelligence Committee, The IEEE Robotics  serving on our Committees and IEEE P7000™ 
and Automation Society Committee on Robot  Standards Working Groups, along with the IEEE 
Ethics, The IEEE Robotics and Automation  staff who support our efforts. Thank you for 
Society, The IEEE Society on Social Implications  your dedication toward defining, designing, and 
of Technology, The IEEE Computer Society, The  inspiring the ethical PRINCIPLES and STANDARDS 
IEEE Computational Intelligence Society, The IEEE  that will ensure that intelligent and autonomous 
Systems, Man and Cybernetics Society, The IEEE  systems and the technologies associated 
Symbiotic Autonomous Systems Initiative.  therewith will positively benefit humanity. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 16The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Disclaimers
Ethically Aligned Design is not a code of conduct  This is the second version of Ethically Aligned 
or a professional code of ethics. Engineers and  Design. Where individuals are listed in a 
technologists have well-established codes,  Committee it indicates only that they are 
and we wish to respectfully recognize the  Members of that Committee. Committee 
formative precedents surrounding issues of  Members may not have achieved final 
ethics and safety and the professional values  concurrence on content in this document 
these codes represent. These codes provide the  because of its versioning format and the 
broad framework for the more focused domain  concurrence-building process of The IEEE Global 
addressed in this document, and it is our hope  Initiative. Content listed by Members in this  
that the inclusive, consensus-building process  or future versions is not an endorsement, implied 
around its design will contribute unique value to  or otherwise, until formally stated as such.
technologists and society as a whole.
A Note Regarding Candidate 
This document is also not a position, or policy 
Recommendations in This Document
statement, or formal report of IEEE or any 
other organization with which is affiliated. It is  Ethically Aligned Design is being created 
intended to be a working reference tool created  via multiple versions that are being iterated 
in an inclusive process by those in the relevant  over the course of two to three years. The 
scientific and engineering communities prioritizing  IEEE Global Initiative is following a specific 
ethical considerations in their work. concurrence-building process where members 
contributing content are proposing candidate 
recommendations so as not to imply these are 
A Note on Affiliations Regarding 
final recommendations at this time.
Members of The Initiative
The language and views expressed in Ethically 
Our Membership
Aligned Design reflect the individuals who 
created content for each section of this  The IEEE Global Initiative currently has more than 
document. The language and views expressed  250 experts from all but one continent involved 
in this document do not necessarily reflect  in our work, and we are eager for new voices and 
the positions taken by the universities or  perspectives to join our work.
organizations to which these individuals belong, 
and should in no way be considered any form  
of endorsement, implied or otherwise, from 
these institutions.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 17The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
Copyright, Trademarks,   Notice and Disclaimer of Liability 
and Disclaimers Concerning the Use of IEEE-SA Industry 
Connections Documents
IEEE believes in good faith that the information 
in this publication is accurate as of its publication  This IEEE Standards Association (“IEEE-SA”) 
date; such information is subject to change  Industry Connections publication (“Work”) is not 
without notice. IEEE is not responsible for any  a consensus standard document. Specifically, this 
inadvertent errors. document is NOT AN IEEE STANDARD. Information 
contained in this Work has been created by, or 
The Institute of Electrical and Electronics 
obtained from, sources believed to be reliable, 
Engineers, Incorporated
and reviewed by members of the IEEE-SA Industry 
3 Park Avenue, New York, NY 10016-5997,   USA Connections activity that produced this Work. 
IEEE and the IEEE-SA Industry Connections 
Copyright © 2017 by The Institute of Electrical 
activity members expressly disclaim all warranties 
and Electronics Engineers, Incorporated
(express, implied, and statutory) related to this 
Work, including, but not limited to, the warranties 
Published December 2017
of: merchantability; fitness for a particular purpose; 
Printed in the United States of America. non-infringement; quality, accuracy, effectiveness, 
currency, or completeness of the Work or content 
IEEE is a registered trademark owned by The 
within the Work. In addition, IEEE and the IEEE-
Institute of Electrical and Electronics Engineers, 
SA Industry Connections activity members 
Incorporated.
disclaim any and all conditions relating to: results; 
and workmanlike effort. This IEEE-SA Industry 
PDF:     ISBN 978-0-7381-xxxx-x     STDVxxxxx
Connections document is supplied “AS IS”  
Print:    ISBN 978-0-7381-xxxx-x     STDPDVxxxxx  and “WITH ALL FAULTS.”
IEEE prohibits discrimination, harassment,   Although the IEEE-SA Industry Connections 
and bullying. For more information, visit   activity members who have created this Work 
http://www.ieee.org/web/aboutus/whatis/  believe that the information and guidance 
policies/p9-26.html given in this Work serve as an enhancement 
to users, all persons must rely upon their own 
This work is made available under the Creative 
skill and judgment when making use of it. IN 
Commons Attribution Non-Commercial License.
NO EVENT SHALL IEEE OR IEEE-SA INDUSTRY 
CONNECTIONS ACTIVITY MEMBERS BE LIABLE 
To order IEEE Press Publications,  
FOR ANY ERRORS OR OMISSIONS OR DIRECT, 
call 1-800-678-IEEE.
INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, 
Find IEEE standards and standards-related  OR CONSEQUENTIAL DAMAGES (INCLUDING, 
product listings at: standards.ieee.org BUT NOT LIMITED TO: PROCUREMENT OF 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 18The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Executive Summary
SUBSTITUTE GOODS OR SERVICES; LOSS  or validity of any patent rights in connection 
OF USE, DATA, OR PROFITS; OR BUSINESS  therewith. IEEE is not responsible for identifying 
INTERRUPTION) HOWEVER CAUSED AND  patent rights for which a license may be required, 
ON ANY THEORY OF LIABILITY, WHETHER  or for conducting inquiries into the legal validity 
IN CONTRACT, STRICT LIABILITY, OR TORT  or scope of patents claims. Users are expressly 
(INCLUDING NEGLIGENCE OR OTHERWISE)  advised that determination of the validity of any 
ARISING IN ANY WAY OUT OF THE USE OF   patent rights, and the risk of infringement of 
THIS WORK, EVEN IF ADVISED OF THE  such rights, is entirely their own responsibility. 
POSSIBILITY OF SUCH DAMAGE AND  No commitment to grant licenses under patent 
REGARDLESS OF WHETHER SUCH   rights on a reasonable or non-discriminatory basis 
DAMAGE WAS FORESEEABLE. has been sought or received from any rights 
holder. The policies and procedures under which 
Further, information contained in this Work 
this document was created can be viewed at 
may be protected by intellectual property rights 
standards.ieee.org/about/sasb/iccom/.
held by third parties or organizations, and the 
use of this information may require the user to  This Work is published with the understanding 
negotiate with any such rights holders in order  that IEEE and the IEEE-SA Industry Connections 
to legally acquire the rights to do so, and such  activity members are supplying information 
rights holders may refuse to grant such rights.  through this Work, not attempting to render 
Attention is also called to the possibility that  engineering or other professional services.  
implementation of any or all of this Work may  If such services are required, the assistance  
require use of subject matter covered by patent  of an appropriate professional should be sought. 
rights. By publication of this Work, no position  IEEE is not responsible for the statements and 
is taken by IEEE with respect to the existence  opinions advanced in this Work. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 19The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
The General Principles Committee seeks to articulate high-level ethical concerns that  
apply to all types of autonomous and intelligent systems (A/IS*), regardless of whether  
they are physical robots (such as care robots or driverless cars) or software systems  
(such as medical diagnosis systems, intelligent personal assistants, or algorithmic chat bots).  
We are motivated by a desire to create ethical principles for A/IS that:
1.  Embody the highest ideals of human beneficence as a superset of Human Rights. 
2.  Prioritize benefits to humanity and the natural environment from the use of A/IS.  
Note that these should not be at odds — one depends on the other. Prioritizing human 
well-being does not mean degrading the environment.
3.  Mitigate risks and negative impacts, including misuse, as A/IS evolve as socio-technical 
systems. In particular by ensuring A/IS are accountable and transparent.
It is our intention that by identifying issues and drafting recommendations these principles 
will serve to underpin and scaffold future norms and standards within a framework of 
ethical governance.
We have identified principles created by our Committee as well as aggregated principles 
reflected from other Committees of The IEEE Global Initiative. Therefore, readers should 
note that some general principles are reiterated and elaborated by other committees, as 
appropriate to the specific concerns of those committees. We have purposefully structured 
our Committee and this document in this way to provide readers with a broad sense  
of the themes and ideals reflecting the nature of ethical alignment for these technologies  
as an introduction to our overall mission and work.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 20The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
The following provides high-level guiding principles for potential solutions-by-design 
whereas other Committee sections address more granular issues regarding specific 
contextual, cultural, and pragmatic questions of their implementation. 
*The acronym A/IS is shorthand for Autonomous and Intelligent Systems. When represented in this way, it refers to the 
overlapping concerns about the design, development, deployment, decommissioning, and adoption of autonomous or intelligent 
software when installed into other software and/or hardware systems that are able to exercise independent reasoning,  
decision-making, intention forming, and motivating skills according to self-defined principles.
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 21The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
Principle 1 — Human Rights 
3.  If an A/IS causes harm it must always  
be possible to discover the root cause,  
Issue: 
by assuring traceability for said harm  
How can we ensure that   (see also Principle 4 — Transparency).
A/IS do not infringe upon  
While their interpretation may change over time, 
human rights?
human rights as defined by international law, 
provide a unilateral basis of creating any A/IS 
system as they affect humans, their emotions, 
Background data, or agency. While the direct coding of human 
rights in A/IS may be difficult or impossible based 
Human benefit is an important goal of A/IS,  
on contextual use, newer guidelines from The 
as is respect for human rights set out, inter alia, 
United Nations, such as the Ruggie principles, 
in The Universal Declaration of Human Rights, 
provide methods to pragmatically implement 
the International Covenant for Civil and Political 
human rights ideals within business or corporate 
Rights, the Convention on the Rights of the 
contexts that could be adapted for engineers and 
Child, Convention on the Elimination of all forms 
technologists. In this way technologists can take 
of Discrimination against Women, Convention 
account of rights in the way A/IS are operated, 
on the Rights of Persons with Disabilities, and 
tested, validated, etc. In short, human rights 
the Geneva Conventions. Such rights need to 
should be part of the ethical risk assessment  
be fully taken into consideration by individuals, 
of A/IS. 
companies, professional bodies, research 
institutions, and governments alike to reflect  
the following concerns: Candidate Recommendations
To best honor human rights, society must assure 
1.  A/IS should be designed and operated in  
the safety and security of A/IS so that they are 
a way that both respects and fulfills human 
designed and operated in a way that benefits 
rights, freedoms, human dignity, and cultural 
humans:
diversity.
1.  Governance frameworks, including standards 
2.  A/IS must be verifiably safe and secure 
and regulatory bodies, should be established 
throughout their operational lifetime.
to oversee processes assuring that the 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 22The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
use of A/IS does not infringe upon human  •  The International Covenant on Economic, 
rights, freedoms, dignity, and privacy, and of  Social and Cultural Rights, 1966.
traceability to contribute to the building  
•  The International Convention on 
of public trust in A/IS.
the Elimination of All Forms of Racial 
2.  A way to translate existing and forthcoming  Discrimination, 1965.
legal obligations into informed policy and 
•  The Convention on the Rights of the Child.
technical considerations is needed. Such  
a method should allow for differing cultural 
•  The Convention on the Elimination of All 
norms as well as legal and regulatory 
Forms of Discrimination against Women, 
frameworks.
1979.
3.  For the foreseeable future, A/IS should 
•  The Convention on the Rights of Persons 
not be granted rights and privileges equal 
with Disabilities, 2006.
to human rights: A/IS should always be 
subordinate to human judgment and control. •  The Geneva Conventions and additional 
protocols, 1949.
Further Resources
•  IRTF’s Research into Human Rights Protocol 
The following documents/organizations are  Considerations.
provided both as references and examples of  
•  The UN Guiding Principles on Business 
the types of work that can be emulated, adapted, 
and Human Rights, 2011.
and proliferated, regarding ethical best practices 
around A/IS to best honor human rights:
•  For an example of a guide on how to conduct  
an ethical risk assessment see British Standards 
•  The Universal Declaration of Human Rights, 
Institute BS8611:2016, Guide to the Ethical 
1947.
Design and Application of Robots and 
•  The International Covenant on Civil and  Robotic Systems.
Political Rights, 1966.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 23The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
Principle 2 — Prioritizing Well-being 
Well-being, for the purpose of The IEEE Global 
Initiative, is defined as encompassing human 
Issue: 
satisfaction with life and the conditions of life as 
Traditional metrics of prosperity  well as an appropriate balance between positive 
do not take into account the   and negative affect. This definition is based on 
the Organization for Economic Co-Operation and 
full effect of A/IS technologies  
Development’s (OECD) Guidelines on Measuring 
on human well-being.
Subjective Well-being that notes, “Being able to 
measure people’s quality of life is fundamental 
when assessing the progress of societies. There 
Background is now widespread acknowledgement that 
measuring subjective well-being is an essential 
A focus on creating ethical and responsible 
part of measuring quality of life alongside other 
AI has been increasing among technologists 
social and economic dimensions.” Data is 
in the past 12 to 16 months. Key issues of 
also currently being gathered in governments, 
transparency, accountability, and algorithmic 
businesses, and other institutions using 
bias are being directly addressed for the 
scientifically valid measurements of well-being. 
design and implementation of A/IS. While 
Since modern societies are largely constituted  
this is an encouraging trend, a key question 
of A/IS users, we believe these considerations  
facing technologists today is beyond designing 
to be relevant for A/IS developers.
responsible A/IS. That question is, What are  
the specific metrics of societal success for  
It is widely agreed that GDP is at best incomplete, 
“ethical AI” once released to the world? 
and at worst misleading, as a metric of 
true prosperity for society at large and A/IS 
For A/IS technologies to provably advance  
technologies (as noted in The Oxford Handbook 
benefit for humanity, we need to be able 
of Well-Being and Public Policy). Although the 
to define and measure the benefit we wish 
concerns regarding GDP reflect holistic aspects  
to increase. Avoiding negative unintended 
of society versus the impact of any one 
consequences and increasing value for customers 
technology, they reflect the lack of universal 
and society (today measured largely by gross 
usage of well-being indicators for A/IS. A/IS 
domestic product (GDP), profit, or consumption 
undoubtedly hold positive promise for society. 
levels) are often the only indicators utilized  
But beyond the critical importance of designing 
in determining success for A/IS. 
and manufacturing these technologies in an 
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 24The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
ethically driven and responsible manner is  fiscal metrics of success, we also risk expediting 
the seminal question of determining the key  negative and irreversible harms to our planet  
performance indicators (KPIs) of their success  and population. 
once introduced into society.
Candidate Recommendation
A/IS technologies can be narrowly conceived 
from an ethical standpoint; be legal, profitable,  A/IS should prioritize human well-being as an 
and safe in their usage; and yet not positively  outcome in all system designs, using the best 
contribute to human well-being. This means  available, and widely accepted, well-being metrics 
technologies created with the best intentions,   as their reference point.
but without considering well-being metrics,  
can still have dramatic negative consequences   Further Resources
on people’s mental health, emotions, sense  
•  IEEE P7010™, Well-being Metrics Standard 
of themselves, their autonomy, their ability  
for Ethical AI and Autonomous Systems.
to achieve their goals, and other dimensions  
of well-being. •  The Measurement of Economic Performance 
and Social Progress (2009) now commonly 
Nonetheless, quantitative indicators of individual 
referred to as “The Stiglitz Report,” 
well-being should be introduced with caution, 
commissioned by the then President of  
as they may provoke in users an automatic urge 
the French Republic. From the report: “…
for numerical optimization. While this tendency 
the time is ripe for our measurement system 
is theoretically unavoidable, efforts should be 
to shift emphasis from measuring economic 
invested in guaranteeing that it will not flatten the 
production to measuring people’s well-being 
diversity of human experience. The A/IS using 
… emphasizing well-being is important 
quantitative indicators for health or happiness 
because there appears to be an increasing 
should therefore develop and implement 
gap between the information contained  
measures for maintaining full human autonomy 
in aggregate GDP data and what counts  
of their users.
for common people’s well-being.” 
In conclusion, it is widely agreed that de facto 
•  Organisation for Economic Co-Operation 
metrics regarding safety and fiscal health do not 
& Development, OECD Guidelines for 
encompass the full spectrum of well-being for 
Measuring Subjective Well-being. Paris: 
individuals or society. By not elevating additional 
OECD, 2013.
environmental and societal indicators as pillars 
of success for A/IS, we risk minimizing the  •  Beyond GDP (European Commission)  
positive and holistic impact for humanity of these  From the site: “The Beyond GDP initiative  
technologies. Where personal, environmental,  is about developing indicators that are 
or social factors are not prioritized as highly as 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 25The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
as clear and appealing as GDP, but more  •  The International Panel on Social Progress, 
inclusive of environmental and social aspects  Social Justice, Well-Being and Economic 
of progress.” Organization.
•  Global Dialogue for Happiness, part of   •  Veenhoven, R. World Database of Happiness. 
the annual World Government Summit,  Rotterdam, The Netherlands: Erasmus 
February 11, 2017. University. 
•  Organization for Economic Co-Operation   •  Royal Government of Bhutan. The Report 
and Development, OECD’s Better Life Index. of the High-Level Meeting on Wellbeing 
and Happiness: Defining a New Economic 
•  New Economics Foundation, The Happy 
Paradigm. New York: The Permanent Mission 
Planet Index.
of the Kingdom of Bhutan to the United 
Nations, 2012.
•  Redefining Progress, Genuine Progress 
Indicator.
•  See also Well-being Section in Ethically 
Aligned Design, Version 2.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 26The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
Principle 3 — Accountability
Candidate Recommendations
Issue:  To best address issues of responsibility and 
accountability:
How can we assure that 
designers, manufacturers,  1.  Legislatures/courts should clarify issues 
of responsibility, culpability, liability, and 
owners, and operators of A/IS 
accountability for A/IS where possible during 
are responsible and accountable?
development and deployment (so that 
manufacturers and users understand their 
rights and obligations).
Background
2.  Designers and developers of A/IS should 
The programming, output, and purpose of A/IS 
remain aware of, and take into account when 
are often not discernible by the general public. 
relevant, the diversity of existing cultural 
Based on the cultural context, application, 
norms among the groups of users of these 
and use of A/IS, people and institutions need 
A/IS.
clarity around the manufacture and deployment 
of these systems to establish responsibility  3.  Multi-stakeholder ecosystems should be 
and accountability, and avoid potential harm.  developed to help create norms (which can 
Additionally, manufacturers of these systems  mature to best practices and laws) where 
must be able to provide programmatic-level  they do not exist because A/IS-oriented 
accountability proving why a system operates in  technology and their impacts are too new 
certain ways to address legal issues of culpability,  (including representatives of civil society, 
if necessary apportion culpability among several  law enforcement, insurers, manufacturers, 
responsible designers, manufacturers, owners,  engineers, lawyers, etc.).
and/or operators, to avoid confusion or fear 
4.  Systems for registration and record-keeping 
within the general public.
should be created so that it is always possible 
Note that accountability is enhanced with  to find out who is legally responsible for  
transparency, thus this principle is closely linked  a particular A/IS. Manufacturers/operators/ 
with Principle 4 — Transparency.  
 
   
   
   
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 27The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
owners of A/IS should register key, high-level  Further Resources
parameters, including:
•  Shneiderman, B. “Human Responsibility 
•  Intended use for Autonomous Agents.” IEEE Intelligent 
Systems 22, no. 2, (2007): 60–61.
•  Training data/training environment  
(if applicable) •  Matthias, A. “The Responsibility Gap: 
Ascribing Responsibility for the Actions of 
•  Sensors/real world data sources Learning Automata.” Ethics and Information 
Technology 6, no. 3 (2004): 175–183.
•  Algorithms
•  Hevelke A., and J. Nida-Rümelin. 
•  Process graphs
“Responsibility for Crashes of Autonomous 
•  Model features (at various levels) Vehicles: An Ethical Analysis.” Science  
and Engineering Ethics 21, no. 3 (2015): 
•  User interfaces
619–630.
•  Actuators/outputs
•  An example of good practice (in relation  
to Candidate Recommendation #3) can  
•  Optimization goal/loss function/reward 
be found in Sciencewise — the U.K. national 
function
center for public dialogue in policy-making 
involving science and technology issues.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 28The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
Principle 4 — Transparency
At the same time, the complexity of A/IS 
technology will make it difficult for users of 
Issue: 
those systems to understand the capabilities 
How can we ensure that A/IS   and limitations of the AI systems that they 
are transparent? use, or with which they interact. This opacity, 
combined with the often-decentralized manner 
in which it is developed, will complicate efforts 
to determine and allocate responsibility when 
Background
something goes wrong with an AI system. Thus, 
A key concern over autonomous systems is  lack of transparency both increases the risk and 
that their operation must be transparent to a  magnitude of harm (users not understanding the 
wide range of stakeholders for different reasons  systems they are using) and also increases the 
(noting that the level of transparency will  difficulty of ensuring accountability (see Principle 
necessarily be different for each stakeholder).  3— Accountability).
Stated simply, transparent A/IS are ones in which 
it is possible to discover how and why a system  Transparency is important to each stakeholder 
made a particular decision, or in the case of a  group for the following reasons:
robot, acted the way it did. Note that here the 
1.  For users, transparency is important  
term transparency also addresses the concepts  
because it provides a simple way for them  
of traceability, explicability, and interpretability.
to understand what the system is doing  
A/IS will be performing tasks that are far more  and why.
complex and have more effect on our world 
2.  For validation and certification of an A/IS, 
than prior generations of technology. This reality 
transparency is important because it exposes 
will be particularly acute with systems that 
the system’s processes and input data  
interact with the physical world, thus raising the 
to scrutiny.
potential level of harm that such a system could 
cause. For example, some A/IS already have  3.  If accidents occur, the AS will need to be 
real consequences to human safety or well- transparent to an accident investigator, so the 
being, such as medical diagnosis AI systems, or  internal process that led to the accident can 
driverless car autopilots; systems such as these  be understood. 
are safety-critical systems.   
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 29The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
4.  Following an accident, judges, juries, lawyers,  Further Resources
and expert witnesses involved in the trial 
•  Cappelli, C., P. Engiel, R. Mendes de Araujo, 
process require transparency to inform 
and J. C. Sampaio do Prado Leite. “Managing 
evidence and decision-making.
Transparency Guided by a Maturity Model.” 
5.  For disruptive technologies, such as driverless  3rd Global Conference on Transparency 
cars, a certain level of transparency to wider  Research 1 no. 3, 1–17. Jouy-en-Josas, 
society is needed to build public confidence  France: HEC Paris, 2013.
in the technology, promote safer practices, 
•  Sampaio do Prado Leite, J. C., and C. 
and facilitate wider societal adoption.
Cappelli. “Software Transparency.” Business  
& Information Systems Engineering 2,  
Candidate Recommendation
no. 3 (2010): 127–139.
Develop new standards* that describe measurable,  
•  Winfield, A., and M. Jirotka. “The Case for an 
testable levels of transparency, so that systems 
Ethical Black Box.” Lecture Notes in Artificial 
can be objectively assessed and levels of 
Intelligence 10454, (2017): 262–273. 
compliance determined. For designers, such 
standards will provide a guide for self-assessing  •  Wortham, R. R., A. Theodorou, and  
transparency during development and suggest  J. J. Bryson. “What Does the Robot Think? 
mechanisms for improving transparency. (The  Transparency as a Fundamental Design 
mechanisms by which transparency is provided  Requirement for Intelligent Systems.” 
will vary significantly, for instance 1) for users   IJCAI-2016 Ethics for Artificial Intelligence 
of care or domestic robots, a why-did-you-do-that  Workshop. New York, 2016.
button which, when pressed, causes the robot  
•  Machine Intelligence Research Institute. 
to explain the action it just took, 2) for validation 
“Transparency in Safety-Critical Systems.” 
or certification agencies, the algorithms underlying  
August 25, 2013.
the A/IS and how they have been verified, and  
3) for accident investigators, secure storage  
•  Scherer, M. “Regulating Artificial Intelligence 
of sensor and internal state data, comparable  
Systems: Risks, Challenges, Competencies, 
to a flight data recorder or black box.)
and Strategies.” Harvard Journal of Law  
& Technology 29, no. 2 (2015).
*Note that IEEE Standards Working Group 
P7001™ has been set up in response to this 
•  U.K. House of Commons. “Decision Making 
recommendation.
Transparency” pp. 17–18 in Report of the 
U.K. House of Commons Science and 
Technology Committee on Robotics and 
Artificial Intelligence, September 13, 2016.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 30The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
Principle 5 — A/IS Technology Misuse 
and Awareness of It
They also have a role to play in guiding new 
technology proactively toward beneficial ends.
Issue: 
How can we extend the benefits 
Candidate Recommendations
and minimize the risks of A/IS 
Raise public awareness around the issues of 
technology being misused?
potential A/IS technology misuse in an informed 
and measured way by:
1.  Providing ethics education and security 
Background
awareness that sensitizes society to the 
New technologies give rise to greater risk of  potential risks of misuse of A/IS (e.g.,  
misuse, and this is especially true for A/IS. A/IS  by providing “data privacy” warnings that 
increases the impact of risks such as hacking, the  some smart devices will collect their user’s 
misuse of personal data, “gaming,” or exploitation  personal data).
(e.g., of vulnerable users by unscrupulous 
parties). These are not theoretical risks. Cases of  2.  Delivering this education in scalable and 
A/IS hacking have already been widely reported,  effective ways, beginning with those having 
of driverless cars for example. The EU’s General  the greatest credibility and impact that also 
Data Protection Regulation (GDPR) provides  minimize generalized (e.g., non-productive) 
measures to remedy the misuse of personal  fear about A/IS (e.g., via credible research 
data. The Microsoft Tay AI chatbot was famously  institutions or think tanks via social media 
gamed when it mimicked deliberately offensive  such as Facebook or YouTube).
users. In an age where these powerful tools are 
3.  Educating government, lawmakers, and 
easily available, there is a need for new kind of 
enforcement agencies surrounding these 
education for citizens to be sensitized to risks 
issues so citizens work collaboratively with 
associated with the misuse of A/IS. 
them to avoid fear or confusion (e.g., in the 
Responsible innovation requires designers to  same way police officers have given public 
anticipate, reflect, and engage with users of A/IS  safety lectures in schools for years; in the 
thus, through education and awareness, citizens,  near future they could provide workshops  
lawyers, governments, etc. have a role to play in  on safe A/IS).
developing accountability structures (Principle 3).  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 31The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
General Principles
Further Resources •  Engineering and Physical Sciences Research 
Council. Anticipate, Reflect, Engage and Act 
•  Greenberg, A. “Hackers Fool Tesla S’s 
(AREA) Framework for Responsible Research 
Autopilot to Hide and Spoof Obstacles.” 
and Innovation.
Wired, August 2016.
•  (In relation to Candidate Recommendation 
#2) Wilkinson, C., and E. Weitkamp.  
Creative Research Communication: Theory 
and Practice. Manchester, UK: Manchester 
University Press, 2016.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 32The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous  
Intelligent Systems
Society has not established universal standards or guidelines for embedding human norms 
and values into autonomous and intelligent systems (A/IS) today. But as these systems are 
instilled with increasing autonomy in making decisions and manipulating their environment, 
it is essential they be designed to adopt, learn, and follow the norms and values of the 
community they serve. Moreover, their actions must be transparent in signaling their norm 
compliance and, if needed, they must be able to explain their actions. This is essential  
if humans are to develop levels of trust in A/IS that are appropriate in the specific contexts 
and roles in which A/IS function.
The conceptual complexities surrounding what “values” are (e.g., Hitlin and Piliavin, 2004; 
Malle and Dickert, 2007; Rohan, 2000; Sommer, 2016) make it currently difficult to envision 
A/IS that have computational structures directly corresponding to social or cultural values 
(such as “security,” “autonomy,” or “fairness”). However, it is a more realistic goal to embed 
explicit norms into such systems because norms can be considered instructions to act in 
defined ways in defined contexts, for a specific community (from family to town to country 
and beyond). A community’s network of norms is likely to reflect the community’s values, 
and A/IS equipped with such a network would, therefore, also reflect the community’s 
values, even if there are no directly identifiable computational structures that correspond  
to values per se. (For discussion of specific values that are critical for ethical considerations 
of A/IS, see the sections “Personal Data and Individual Access Control” and “Well-being”.)
Norms are typically expressed in terms of obligations and prohibitions, and these can  
be expressed computationally (e.g., Malle, Scheutz, and Austerweil, 2017; Vázquez- 
Salceda, Aldewereld, Dignum, 2004). At this level, norms are typically qualitative in nature  
(e.g., do not stand too close to people). However, the implementation of norms also  
has a quantitative component (the measurement of the physical distance we mean  
by “too close”), and the possible instantiations of the quantitative component technically 
enable the qualitative norm.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 33The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous  
Intelligent Systems
To address the broad objective of embedding norms and, by implication, values into  
these systems, our Committee has defined three more concrete goals as described  
in the following sections:
1.  Identifying the norms of a specific community in which A/IS operate.
2.  Computationally implementing the norms of that community within the A/IS.
3.  Evaluating whether the implementation of the identified norms in the A/IS  
are indeed conforming to the norms reflective of that community.
Pursuing these three goals represents an iterative process that is sensitive to the purpose  
of A/IS and their users within a specific community. It is understood that there may be 
clashes of values and norms when identifying, implementing, and evaluating these systems. 
Such clashes are a natural part of the dynamically changing and renegotiated norm systems 
of any community. As a result, we advocate for an approach where systems are designed  
to provide transparent signals (such as explanations or inspection capabilities) about  
the specific nature of their behavior to the individuals in the community they serve.
References
•  Hitlin, S., and J. A. Piliavin. “Values: Reviving a Dormant Concept.” Annual Review  
of Sociology 30 (2004): 359–393.
•  Malle, B. F., and S. Dickert. “Values,” The Encyclopedia of Social Psychology, edited  
by R. F. Baumeister and K. D. Vohs, Thousand Oaks, CA: Sage, 2007.
•  Malle, B. F., M. Scheutz, and J. L. Austerweil. “Networks of Social and Moral Norms in 
Human and Robot Agents,” in A World with Robots: International Conference on Robot 
Ethics: ICRE 2015, edited by M. I. Aldinhas Ferreira, J. Silva Sequeira, M. O. Tokhi, E. E. 
Kadar, and G. S. Virk, 3–17. Cham, Switzerland: Springer International Publishing, 2017.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 34The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous  
Intelligent Systems
•  Rohan, M. J. “A Rose by Any Name? The Values Construct.” Personality and Social 
Psychology Review 4 (2000): 255–277.
•  Sommer, A. U. Werte: Warum Man Sie Braucht, Obwohl es Sie Nicht Gibt. [Values. Why 
We Need Them Even Though They Don’t Exist.] Stuttgart, Germany: J. B. Metzler, 2016.
•  Vázquez-Salceda J., H. Aldewereld, and F. Dignum. “Implementing Norms in Multiagent 
Systems,” in Multiagent System Technologies. MATES 2004, edited by G. Lindemann,  
J. Denzinger, I. J. Timm, and R. Unland. (Lecture Notes in Computer Science, vol. 3187.) 
Berlin: Springer, 2004.
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 35The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
Section 1 — Identifying Norms  
for Autonomous Intelligent Systems
We identify three issues that must be addressed  machines to do so is to identify these norms.  
in the attempt to identify norms (and thereby  But which norms? Laws are publicly documented 
values) for A/IS. The first issue asks which  and therefore easy to identify, so they will 
norms should be identified, and with which  certainly have to be incorporated into A/IS. Social 
properties. Here we highlight context specificity  and moral norms are more difficult to ascertain, 
as a fundamental property of norms. Second,  as they are expressed through behavior, language, 
we emphasize another fundamental property of  customs, cultural symbols, and artifacts. Most 
norms: their dynamically changing nature, which  important, communities (from families to whole 
requires A/IS to have the capacity to update their  nations) differ to various degrees in the laws 
norms and learn new ones. Third, we address the  and norms they follow. Therefore, generating 
challenge of norm conflicts that naturally arise in  a universal set of norms that applies to all 
a complex social world. Resolving such conflicts  autonomous systems is not realistic, but neither 
requires priority structures among norms, which  is it advisable to completely personalize an A/IS 
help determine whether, in a given context,  to individual preferences. However, we believe 
adhering to one norm is more important than  that identifying broadly observed norms of  
adhering to another norm. a particular community is feasible. 
The difficulty of generating a set of universal 
norms is not inconsistent with the goal of 
seeking agreement over Universal Human Rights 
Issue 1:  (see “General Principles” section). However, 
such universal rights would not be sufficient 
Which norms should be 
for devising an A/IS that obeys the specific 
identified?
norms of its community. Universal rights must, 
however, constrain the kinds of norms that are 
implemented in an A/IS.
Background and Analysis
Embedding norms in A/IS requires a clear 
If machines engage in human communities  delineation of the community in which the  
as autonomous agents, then those agents will  A/IS are to be deployed. Further, even within  
be expected to follow the community’s social  a particular community, different types of  
and moral norms. A necessary step in enabling  A/IS will demand different sets of norms.  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 36The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
The relevant norms for self-driving vehicles, for  Empirical research involving multiple disciplines 
example, will differ greatly from those for robots  and multiple methods (see the Further Resources 
used in healthcare. Thus, we recommend that  section) should therefore (a) investigate and 
to develop A/IS capable of following social and  document both community- and task-specific 
moral norms, the first step is to identify the  norms that apply to humans and (b) consider 
norms of the specific community in which the   possible differences for A/IS deployed in these 
A/IS are to be deployed and, in particular, norms  contexts. The set of empirically identified norms 
relevant to the kinds of tasks that the A/IS are  applicable to A/IS should then be made available 
designed to perform. Even when designating  for designers to implement.
a narrowly defined community (e.g., a nursing 
home; an apartment complex; a company),   Candidate Recommendation
there will be variations in the norms that apply. 
To develop A/IS capable of following social and 
The identification process must heed such 
moral norms, the first step is to identify the 
variation and ensure that the identified norms  
norms of the specific community in which the  
are representative not only of the dominant 
A/IS are to be deployed and, in particular, norms 
subgroup in the community but also of 
relevant to the kinds of tasks that the A/IS are 
vulnerable and underrepresented groups.
designed to perform.
The most narrowly defined community is a 
single person, and A/IS may well have to adapt  Further Resources
to the unique norms of a given individual, such 
•  Bendel, O. Die Moral in der Maschine: 
as norms of arranging a disabled person’s home 
Beiträge zu Roboter- und Maschinenethik. 
to accommodate certain physical limitations. 
Hannover, Germany: Heise Medien, 2016. 
However, unique individual norms must not 
Accessible popular-science contributions 
violate norms in the larger community. Whereas 
to philosophical issues and technical 
the arrangement of someone’s kitchen or the 
implementations of machine ethics.
frequency with which a care robot checks in with 
a patient can be personalized without violating  •  Burks, S. V., and E. L. Krupka. “A Multimethod 
any community norms, encouraging the robot  Approach to Identifying Norms and 
to use derogatory language to talk about certain  Normative Expectations within a Corporate 
social groups does violate such norms. (In the  Hierarchy: Evidence from the Financial 
next section we discuss how A/IS might handle  Services Industry.” Management Science  
such norm conflicts.)  58 (2012): 203–217. Illustrates surveys  
and incentivized coordination games as 
We should note that the norms that apply to 
methods to elicit norms in a large financial 
humans may not always be identical to the norms 
services firm.
that would apply to an A/IS in the same context. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 37The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
•  Friedman, B., P. H. Kahn, A. Borning, and  •  Rizzo, A., and L. L. Swisher. “Comparing  
A. Huldtgren. “Value Sensitive Design and  the Stewart–Sprinthall Management Survey 
Information Systems,” in Early Engagement  and the Defining Issues Test-2 as Measures 
and New Technologies: Opening up the  of Moral Reasoning in Public Administration.” 
Laboratory (Vol. 16), edited by N. Doorn,  Journal of Public Administration Research 
D. Schuurbiers, I. van de Poel, and M.  and Theory 14 (2004): 335–348. Describes 
E. Gorman, 55–95. Dordrecht: Springer,  two assessment instruments of moral 
2013. A comprehensive introduction into  reasoning (including norm maintenance) 
Value Sensitive Design and three sample  based on Kohlberg’s theory of moral 
applications.  development. 
•  Mackie, G., F. Moneti, E. Denny, and   •  Schwartz, S. H. “An Overview of the Schwartz 
H. Shakya. What Are Social Norms? How  Theory of Basic Values.” Online Readings 
Are They Measured? UNICEF Working Paper.  in Psychology and Culture 2 (2012).
University of California at San Diego:   Comprehensive overview of a specific 
UNICEF, 2012. A broad survey of conceptual  theory of values, understood as motivational 
and measurement questions regarding   orientations toward abstract outcomes  
social norms.  (e.g., self-direction, power, security).
•  Malle, B. F. “Integrating Robot Ethics and  •  Schwartz, S. H., and K. Boehnke.  
Machine Morality: The Study and Design   “Evaluating the Structure of Human Values 
of Moral Competence in Robots.” Ethics   with Confirmatory Factor Analysis.” Journal 
and Information Technology 18, no. 4  of Research in Personality 38 (2004): 
(2016): 243–256. Discusses how a robot’s  230–255. Describes an older method of 
norm capacity fits in the larger vision of   subjective judgments of relations among 
a robot with moral competence. valued outcomes and a newer,  
formal method of analyzing these relations.
•  Miller, K. W., M. J. Wolf, and F. Grodzinsky. 
“This ‘Ethical Trap’ Is for Roboticists, Not  •  Wallach, W., and C. Allen. Moral Machines: 
Robots: On the Issue of Artificial Agent Ethical  Teaching Robots Right from Wrong.  
Decision-Making.” Science and Engineering  New York: Oxford University Press, 2008. 
Ethics 23 (2017): 389–401. This article  This book describes some of the challenges 
raises doubts about the possibility of imbuing  of having a one-size-fits-all approach to 
artificial agents with morality, or claiming   embedding human values in autonomous 
to have done so. systems.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 38The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
best equipped to respond to such demands  
for change by relying on multiple mechanisms, 
Issue 2: 
such as:
The need for norm updating.
•  Processing behavioral trends by members  
of the target community and comparing  
them to trends predicted by the baseline 
Background and Analysis
norm system; 
Norms are not static. They change over time, 
•  Asking for guidance from the community 
in response to social progress and new legal 
when uncertainty about applicable norms 
measures, and, in smaller communities, in 
exceeds a critical threshold;
response to complaints or new opportunities. 
New norms form when technological innovation 
•  Responding to instruction from the 
demands novel social standards (e.g., cell phone 
community members who introduce the 
use in public), and norms can fade away when, 
robot to a previously unknown context  
for whatever reasons, fewer and fewer people 
or who notice the A/IS’s uncertainty in  
adhere to them. 
a familiar context;
Humans have many mechanisms available  
•  Responding to critique from the community 
to update norms and learn new ones. They 
when the A/IS violates a norm.
observe other community members’ behavior 
and are sensitive to collective norm change;   The modification of a normative system can 
they explicitly ask about new norms when joining  occur at any level of the system: it could involve 
new communities (e.g., entering college, a job  altering the priority weightings between individual 
in a new town); and they respond to feedback  norms, (changing the qualitative expression of 
from others when they exhibit uncertainty about  a norm), or altering the quantitative parameters 
norms or have violated a norm. that enable the norm.
An A/IS may be equipped with a norm baseline  As in the case of resolving norm conflicts  
before it is deployed in its target community  (Issue 2), we recommend that the system’s 
(Issue 1), but this will not suffice for it to behave  norm changes be transparent. That is, the 
appropriately over an extended time. It must   system should make explicit when it adds new 
be capable of identifying and adding new norms  norms to its norm system or adjusts the priority 
to its baseline system, because the initial norm  or content of existing norms. The specific 
identification process will undoubtedly have  form of communication will vary by machine 
missed some norms. It must also be capable   sophistication (e.g., communication capacity) 
of updating some of its existing norms, as change  and function (e.g., flexible social companion 
occurs in its target community. A/IS would be  vs. task-defined medical robot). In some cases, 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 39The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
the system may document its dynamic change  priorities of one norm or value over another 
and the user can consult this documentation as  (in a given context). Such priorities may be 
desired; in other cases, explicit announcements  represented in the norm system as hierarchical 
and requests for discussion may be appropriate;  relations. 
in yet other cases, the A/IS may propose changes 
Along with identifying the norms within a specific 
and the relevant human community will decide 
community and task domain, we need to identify 
whether such changes should be implemented  
the ways in which people prioritize competing 
in the system. 
norms and resolve norm conflicts, and the ways 
in which people expect A/IS to resolve similar 
Candidate Recommendation
norm conflicts. Some general principles are 
To respond to the dynamic change of norms  available, such as the Common Good Principle 
in society the A/IS must be able to adjust its  (Andre and Velasquez, 1992). However, other 
existing norms and learn new ones, while being  priority relations in the norm network must be 
transparent about these changes.  established through empirical research so as to 
reflect the shared values of the community in 
question. For example, a self-driving vehicle’s 
prioritization of one factor over another in its 
decision-making will need to reflect the priority 
Issue 3: 
order of values of its target user population,  
A/IS will face norm conflicts   even if this order is in conflict with that of an 
individual designer, manufacturer, or client.
and need methods to  
resolve them. Some priority orders can be built into a  
given norm network as hierarchical relations  
(e.g., prohibitions against harm to humans 
typically override prohibitions against lying). 
Background and Analysis
Other priority orders can stem from the general 
Often, even within a well-specified context, no 
override that norms in the larger community  
action is available that fulfills all obligations and 
exert on norms and preferences of an individual 
prohibitions. Such situations (often described as 
user. In the earlier example discussing 
moral dilemmas or moral overload; see Van den 
personalization (see Issue 1), an A/IS of a racist 
Hoven, 2012) must be computationally tractable 
user who demands the A/IS use derogatory 
by an A/IS — it cannot simply stop in its tracks 
language for certain social groups might have  
and end on a logical contradiction. Humans 
to resist such demands because community 
resolve such situations by accepting trade-offs 
norms hierarchically override an individual  
between conflicting norms, which constitute 
user’s preferences.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 40The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
In many cases, priority orders are not built in  References
as fixed hierarchies because the priorities are 
•  Andre, C., and M. Velasquez. “The Common 
themselves context specific or may arise from  
Good.” Issues in Ethics 5, no. 1 (1991).
net moral costs and benefits of the particular 
case at hand. A/IS must have learning capacities  •  Van den Hoven, J. “Engineering and the 
to track such variations and incorporate user  Problem of Moral Overload.” Science  
input (e.g., about the subtle differences between  and Engineering Ethics 18, no. 1 (2012): 
contexts) to refine the system’s norm network  143–155.
(see Issue 2).
Further Resources
We also recommend that the system’s resolution 
of norm conflicts be transparent — that is,  •  Abel, D., J. MacGlashan, and M. L. Littman. 
documented by the system and ready to be  “Reinforcement Learning as a Framework  
made available to users. Just like people explain  for Ethical Decision Making.” AAAI Workshop: 
to each other why they made decisions, they will  AI, Ethics, and Society, Volume WS-16-02  
expect any A/IS to be able to explain its decisions  of 13th AAAI Workshops. Palo Alto, CA: AAAI 
(and be sensitive to user feedback about the  Press, 2016.
appropriateness of the decision). To do so, design 
•  Cushman, F., V. Kumar, and P. Railton.  
and development of A/IS should specifically 
“Moral Learning.” Cognition 167 (2017): 
identify the relevant groups of humans who  
1–282. 
may request explanations and evaluate the 
system’s behavior. 
•  Open Roboethics Initiative (e.g., on care 
robots). A series of poll results on differences 
Candidate Recommendation in human moral decision-making and 
changes in priority order of values for 
One must identify the ways in which people 
autonomous systems.
resolve norm conflicts and the ways in which  
they expect A/IS to resolve similar norm conflicts. 
 
The system’s resolution of norm conflicts must 
be transparent — that is, documented by the 
system and ready to be made available to 
relevant users.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 41The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
Section 2 — Implementing Norms  
in Autonomous Intelligent Systems
Once the norms relevant to an A/IS’s role in  agreement on moral decisions, verifiability  
a specific community have been identified,  of A/IS decisions, justified trust). 
including their properties and priority structure, 
we must link these norms to the functionalities of 
the underlying computational system. We discuss 
three issues that arise in this process of norm 
Issue 1: 
implementation. First, computational approaches 
to enable a system to represent, learn, and  Many approaches to norm 
execute norms are only slowly emerging. 
implementation are currently 
However, the diversity of approaches may soon 
available, and new ones are 
lead to substantial advances. Second, for A/
being developed.
IS that operate in human communities, there 
is a particular need for transparency — ranging 
from the technical process of implementation 
to the ethical decisions that A/IS will make in  Background and Analysis
human-machine interactions, which will require 
The prospect of developing artificial systems that 
a high level of explainability. Third, failures of 
are sensitive to human norms and factor them 
normative reasoning can be considered inevitable 
into morally or legally significant decisions has 
and mitigation strategies should therefore be 
intrigued science fiction writers, philosophers, 
put in place to handle such failures when they 
and computer scientists alike. Modest efforts  
occur. Before we discuss these three issues and 
to realize this worthy goal in limited or bounded 
corresponding candidate recommendations, we 
contexts are already underway. This emerging 
offer one general recommendation for the entire 
field of research appears under many names, 
process of implementation: 
including: machine morality, machine ethics, 
moral machines, value alignment, computational 
Candidate Recommendation
ethics, artificial morality, safe AI, and friendly AI. 
Throughout the technical implementation  
There are a number of different implementation 
of norms, designers should already consider 
routes for implementing ethics into autonomous 
forms and metrics of evaluation and define  
systems. Following Wallach and Allen (2008),  
and incorporate central criteria for assessing  
we might begin to categorize these as either:
an A/IS’s norm conformity (e.g., human-machine 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 42The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
A.  Top-down approaches, where the system  Recent breakthroughs in machine learning and 
(e.g., a software agent) has some symbolic  perception will enable researchers to explore 
representation of its activity, and so can  bottom-up approaches in which the AI system 
identify specific states, plans, or actions as  learns about its context and about human 
ethical/unethical with respect to particular  norms, similar to the manner in which a child 
ethical requirements (e.g., Dennis, Fisher,  slowly learns which forms of behavior are safe 
Slavkovik, Webster, 2016; Pereira and  and acceptable. Of course a child can feel pain 
Saptawijaya, 2016; Rötzer, 2016; Scheutz,  and pleasure, empathize with others, and has 
Malle, and Briggs, 2015); or other capabilities that an AI system cannot 
presently imitate. Nevertheless, as research on 
B.  Bottom-up approaches, where the system 
autonomous systems progresses, engineers  
(e.g., a learning component) builds up, 
will explore new ways to either simulate learning 
through experience of what is to be 
capabilities or build alternative mechanisms  
considered ethical/unethical in certain 
that fulfill similar functions. 
situations, an implicit notion of ethical 
behavior (e.g., Anderson and Anderson,  Each of the first two options has obvious 
2014; Riedl and Harrison, 2016). limitations, such as option A’s inability to learn 
and adapt and option B’s unconstrained learning 
Relevant examples of these two are: (A) symbolic 
behavior. A third option tries to address these 
agents that have explicit representations of plans, 
limitations:
actions, goals, etc.; and (B) machine learning 
systems that train subsymbolic mechanisms with  C.  Hybrid approaches, combining (A)  
acceptable ethical behavior. (For more detailed  and (B).
discussion, see Charisi et al., 2017.)
For example, the selection of action might be 
Computers and robots already reflect values in  carried out by a subsymbolic system, but this 
their choices and actions, but these values are  action must be checked by a symbolic “gateway” 
programmed or designed in by the engineers  agent before being invoked. This is a typical 
that build the systems. Increasingly, autonomous  approach for Ethical Governors (Arkin, 2008; 
systems will encounter situations that their  Winfield, Blum, and Liu, 2014) or Guardians 
designers cannot anticipate and will require  (Etzioni, 2016) that monitor, restrict, and even 
algorithmic procedures to select the better   adapt certain unacceptable behaviors proposed 
of two or more possible courses of action.  by the system. (See also Issue 3.) Alternatively, 
Many of the existing experimental approaches  action selection in light of norms could be done 
to building moral machines are top-down,  in a verifiable logical format, while many of the 
in the sense that norms, rules, principles, or  norms constraining those actions can be learned 
procedures are used by the system to evaluate  through bottom-up learning mechanisms  
the acceptability of differing courses of action,   (e.g., Arnold, Kasenberg, and Scheutz, 2017). 
or as moral standards or goals to be realized. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 43The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
These three architectures are not a 
comprehensive list of all possible techniques 
Issue 2: 
for implementing norms and values into A/IS. 
For example, some contributors to the multi- The need for transparency from 
agent systems literature have integrated norms  implementation to deployment. 
into their agent specifications (Andrighetto et 
al., 2013), and even though these agents live in 
societal simulations and are too underspecified 
Background and Analysis
to be translated into individual A/IS (such 
as robots), the emerging work can inform  When A/IS are part of social communities and 
cognitive architectures of such A/IS that fully  act according to the norms of their communities, 
integrate norms. In addition, some experimental  people will want to understand the A/IS decisions 
approaches may attempt to capture values  and actions, just as they want to understand  
computationally (Conn, 2017), or attempt   each other’s decisions and actions. This is 
to relate norms to values in ways that ground  particularly true for morally significant actions or 
or justify norms (Sommer, 2016). Of course,  omissions: an ethical reasoning system should  
none of these experimental systems should be  be able to explain its own reasoning to a user  
deployed outside of the laboratory before testing  on request. Thus, transparency (or explainability) 
or before certain criteria are met, which we  of A/IS is paramount (Wachter, Mittelstadt, and 
outline in the remainder of this section and   Floridi, 2017), and it will allow a community 
in Section 3. to understand, predict, and appropriately trust 
the A/IS (see Section 1, Issue 2). Moreover, as 
the norms embedded in A/IS are continuously 
Candidate Recommendation
updated and refined (see Section 1, Issue 2), 
In light of the multiple possible approaches 
transparency allows for trust to be maintained 
to computationally implement norms, diverse 
(Grodzinsky, Miller, and Wolf 2011), and, where 
research efforts should be pursued, especially 
necessary, allows the community to modify  
collaborative research between scientists from 
a system’s norms, reasoning, and behavior.
different schools of thought.
Transparency can occur at multiple levels  
(e.g., ordinary language, coder verification) and 
for multiple stakeholders (e.g., user, engineer, 
attorney). (See IEEE P7001™, Draft Standard  
for Transparency of Autonomous Systems.)  
It should be noted that transparency to all parties 
may not always be advisable, such as in the 
case of security programs that prevent a system 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 44The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
from being hacked (Kroll et al., 2016). Here we  Webster, 2013). Even if a system cannot explain 
briefly illustrate the broad range of transparency  every single reasoning step in understandable 
by reference to four ways in which systems  human terms, a log of ethical reasoning should 
can be transparent (traceability, verifiability,  be available for inspection of later evaluation 
nondeception, and intelligibility) and apply these  purposes.
considerations to the implementation of norms  
Transparency as nondeception and honest 
in A/IS.
design. We can assume that lying and deception 
Transparency as traceability. Most relevant for  will be prohibited actions in many contexts, 
the topic of implementation is the transparency  and therefore will be part of the norm system 
of the software engineering process during  implemented into A/IS. In certain use cases of 
implementation (Cleland-Huang, Gotel, and  an A/IS, deception may be necessary in serving 
Zisman, 2012). It allows for the originally  the core functionality of the system (e.g., a robot 
identified norms (Section 1, Issue 1) to be  that plays poker with humans), but those actions 
traced through to the final system. This allows  are no longer norm violations because they are 
technical inspection of which norms have been  justified by context and user consent. 
implemented, for which contexts, and how 
However, the absence of deception does not 
norm conflicts are resolved (e.g., priority weights 
yet meet the goal of transparency. One should 
given to different norms). Transparency in the 
demand that A/IS be honest, and that includes 
implementation process may also reveal biases 
both, more obviously, honest communication 
that were inadvertently built into systems, such 
by the A/IS itself and, less obviously, “honest 
as racism and sexism in search engine algorithms 
design.” Honest design entails that the physical 
(e.g., Noble, 2013). (See Section 3, Issue 2.) 
appearance of a system accurately represents 
Such traceability in turn calibrates a community’s 
what the system is capable of doing — e.g., ears 
trust about whether A/IS are conforming to  
only for systems that actually process acoustic 
the norms and values relevant in its use context 
information; eyes only for systems that actually 
(Fleischmann and Wallace, 2005). 
process visual information. The requirement 
Transparency as verifiability. Transparency  for honest design may also extend to higher-
concerning how normative reasoning is  level capacities of artificial agents: If the agent 
approached in the implementation is important  introduces a certain topic into conversation, 
as we wish to verify that the normative decisions  then it should also be able to, if asked, reason 
the system makes match the required norms and  about that topic; if the agent displays signs of a 
values. Explicit and exact representations of these  certain human-like emotion, then it should have 
normative decisions can then provide the basis  an internal state that corresponds to at least an 
for a range of strong mathematical techniques,  analogue to that human emotion (e.g., inhabit  
such as formal verification (Fisher, Dennis, and  the appraisal states that make up the emotion). 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 45The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
Transparency as intelligibility. As mentioned 
above, humans will want to understand an  
Issue 3: 
A/IS’s decisions and actions, especially the 
morally significant ones. A clear requirement   Failures will occur.
for an ethical A/IS is therefore that the system  
be able to explain its own reasoning to a user, 
Operational failures and, in particular, violations 
when asked (or, ideally, also when suspecting  
of a system’s embedded community norms are 
the user’s confusion), and the system should  
unavoidable, both during system testing and 
do so at a level of ordinary human reasoning,  
during deployment. Not only are implementations 
not with incomprehensible technical detail 
never perfect, but A/IS with embedded norms 
(Tintarev and Kutlak, 2014). Furthermore,  
will update or expand their norms over extended 
when the system cannot itself explain some  
use (see Section 1, Issue 2) and interactions 
of its actions, technicians or designers should  
in the social world are particularly complex 
be available to make those actions intelligible. 
and uncertain. Thus, we propose the following 
Along these lines, the European Union’s new 
candidate recommendation.
General Data Protection Regulation (GDPR), 
scheduled to take effect in 2018, states that,  
for automated decisions based on personal  Candidate Recommendation
data, individuals have a right to “an explanation 
Because designers cannot anticipate all possible 
of the [algorithmic] decision reached after such 
operating conditions and potential failures of  
assessment and to challenge the decision.”  
A/IS, multiple additional strategies to mitigate the 
(See Boyd, 2016, for a critical discussion  
chance and magnitude of harm must be in place. 
of this regulation.)
Elaboration
Candidate Recommendation
To be specific, we sample three possible 
A/IS, and especially those with embedded 
mitigation strategies. 
norms, must have a high level of transparency, 
from traceability in the implementation process,  First, anticipating the process of evaluation 
mathematical verifiability of its reasoning,   already during the implementation phase requires 
to honesty in appearance-based signals, and  defining criteria and metrics for such evaluation, 
intelligibility of the system’s operation and  which in turn better allows the detection and 
decisions.  mitigation of failures. Metrics will include more 
technical variables, such as traceability and 
verifiability; user-level variables such as reliability, 
understandable explanations, and responsiveness 
to feedback; and community-level variables such 
as justified trust (see Issue 2) and the collective 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 46The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
belief that A/IS are generally creating social  References
benefits rather than, for example, technological 
•  Anderson, M., and S. L. Anderson.  
unemployment.
“GenEth: A General Ethical Dilemma 
Second, a systematic risk analysis and  Analyzer.” Proceedings of the Twenty-Eighth 
management approach can be useful (e.g.,  AAAI Conference on Artificial Intelligence 
Oetzel and Spiekermann, 2014, for an application  (2014): 253–261.
to privacy norms). This approach tries to 
•  Andrighetto, G., G. Governatori, P. Noriega, 
anticipate potential points of failure (e.g., norm 
and L. W. N. van der Torre, eds. Normative 
violations) and, where possible, develops some 
Multi-Agent Systems. Saarbrücken/Wadern, 
ways to mitigate or remove the effects of failures. 
Germany: Dagstuhl Publishing, 2013.
Successful behavior, and occasional failures, 
can then iteratively improve predictions and  •  Arkin, R. “Governing Lethal Behavior: 
mitigation attempts.  Embedding Ethics in a Hybrid Deliberative/
Reactive Robot Architecture.” Proceedings 
Third, because not all risks and failures are 
of the 2008 Conference on Human-Robot 
predictable, especially in complex human-machine  
Interaction (2008): 121–128.
interactions in social contexts, additional mitigation  
mechanisms must be made available. Designers  •  Arnold, T., D. Kasenberg, and M. Scheutz. 
are strongly encouraged to augment the  “Value Alignment or Misalignment — 
architectures of their systems with components  What Will Keep Systems Accountable?” 
that handle unanticipated norm violations with   The Workshops of the Thirty-First AAAI 
a fail-safe, such as the symbolic “gateway” agents  Conference on Artificial Intelligence: Technical 
discussed in Section 1, Issue 1. Designers should  Reports, WS-17-02: AI, Ethics, and Society, 
identify a number of strict laws (that is, task- and  81–88. Palo Alto, CA: The AAAI Press, 2017.
community-specific norms that should never be 
•  Boyd, D. “Transparency ≠ Accountability.” 
violated), and the fail-safe components should 
Data & Society: Points, November 29, 2016.
continuously monitor operations against possible 
violations of these laws. In case of violations, 
•  Charisi, V., L. Dennis, M. Fisher et al.  
the higher-order gateway agent should take 
“Towards Moral Autonomous Systems,” 2017.
appropriate actions, such as safely disabling  
the system’s operation until the source of failure  •  Cleland-Huang, J., O. Gotel, and A. Zisman, 
is identified. The fail-safe components need to be  eds. Software and Systems Traceability. 
extremely reliable and protected against security  London: Springer, 2012. doi:10.1007/978- 
breaches, which can be achieved, for example,   1-4471-2239-5
by validating them carefully and not letting  
•  Conn, A. “How Do We Align Artificial 
them adapt their parameters during execution.
Intelligence with Human Values?”  
Future of Life Institute, February 3, 2017.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 47The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
•  Dennis, L., M. Fisher, M. Slavkovik, and   •  Pereira, L. M., and A. Saptawijaya. 
M. Webster. “Formal Verification of Ethical  Programming Machine Ethics. Cham, 
Choices in Autonomous Systems.” Robotics  Switzerland: Springer International, 2016.
and Autonomous Systems 77 (2016): 1–14.
•  Riedl, M. O., and B. Harrison. “Using Stories 
•  Etzioni, A. “Designing AI Systems That Obey  to Teach Human Values to Artificial Agents.” 
Our Laws and Values.” Communications   Proceedings of the 2nd International 
of the ACM 59, no. 9 (2016): 29–31. Workshop on AI, Ethics and Society,  
Phoenix, Arizona, 2016.
•  Fisher, M., L. A. Dennis, and M. P. Webster. 
“Verifying Autonomous Systems.”  •  Rötzer, F. ed. Programmierte Ethik:  
Communications of the ACM 56, no. 9  Brauchen Roboter Regeln oder Moral? 
(2013): 84–93. Hannover, Germany: Heise Medien, 2016.
•  Fleischmann, K. R., and W. A. Wallace.   •  Scheutz, M., B. F. Malle, and G. Briggs. 
“A Covenant with Transparency: Opening   “Towards Morally Sensitive Action 
the Black Box of Models.” Communications   Selection for Autonomous Social Robots.” 
of the ACM 48, no. 5 (2005): 93–97. Proceedings of the 24th International 
Symposium on Robot and Human Interactive 
•  Grodzinsky, F. S., K. W. Miller, and M. J.  
Communication, RO-MAN 2015 (2015): 
Wolf. “Developing Artificial Agents Worthy 
492–497. 
of Trust: Would You Buy a Used Car from 
This Artificial Agent?” Ethics and Information  •  Sommer, A. U. Werte: Warum Man Sie Braucht,  
Technology 13, (2011): 17–27. Obwohl es Sie Nicht Gibt. [Values. Why  
we need them even though they don’t exist.] 
•  Kroll, J. A., J. Huey, J., S. Barocas et al. 
Stuttgart, Germany: J. B. Metzler, 2016.
“Accountable Algorithms.” University  
of Pennsylvania Law Review 165 (2017  •  Sommerville, I. Software Engineering. Harlow, 
forthcoming). U.K.: Pearson Studium, 2001.
•  Noble, S. U. “Google Search: Hyper-Visibility  •  Tintarev, N., and R. Kutlak. “Demo: Making 
as a Means of Rendering Black Women and  Plans Scrutable with Argumentation and 
Girls Invisible.” InVisible Culture 19 (2013). Natural Language Generation.” Proceedings 
of the Companion Publication of the 19th 
•  Oetzel, M. C., and S. Spiekermann. “A 
International Conference on Intelligent User 
Systematic Methodology for Privacy Impact 
Interfaces (2014): 29–32. 
Assessments: A Design Science Approach.” 
 
European Journal of Information Systems 23, 
(2014): 126–150. doi:10.1057/ejis.2013.18
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 48The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
•  Wachter, S., B. Mittelstadt, and L. Floridi.  •  Winfield A. F. T., C. Blum, and W. Liu. 
“Transparent, Explainable, and Accountable  “Towards an Ethical Robot: Internal Models, 
AI for Robotics.” Science Robotics 2, no. 6  Consequences and Ethical Action Selection” 
(2017): eaan6080. doi:10.1126/scirobotics. in Advances in Autonomous Robotics 
aan6080 Systems, Lecture Notes in Computer Science 
Volume, edited by M. Mistry, A. Leonardis,  
•  Wallach, W., and C. Allen. Moral Machines: 
M. Witkowski, and C. Melhuish, 85–96. 
Teaching Robots Right from Wrong. New 
Springer, 2014. 
York: Oxford University Press, 2008. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 49The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
Section 3 — Evaluating  
the Implementation of A/IS
The success of implementing appropriate   matches the criteria. Many different evaluation 
norms in A/IS must be rigorously evaluated.   techniques are available in the field of software 
This evaluation process must be anticipated  engineering (Sommerville, 2001), ranging from 
during design and incorporated into the  formal mathematical proof, through rigorous 
implementation process, and it must continue  empirical testing against criteria of normatively 
throughout the life cycle of the system’s  correct behavior, to informal analysis of user 
deployment. Assessment before full-scale  interactions and responses to the machine’s  
deployment would best take place in systematic  norm awareness and compliance. All these 
test beds that allow human users (from the  approaches can, in principle, be applied to  
defined community, and representing all  the full range of autonomous systems, including 
demographic groups) to engage safely with   robots (Fisher, Dennis, and Webster, 2013). 
the A/IS in intended tasks. Multiple disciplines 
Evaluation may be done by first parties 
and methods should contribute to developing 
(designers/manufacturers, and users) as well 
and conducting such evaluations. 
as third parties (e.g., regulators or independent 
Evaluation criteria must capture the quality of  testing agencies). In either case, the results 
human-machine interactions, human approval  of evaluations should be made available to 
and appreciation of the A/IS, trust in the A/IS,   all parties, with strong encouragement to 
adaptability of the A/IS to human users, and  resolve discovered system limitations and 
human benefits in the presence or under  resolve potential discrepancies among multiple 
the influence of the A/IS. A range of ethical/ evaluations. 
normative aspects to be considered can be found 
in the UK standard on Robot Ethics (BSI, 2016).  Candidate Recommendation
These are important general evaluation criteria, 
Evaluation must be anticipated during a system’s 
but they do not yet fully capture evaluation of  
design, incorporated into the implementation 
a system that has norm capacities. To evaluate 
process, and continue throughout the system’s 
a system’s norm-conforming behavior, one must 
deployment. Evaluation must include multiple 
describe (and ideally, formally specify) criterion 
methods, be made available to all parties 
behaviors that reflect the previously identified 
(from designers and users to regulators), and 
norms, describe what the user expects the 
should include procedures to resolve conflicting 
system to do, verify that the system really does 
evaluation results. 
this, and validate that the specification actually 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 50The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
Issue 1:  Issue 2: 
Not all norms of a target  A/IS can have biases that 
community apply equally   disadvantage specific groups. 
to human and artificial agents.
Background and Analysis
Background and Analysis Even when reflecting the full system of 
An intuitive criterion for evaluations of norms  community norms that was identified, A/IS may 
embedded in A/IS would be that the A/IS norms  show operation biases that disadvantage specific 
should mirror the community’s norms — that is,  groups in the community or instill biases in users 
the A/IS should be disposed to behave the same  by reinforcing group stereotypes. A system’s 
way that people expect each other to behave.  bias can emerge in perception (e.g., a passport 
However, for a given community and a given   application AI rejected an Asian man’s photo 
A/IS use context, A/IS and humans may not have  because it insisted his eyes were closed; Griffiths, 
identical sets of norms. People will have some  2016); information processing (e.g., speech 
unique expectations for humans than they do for  recognition systems are notoriously less accurate 
machines (e.g., norms governing the regulation   for female speakers than for male speakers; 
of negative emotions, assuming that machines   Tatman, 2016); decisions (e.g., a criminal risk 
do not have such emotions), and people will  assessment device overpredicts recidivism  
have some unique expectations of A/IS that they  by African Americans; Angwin, et al., 2016);  
do not have for humans (e.g., that the machine  and even in its own appearance and presentation 
will sacrifice itself, if it can, to prevent harm to   (e.g., the vast majority of humanoid robots  
a human). have white “skin” color and use female voices) 
(Riek and Howard, 2014).
Candidate Recommendation
The norm identification process detailed in 
The norm identification process must document  Section 1 is intended to minimize individual 
the similarities and differences between the norms   designers’ biases, because the community 
that humans apply to other humans and the  norms are assessed empirically. The process also 
norms they apply to A/IS. Norm implementations  seeks to incorporate values and norms against 
should be evaluated specifically against the norms   prejudice and discrimination. However, biases 
that the community expects the A/IS to follow. may still emerge from imperfections in the norm 
identification process itself, from unrepresentative 
training sets for machine learning systems, and 
from programmers’ and designers’ unconscious 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 51The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
assumptions. Therefore, unanticipated or  However, transparency can be severely limited 
undetected biases should be further reduced   in some systems, especially in those that rely 
by including members of diverse social groups   on machine learning algorithms trained on large 
in both the planning and evaluation of AI systems  data sets. The data sets may not be accessible 
and integrating community outreach into the  to evaluators; the algorithms may be proprietary 
evaluation process (e.g., DO-IT program; RRI  information or mathematically so complex that 
framework). Behavioral scientists and members  they defy common-sense explanation; and  
of the target populations will be particularly  even fellow software experts may be unable  
valuable when devising criterion tasks for system  to verify reliability and efficacy of the final system 
evaluation. Such tasks would assess, for example,  because the system’s specifications are opaque. 
whether the A/IS applies norms in discriminatory 
For less inscrutable systems, numerous 
ways to different races, ethnicities, genders, ages, 
techniques are available to evaluate the 
body shapes, or to people who use wheelchairs 
implementation of an A/IS’s norm conformity.  
or prosthetics, and so on. 
On one side there is formal verification,  
which provides a mathematical proof that  
Candidate Recommendation
the A/IS will always match specific normative  
Evaluation of A/IS must carefully assess   and ethical requirements (typically devised in  
potential biases in the system’s performance   a top-down approach; see Section 2, Issue 1). 
that disadvantage specific social groups.   This approach requires access to the decision-
The evaluation process should integrate   making process and the reasons for each  
members of potentially disadvantaged   decision (Fisher, Dennis, and Webster, 2013).  
groups to diagnose and correct such biases. A simpler alternative, sometimes suitable even  
for machine learning systems, is to test the  
A/IS against a set of scenarios and assess how 
well it matches its normative requirements 
(e.g., acting in accordance with relevant norms; 
Issue 3: 
recognizing other agents’ norm violations). 
Challenges to evaluation  
These different evaluation techniques can be 
by third parties.
assigned different levels of “strength” — strong 
ones demonstrate the exhaustive set of an  
A/IS’s allowable behaviors for a range of criterion 
Background and Analysis scenarios; weaker ones sample from criterion 
scenarios and illustrate the system’s behavior  
A/IS should have sufficient transparency  
for that subsample. In the latter case, confidence  
to allow evaluation by third parties, including 
in the A/IS’s ability to meet normative 
regulators, consumer advocates, ethicists, 
requirements is more limited. An evaluation’s 
post-accident investigators, or society at large. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 52The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
concluding judgment must therefore  •  Federal Trade Commission. “Big Data: A Tool 
acknowledge the strength of the verification  for Inclusion or Exclusion? Understanding the 
technique used, and the expressed confidence   Issues. FTC Report.” Washington DC: Federal 
in the evaluation (and in the A/IS itself) must   Trade Commission, 2016. 
be qualified by this level of strength. 
•  Fisher, M., L. A. Dennis, and M. P. Webster. 
Transparency is only a necessary requirement  “Verifying Autonomous Systems.” 
for a more important long-term goal, having  Communications of the ACM 56 (2013): 
systems be accountable to their users and  84–93.
community members. However, this goal raises 
•  Griffiths, J. “New Zealand Passport Robot 
many questions such as to whom the A/IS are 
Thinks This Asian Man’s Eyes Are Closed.” 
accountable and who has the right to correct  
CNN.com, December 9, 2016.
the systems, or also which kind of A/IS should  
be subject to accountability requirements.
•  Riek, L. D., and D. Howard. “A Code of Ethics 
for the Human-Robot Interaction Profession.” 
Candidate Recommendation Proceedings of We Robot, April 4, 2014. 
To maximize effective evaluation by third parties 
•  Tatman, R. “Google’s Speech Recognition  
(e.g., regulators, accident investigators), A/IS 
Has a Gender Bias.” Making Noise and 
should be designed, specified, and documented 
Hearing Things, July 12, 2016. 
so as to permit the use of strong verification 
and validation techniques for assessing the 
Further Resources
system’s safety and norm compliance, in order 
to possibly achieve accountability to the relevant  •  Anderson, M., and S. L. Anderson eds. 
communities. Machine Ethics. New York: Cambridge 
University Press, 2011. 
References
•  Abney, K., G. A. Bekey, and P. Lin. Robot 
•  Angwin, J., J. Larson, S. Mattu, L. Kirchner.  Ethics: The Ethical and Social Implications 
“Machine Bias: There’s Software Used Across  of Robotics. Cambridge, MA: The MIT Press, 
the Country to Predict Future Criminals.   2011.
And It’s Biased Against Blacks.” ProPublica, 
•  Boden, M., J. Bryson et al. “Principles  
May 23, 2016. 
of Robotics: Regulating Robots in the Real 
•  British Standards Institution. BS8611:2016,  World.” Connection Science 29, no. 2  
“Robots and Robotic Devices. Guide to the  (2017): 124–129.
Ethical Design and Application of Robots  
•  Coeckelbergh, M. “Can We Trust Robots?” 
and Robotic Systems,” 2016.
Ethics and Information Technology 14 (2012): 
53–60. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 53The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Embedding Values into Autonomous Intelligent Systems
•  Dennis, L. A., M. Fisher, N. Lincoln, A. Lisitsa,  Germany: Schloss Dagstuhl — Leibniz-
and S. M. Veres. “Practical Verification of  Zentrum fuer Informatik, 2009.
Decision-Making in Agent-Based Autonomous 
•  Leet, E. H., and W. A. Wallace. “Society’s  
Systems.” Automated Software Engineering 
Role and the Ethics of Modeling,” in Ethics  
23, no. 3, (2016): 305–359.
in Modeling, edited by W. A. Wallace, 242–
•  Fisher, M., C. List, M. Slavkovik, and A. F.  245. Tarrytown, NY: Elsevier, 1994.
T. Winfield. “Engineering Moral Agents — 
•  Jarvenpaa, S. L., N. Tractinsky, and L. Saarinen. 
From Human Morality to Artificial Morality” 
“Consumer Trust in an Internet Store: 
(Dagstuhl Seminar 16222). Dagstuhl Reports 
A Cross-Cultural Validation.” Journal of 
6, no. 5 (2016): 114–137. 
Computer-Mediated Communication 5, no. 2 
•  Fleischmann, K. R. Information and Human  (1999): 1–37. 
Values. San Rafael, CA: Morgan and Claypool, 
•  Mahmoud, M. A., M. S. Ahmad, M. Z. Mohd 
2014.
Yusoff, and A. Mustapha. “A Review of Norms 
•  Governatori, G., and A. Rotolo. “How Do  and Normative Multiagent Systems.” The 
Agents Comply with Norms?” in Normative  Scientific World Journal, (2014): 1–23. 
Multi-Agent Systems, edited by G. Boella, 
P. Noriega, G. Pigozzi, and H. Verhagen, 
Dagstuhl Seminar Proceedings. Dagstuhl, 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 54The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical  
Research and Design
To ensure autonomous and intelligent systems (A/IS) are aligned to benefit humanity A/IS 
research and design must be underpinned by ethical and legal norms as well as methods. 
We strongly believe that a value-based design methodology should become the essential 
focus for the modern A/IS organization. 
Value-based system design methods put human advancement at the core of A/IS 
development. Such methods recognize that machines should serve humans, and not the 
other way around. A/IS developers should employ value-based design methods to create 
sustainable systems that are thoroughly scrutinized for social costs and advantages that 
will also increase economic value for organizations. To create A/IS that enhances human 
well-being and freedom, system design methodologies should also be enriched by putting 
greater emphasis on internationally recognized human rights, as a primary form of human 
values. 
To help achieve these goals, researchers and technologists need to embrace transparency 
regarding their processes, products, values, and design practices to increase end-user 
and community trust. It will be essential that educational institutions inform engineering 
students about ethics, justice, and human rights, address ethical research and business 
practices surrounding the development of A/IS, and attend to the responsibility of the 
technology sector vis-à-vis public interest issues. The proliferation of value-based design  
will require a change of current system development approaches for organizations,  
including a commitment of research institutions to strong ethical guidelines for research, 
and of businesses to values that transcend narrow economic incentives.
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 55The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
Section 1 — Interdisciplinary  
Education and Research
Integrating applied ethics into education and  programming associated with algorithms and 
research to address the issues of autonomous  machine learning. Thus, ethical issues can easily 
and intelligent systems (A/IS) requires an  be rendered invisible or inappropriately reduced 
interdisciplinary approach, bringing together  and simplified in the context of technical practice. 
humanities, social sciences, science, engineering,  This originates in the fact that many engineering 
and other disciplines.  programs do not sufficiently integrate coursework, 
training, or practical experience in applied ethics 
throughout their curricula; too often ethics is 
relegated to a stand-alone course or module 
that gives students little or no direct experience 
Issue: 
in ethical decision-making in engineering work. 
Inadequate integration   Ethics education for engineering students should 
be meaningful, measurable, and incorporate best 
of ethics in A/IS-related  
practices of STEM ethics education drawn from 
degree programs. 
pertinent multidisciplinary resources. 
The aim of these recommendations is to 
prepare students for the technical training and 
Background
engineering development methodologies that 
AI engineers and design teams too often fail  
incorporate ethics as essential so that ethics  
to thoroughly explore the ethical considerations 
and human rights become naturally part of  
implicit in their technical work and design 
the design process. 
choices. They tend to treat ethical decision-
making as another form of technical problem 
Candidate Recommendations
solving. Although ethical challenges often have 
technical solutions, identifying and ameliorating  Ethics and ethical reflection need to be a core 
those challenges requires technicians to  subject for aspiring engineers and technologists 
methodically inquire about the social context  beginning at the earliest appropriate level and 
of their work. Moreover, technologists often  for all advanced degrees. By training students 
struggle with the imprecision and ambiguity  how to be sensitive to ethical issues in design 
inherent in ethical language, which cannot  before they enter the workplace, they can 
be readily articulated and translated into the  more effectively implement value-based design 
formal languages of mathematics and computer  methodologies in the context of A/IS work.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 56The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
We also recommend that effective STEM ethics  (CCE-STEM) Program, and recommends 
curricula be informed by scientists, artists,  integrative approaches that incorporate  
philosophers, psychologists, legal scholars,  ethics throughout STEM education. 
engineers, and other subject matter experts from 
•  Comparing the UK, EU, and US approaches 
a variety of cultural backgrounds to ensure that 
to AI and ethics: Cath, C. et al. “Artificial 
students acquire sensitivity to a diversity of robust 
Intelligence and the ‘Good Society’:  
perspectives on human flourishing. Such curricula 
The US, EU, and UK Approach.” Science  
should teach aspiring engineers, computer 
and Engineering Ethics (2017).
scientists, and statisticians about the relevance 
and impact of their decisions in designing A/
•  The Oxford Internet Institute (OII) organized 
IS technologies. Effective ethics education in 
a workshop on ethical issues in engineering. 
STEM contexts should span primary, secondary, 
The output paper can be found here: 
and post-secondary education, and include 
Zevenbergen, B. et al. “Philosophy Meets 
both universities and vocational training schools. 
Internet Engineering: Ethics in Networked 
Relevant accreditation bodies should reinforce 
Systems Research.” Oxford, U.K.: Oxford 
this integrated approach as outlined above. 
Internet Institute, University of Oxford, 2015. 
•  Companies should also be encouraged  
Further Resources
to mandate consideration of ethics at the 
•  Holdren, J., and M. Smith. “Preparing for the 
pre-product design stage, as was done  
Future of Artificial Intelligence.” Washington, 
by Lucid AI.
DC: Executive Office of the President, 
National Science and Technology Council,  •  There are a variety of peer-reviewed online 
2016. This White House report makes several  resources collecting STEM ethics curricula, 
recommendations on how to ensure that   syllabi, and education modules:
AI practitioners are aware of ethical issues  
•  Ethics Education Library, Illinois Institute 
by providing them with ethical training. 
of Technology
•  The French Commission on the Ethics  
•  IDEESE: International Dimensions of  
of Research in Digital Sciences and 
Ethics Education in Science & Engineering,  
Technologies (CERNA) recommends 
University of Massachusetts Amherst
including ethics classes in doctoral programs.
•  National Center for Professional & 
•  The U.S. National Science Foundation 
Research Ethics, University of Illinois
has funded extensive research on STEM 
ethics education best practices through 
•  Online Ethics Center, National Academy 
the Cultivating Cultures for Ethical Science, 
of Engineering
Technology, Engineering, and Mathematics 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 57The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
components to encourage integration of ethics 
into projects at all levels. 
Issue: 
The need for more constructive 
Further Resources
and sustained interdisciplinary 
•  Barocas, S. Course Material for Ethics and 
collaborations to address ethical 
Policy in Data Science. 
issues concerning autonomous 
•  Floridi, L., and M. Taddeo. “What Is Data 
and intelligent systems (A/IS).
Ethics?” Philosophical Transactions of  
the Royal Society 374, no. 2083 (2014):  
1–4. doi:10.1098/rsta.2016.0360.
Background
•  Spiekermann, S. Ethical IT Innovation: A 
Not enough institutional resources and incentive 
Value-Based System Design Approach. Boca 
structures exist for bringing A/IS engineers 
Raton, Florida: Auerbach Publications, 2015.
and designers into sustained and constructive 
contact with ethicists, legal scholars, and social  •  The approach developed by the Internet 
scientists, both in academia and industry. This  Research Task Force’s Human Rights Protocol 
contact is necessary as it can enable meaningful  Research Group (HRPC) for integrating 
interdisciplinary collaboration to shape the future  human rights concern in technical design.
of technological innovation. There are currently 
few methodologies, shared knowledge, and 
lexicons that would facilitate such collaborations.
This issue, to a large degree, relates to funding  Issue: 
models as well as the traditional mono-function 
The need to differentiate 
culture in A/IS-related institutions and companies, 
culturally distinctive values 
which limit cross-pollination between disciplines 
(see below). To help bridge this gap, additional  embedded in AI design.
“translation work” and resource sharing (including 
websites and MOOCs) needs to happen among 
technologists and other relevant experts (e.g., 
Background
in medicine, architecture, law, philosophy, 
A responsible approach to embedded values 
psychology, cognitive science).
(both as uncritical bias and as value by design) 
in information and communications technology 
Candidate Recommendations
(ICT), algorithms and autonomous systems 
Funding models and institutional incentive  will need to differentiate between culturally 
structures should be reviewed and revised to  distinctive values (i.e., how do different cultures 
prioritize projects with interdisciplinary ethics 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 58The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
view privacy, or do they at all? And how do  Further Resources
these differing presumptions of privacy inform 
•  Pauleen, D. J. et al. “Cultural Bias in 
engineers and technologists and the technologies 
Information Systems Research and Practice: 
designed by them?). Without falling into 
Are You Coming From the Same Place I 
oversimplified ethical relativism, or embedding 
Am?” Communications of the Association 
values that are antithetical to human flourishing 
for Information Systems 17, no. 17 (2006). 
(for example, human rights violations), it is 
The work of Pauleen et al. (2006) and 
critical that A/IS design avoids only considering 
Bielby (2015) has been guiding in this field: 
monocultural influenced ethical foundations.
“Cultural values, attitudes, and behaviours 
prominently influence how a given group 
Candidate Recommendations
of people views, understands, processes, 
Establish a leading role for intercultural  communicates, and manages data, 
information ethics (IIE) practitioners in ethics  information, and knowledge.” 
committees informing technologists, policy 
•  Bielby, J. “Comparative Philosophies in 
makers, and engineers. Clearly demonstrate 
Intercultural Information Ethics,” Confluence: 
through examples how cultural bias informs not 
Online Journal of World Philosophies 2,  
only information flows and information systems, 
no. 1 (2015): 233–253. 
but also algorithmic decision-making and value  
by design.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 59The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
Section 2 — Corporate Practices  
and A/IS
Corporations, whether for-profit or not-for-profit,  Candidate Recommendations
are eager to develop, deploy, and monetize  
The building blocks of such practices include 
A/IS, but there are insufficient structures in place 
top-down leadership, bottom-up empowerment, 
for creating and supporting ethical systems and 
ownership, and responsibility, and the need to 
practices around A/IS funding, development,  
consider system deployment contexts and/or 
or use.
ecosystems. The institution of an ethical A/IS 
corporate culture would accelerate the adoption 
of the other recommendations within this section 
focused on business practices. 
Issue: 
Further Resources
Lack of value-based ethical 
•  The website of the Benefit corporations 
culture and practices  
(B-corporations) provides a good overview  
for industry.
of a range of companies that personify this 
type of culture. 
•  Firms of Endearment is a book which 
Background
showcases how companies embracing  
There is a need to create value-based ethical 
values and a stakeholder approach 
culture and practices for the development and 
outperform their competitors in the  
deployment of products based on autonomous 
long run. 
and intelligent systems (A/IS). To do so, we need 
to further identify and refine social processes  •  The ACM Code of Ethics and Professional 
and management strategies that facilitate  Ethics, which also includes various  
values-based design in the engineering and  references to human well-being and  
manufacturing process. human rights. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 60The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
AI and Machine Learning at the World Economic 
Forum. The CVO should support system 
Issue: 
innovations and engineering teams to consider 
Lack of values-aware   values and provide them with methodological 
leadership.  guidance on how to do so. However, ethical 
responsibility should not be delegated solely to 
CVOs. CVOs can support the creation of ethical 
knowledge in companies, but in the end all 
Background
members of an innovation team will need to  
Technology leadership should give innovation  act responsibly throughout the design process. 
teams and engineers direction regarding which 
human values and legal norms should be 
Further Resources
promoted in the design of an A/IS system. 
•  United Nations, Guiding Principles on 
Cultivating an ethical corporate culture is an 
Business and Human Rights: Implementing 
essential component of successful leadership  
the United Nations “Protect, Respect and 
in the A/IS domain.
Remedy” Framework, New York and Geneva: 
UN, 2011.
Candidate Recommendations
•  Institute for Human Rights and Business 
Companies need to create roles for senior-
(IHRB), and Shift, SectICTor Guide on 
level marketers, ethicists, or lawyers who can 
Implementing the UN Guiding Principles  
pragmatically implement ethically aligned 
on Business and Human Rights, 2013.
design, both the technology and the social 
processes to support value-based system 
•  Cath, C., and L. Floridi. “The Design of 
innovation. Companies need to ensure that their 
the Internet’s Architecture by the Internet 
understanding of value-based system innovation 
Engineering Task Force (IETF) and Human 
is based on de jure and de facto international 
Rights.” Science and Engineering Ethics 23, 
human rights standards. 
no. 2 (2017): 449–468.
A promising way to ensure values are on the 
•  Butterfield, Kay-Firth (2017). How IEEE  
agenda in system development is to have  
Aims to Instill Ethics in Artificial Intelligence 
a Chief Values Officer (CVO), a role first 
Design. The Institute.
suggested by Kay Firth-Butterfield, Vice-Chair,  
The IEEE Global Initiative and Project Head of 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 61The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
Further Resources
Issue:  •  The British Computer Society (BCS) code  
of conduct holds that individuals have  
Lack of empowerment  
to: “a) have due regard for public health, 
to raise ethical concerns. 
privacy, security and well-being of others  
and the environment. b) have due regard  
for the legitimate rights of Third Parties.  
Background c) conduct your professional activities  
without discrimination on the grounds  
Engineers and design teams can encounter 
of sex, sexual orientation, marital status, 
obstacles to raising ethical concerns regarding 
nationality, colour, race, ethnic origin, religion, 
their designs or design specifications within 
age or disability, or of any other condition  
their organizations. Corporate culture should 
or requirement. d) promote equal access  
incentivize technical staff to voice the full range 
to the benefits of IT and seek to promote  
of ethical questions to relevant corporate actors 
the inclusion of all sectors in society 
throughout the full product lifecycle. Because 
wherever opportunities arise.” 
raising ethical concerns can be perceived as 
slowing or halting a design project, organizations 
•  The Design of the Internet’s Architecture 
need to consider how they can recognize and 
by the Internet Engineering Task Force 
incentivize value-based design as an integral 
(IETF) and Human Rights mitigates the 
component of product development. 
issue surrounding the lack of empowerment 
to raise ethical concerns as they relate to 
Candidate Recommendations human rights by suggesting that companies 
can implement measures that emphasize 
Employees should be empowered to raise ethical 
responsibility-by-design. This term refers 
concerns in day-to-day professional practice, 
to solutions where the in-house working 
not just in extreme emergency circumstances 
methods ensure that engineers have 
such as whistleblowing. New organizational and 
thought through the potential impact of their 
socio-cultural processes that broaden the scope 
technology, where a responsible attitude  
around professional ethics and design need 
to design is built into the workflow.
to be implemented within organizations. New 
categories of considerations around these issues 
need to be accommodated along with new 
forms of Codes of Conduct, so individuals are 
empowered to share their insights and concerns 
in an atmosphere of trust. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 62The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
Iterative review processes are also advisable, in 
part because changes to risk profiles over time 
Issue: 
can illustrate needs or opportunities for improving 
Organizations should examine  the final product.
their cultures to determine  
how to flexibly implement   Candidate Recommendations
value-based design. Companies should study their own design 
processes to identify moments where engineers 
and researchers can be encouraged to raise  
and resolve questions of ethics. Achieving  
Background
a distributed responsibility for ethics requires 
Ethics is often treated as an impediment to 
that all people involved in product design are 
innovation, even among those who ostensibly 
encouraged to notice and respond to ethical 
support ethical design practices. In industries 
concerns, particularly around safety, bias, and 
that reward rapid innovation, it is necessary to 
legality. Organizations should consider how 
develop design practices that integrate effectively 
they can best encourage and accommodate 
with existing engineering workflows. Those who 
lightweight deliberations among peers. 
advocate for ethical design within a company 
should not be seen as innovators seeking the  Additionally, organizations should identify 
best ultimate outcomes for the company, end- points for formal review inside their product 
users, and society. Leaders can facilitate that  development processes. These reviews can  
mindset by promoting an organizational structure  focus on “red flags” that have been identified  
that supports the integration of dialogue about  in advance as indicators of risk. For example,  
ethics throughout product lifecycles. if the datasets involve minors or focus on users 
from protected classes then it may require 
A/IS design processes often present moments 
additional justification or alterations to the 
where ethical consequences can be highlighted. 
research or development protocols. 
There are no universally prescribed models  
for this because organizations vary significantly 
Further Resources
in structure and culture. In some organizations, 
design team meetings may be brief and informal.  •  Sinclair, A. “Approaches to Organizational 
In others, the meetings may be lengthy and  Culture and Ethics.” Journal of Business 
structured. Regardless, team members should  Ethics 12, no. 1 (1993): 63–73. 
understand how to raise such questions without 
•  Chen, A. Y. S., R. B. Sawyers, and P. F. 
being perceived as impediments by peers 
Williams. “Reinforcing Ethical Decision Making 
and managers. The transitions point between 
Through Corporate Culture.” Journal of 
discovery, prototyping, release, and revisions  
Business Ethics 16, no. 8 (1997): 855–865. 
are natural contexts for conducting such reviews. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 63The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
•  Crawford, K., and R. Calo. “There Is a Blind  Candidate Recommendations
Spot in AI Research.” Nature 538 (2016): 
To help integrate applied ethics regarding  
311–313. 
A/IS and in general, organizations need to choose 
specific language that will break down traditional 
biases or barriers and increase adoption of 
values-based design. For instance, an organization 
Issue:  can refer to the “trade-offs” (or “value trade-
offs”) involved in the examination of the fairness 
Lack of ownership or 
of an algorithm to a specific end user population. 
responsibility from the tech 
Organizations should clarify the relationship 
community.
between professional ethics and applied  
A/IS ethics and help designers, engineers, and 
other company representatives discern the 
Background differences between them and where they 
complement each other. 
There is a divergence between the values the 
technology community sees as its responsibility 
Corporate ethical review boards, or comparable 
in regards to A/IS, and the broader set of 
mechanisms, should be formed to address  
social concerns raised by the public, legal, and 
ethical concerns in relation to their A/IS research. 
professional communities. The current makeup  
Such boards should seek an appropriately diverse 
of most organizations has clear delineations 
composition and use relevant criteria, including 
among engineering, legal, and marketing 
both research ethics and product ethics at the 
arenas. Thus technologists feel responsible for 
appropriate levels of advancement of research 
safety issues regarding their work, but for larger 
and development. These boards should examine 
social issues may say, “legal will handle that.” 
justifications of research or industrial projects  
In addition, in employment and management 
in terms of consequences for human flourishing. 
technology or work contexts, “ethics” typically 
refers to a code of conduct regarding professional 
Further Resources
decorum (versus a values-driven design process 
mentality). As such, ethics regarding professional  •  Evolving the IRB: Building Robust Review  
conduct often implies moral issues such as  for Industry Research by Molly Jackman  
integrity or the lack thereof (in the case of  of Facebook explains the differences 
whistleblowing, for instance), but ethics in A/IS  between top-down and bottom up approach 
design includes broader considerations about   to the implementation of ethics within  
the consequences of technologies. an organization and describes Facebook’s 
internal ethics review for research and 
development. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 64The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
•  The article by van der Kloot Meijburg and   academically oriented language about ethics, 
ter Meulen gives a good overview of some   that feedback is often about crucial design detail 
of the issues involved in “developing  gained by experience (form, sound, space, 
standards for institutional ethics committees.”  dialogue concepts). There are successful models 
It focuses specifically on health care  of user experience (UX design) that account for 
institutions in the Netherlands, but the  human factors which should be incorporated 
general lessons drawn can also be applied  to A/IS design as systems are more widely 
to ethical review boards. Examples of  deployed.
organizations dealing with such trade-offs 
can for instance be found in the security  Candidate Recommendations
considerations of the Internet Engineering 
Account for the interests of the full range of 
Task Force (IETF). 
stakeholders or practitioners who will be working 
alongside A/IS, incorporating their insights.  
Build upon, rather than circumvent or ignore, 
the social and practical wisdom of involved 
Issue:  practitioners and other stakeholders. 
Need to include stakeholders  
Further Resources
for adequate ethical  
•  Schroeter, Ch. et al. “Realization and User 
perspective on A/IS. 
Evaluation of a Companion Robot for 
People with Mild Cognitive Impairments.” 
Proceedings of IEEE International Conference 
Background
on Robotics and Automation (ICRA 2013), 
The interface between AI and practitioners,  Karlsruhe, Germany (2013): 1145–1151.
as well as other stakeholders, is gaining 
•  Chen, T. L. et al. “Robots for Humanity:  
broader attention in domains such as health 
Using Assistive Robotics to Empower 
care diagnostics, and there are many other 
People with Disabilities.” IEEE Robotics and 
contexts where there may be different levels 
Automation Magazine 20, no. 1 (2013): 
of involvement with the technology. We should 
30–39.
recognize that, for example, occupational 
therapists and their assistants may have on-the- •  Hartson, R., and P. S. Pyla. The UX Book: 
ground expertise in working with a patient, who  Process and Guidelines for Ensuring a 
themselves might be the “end user” of a robot  Quality User Experience. Waltham, MA: 
or social AI technology. Technologists need to  Elsevier, 2012.
have that stakeholder feedback, because beyond 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 65The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
Section 3 — Research Ethics  
for Development and Testing  
of A/IS Technologies
typically falls to the governance of research 
ethics boards (e.g., institutional review boards). 
Issue: 
The national level and institutional resources 
Institutional ethics committees  (e.g., hospitals and universities) to govern ethical 
are under-resourced to   conduct of HCI, particularly within the disciplines 
pertinent to A/IS research, are underdeveloped. 
address the ethics of R&D  
First, there is limited international or national 
in the A/IS fields.
guidance to govern this form of research. While 
sections of IEEE standards governing research 
on AI in medical devices address some of the 
Background issues related to security of AI-enabled devices, 
the ethics of testing those devices to bring them 
It is unclear how research on the interface 
to market are not developed into recognized 
of humans and A/IS, animals and A/IS, and 
national (e.g., U.S. FDA) or international  
biological hazards will pose practical challenges 
(e.g., EU EMA) policies or guidance documents. 
for research ethical review boards. Norms, 
Second, the bodies that typically train individuals 
institutional controls, and risk metrics appropriate 
to be gatekeepers for the research ethics bodies 
to the technology are not well established in 
(e.g., PRIM&R, SoCRA) are under-resourced in 
the relevant literature and research governance 
terms of expertise for A/IS development. Third,  
infrastructure. Additionally, national and 
it is not clear whether there is sufficient attention 
international regulations governing review  
paid to A/IS ethics by research ethics board 
of human-subjects research may explicitly 
members or by researchers whose projects 
or implicitly exclude A/IS research from their 
involve the use of human participants or their 
purview on the basis of legal technicalities  
identifiable data.
or medical ethical concerns regardless  
of potential harms posed by the research.
Research pertinent to the ethics governing 
research at the interface of animals and  
Research on A/IS human-machine interaction, 
A/IS research is underdeveloped with respect to 
when it involves intervention or interaction with 
systematization for implementation by  
identifiable human participants or their data, 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 66The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
IACUC or other relevant committees. In institutions   Further Resources
without a veterinary school, it is unclear that the 
•  Jordan, S. R. “The Innovation Imperative.” 
organization would have the relevant resources 
Public Management Review 16, no. 1 
necessary to conduct an ethical review of such 
(2014): 67–89.
research.
•  Schneiderman, B. “The Dangers of Faulty, 
Research pertinent to the intersection of 
Biased, or Malicious Algorithms Requires 
radiological, biological, and toxicological research 
Independent Oversight.” Proceedings  
(ordinarily governed under institutional biosafety 
of the National Academy of Sciences of  
committees) and A/IS research is not found  
the United States of America 113, no. 48 
often in the literature pertinent to research 
(2016): 13538–13540.
ethics or research governance. Beyond a limited 
number of pieces addressing the “dual use” or  •  Metcalf, J., and K. Crawford. “Where Are 
import/export requirements for A/IS in weapons  Human Subjects in Big Data Research?  
development, there are no guidelines or  The Emerging Ethics Divide.” SSRN Scholarly 
standards governing topics ordinarily reserved   Paper, Rochester, NY: Social Science  
for review by institutional biosafety committees,  Research Network, 2016. 
or institutional radiological safety committees,  
•  Calo, R. “Consumer Subject Review Boards:  
or laboratory safety committees.
A Thought Experiment.” Stanford Law  
Review Online 66 (2013): 97.
Candidate Recommendations
IEEE should draw upon existing standards, 
empirical research, and expertise to identify 
priorities and develop standards for governance 
of A/IS research and to partner with relevant 
national agencies, and international organizations, 
when possible.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 67The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
Section 4 — Lack of Transparency
Lack of transparency about the A/IS  Further Resources
manufacturing process presents a challenge  
•  Cath, C. J. N., L. Glorioso, and M. R. Taddeo.  
to ethical implementation and oversight.
“NATO CCD COE Workshop on ‘Ethics 
and Policies for Cyber Warfare’” NATO 
Cybersecurity Centre for Excellence 
(CCDCOE) Report. Oxford, U.K.: Magdalen 
College. Addressed indicators of transparency 
Issue: 
along these lines. 
Poor documentation hinders 
•  Turilli, M., and L. Floridi. “The Ethics of 
ethical design.
Information Transparency.” Ethics and 
Information Technology 11, no. 2 (2009): 
105–112.  
Background
•  Wachter, S., B. Mittelstadt, and L. Floridi. 
The limitations and assumptions of a system  
“Transparent, Explainable, and Accountable 
are often not properly documented. Oftentimes  
AI for Robotics.” Science Robotics 2, no. 6 
it is even unclear what data is processed or how.
(2017). 
Candidate Recommendation •  Kroll, J. A., J. Huey, S. Barocas, E. W. Felten, 
J. R. Reidenberg, D. G. Robinson, and H. 
Software engineers should be required to 
Yu. “Accountable Algorithms.” University of 
document all of their systems and related data 
Pennsylvania Law Review 165, no. 1 (2017): 
flows, their performance, limitations, and risks. 
633–705. 
Ethical values that have been prominent in the 
engineering processes should also be explicitly  •  Balkin, J. M., “Free Speech in the Algorithmic  
presented as well as empirical evidence of  Society: Big Data, Private Governance, and 
compliance and methodology used, such as  New School Speech Regulation.” UC Davis 
data used to train the system, algorithms and  Law Review, (2018 forthcoming). 
components used, and results of behavior 
monitoring. Criteria for such documentation  
could be: auditability, accessibility, 
meaningfulness, and readability.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 68The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
Further Resources
Issue:  •  Frank Pasquale, Professor of Law at the 
University of Maryland, provides the  
Inconsistent or lacking oversight 
following insights regarding accountability  
for algorithms. 
in a February, 2016 post for the Media  
Policy Project Blog produced by The London 
School of Economics and Political Science. 
The algorithms behind intelligent or autonomous 
systems are not subject to consistent oversight.  •  Ryan Calo, Associate Professor of Law at  
This lack of transparency causes concern because  the University of Washington, wrote an 
end users have no context to know how a certain  excellent article that gives a detailed overview 
algorithm or system came to its conclusions.  of a broad array of AI policy questions. 
These recommendations are similar to those 
made in committees 1 and 2, but here are used  •  In the United States, a recent court case,  
as they apply to the narrow scope of this group. Armstrong, highlights the need for appropriate  
oversight of algorithmic decision-making,  
to preserve due process and other legal  
Candidate Recommendations
and ethical principles. K.W. v. Armstrong,  
180 F. Supp. 3d 703 (D. Idaho 2016).  
Accountability
In the case, a court ruled that Idaho’s 
As touched on in the General Principles 
Department of Health and Welfare violated 
section of Ethically Aligned Design, algorithmic 
the rights of disabled Medicaid recipients by 
transparency is an issue of concern. It is 
relying upon arbitrary and flawed algorithmic 
understood that specifics relating to algorithms 
decision systems when cutting benefits,  
or systems contain intellectual property that 
and refusing to disclose the decision bases 
cannot be released to the general public. 
as ‘trade secrets.’ See details of the case 
Nonetheless, standards providing oversight of 
here: https://www.aclu.org/news/federal-
the manufacturing process of intelligent and 
court-rules-against-idaho-department-
autonomous technologies need to be created  
health-and-welfare-medicaid-class-action 
to avoid harm and negative consequences of  
and a related discussion of the general risks 
the use of these technologies. Here we can look 
of opaque algorithmic bureaucracies here: 
to other technical domains, such as biomedical, 
https://medium.com/aclu/pitfalls-of-artificial-
civil, and aerospace engineering, where 
intelligence-decisionmaking-highlighted-in-
commercial protections for proprietary technology 
idaho-aclu-case-ec59941fb026
are routinely and effectively balanced with the 
need for appropriate oversight standards and 
mechanisms to safeguard the public.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 69The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
Candidate Recommendations
Issue:  An independent, internationally coordinated 
body should be formed to oversee whether such 
Lack of an independent  
products actually meet ethical criteria, both when 
review organization.
deployed, and considering their evolution after 
deployment and interaction with other products. 
Background Further Resources
We need unaffiliated, expert opinions that  •  Tutt, A. “An FDA for Algorithms.” 
provide guidance to the general public regarding  Administrative Law Review (2017): 83–123. 
automated and intelligent systems. Currently, 
there is a gap between how A/IS are marketed  •  Scherer, M. U. “Regulating Artificial 
and their actual performance, or application.  Intelligence Systems: Risks, Challenges, 
We need to ensure that A/IS technology is  Competencies, and Strategies.” Harvard 
accompanied by best use recommendations,  Journal of Law and Technology 29, no. 2 
and associated warnings. Additionally, we need  (2016): 354–400.
to develop a certification scheme for A/IS 
•  Desai, D. R., and J. A. Kroll. “Trust But  
that ensures that the technologies have been 
Verify: A Guide to Algorithms and the Law.” 
independently assessed as being safe and 
Harvard Journal of Law and Technology 
ethically sound.
(2018 forthcoming). 
For example, today it is possible for systems  
to download new self-parking functionality to 
cars, and no independent reviewer establishes  
or characterizes boundaries or use. Or, when  
Issue: 
a companion robot like Jibo promises to watch 
your children, there is no organization that  Use of black-box components.
can issue an independent seal of approval or 
limitation on these devices. We need a ratings 
and approval system ready to serve social/
Background
automation technologies that will come online 
Software developers regularly use “black-box” 
as soon as possible. We also need further 
components in their software, the functioning  
government funding for research into how  
of which they often do not fully understand. 
A/IS technologies can best be subjected  
“Deep” machine learning processes, which are 
to review, and how review organizations can 
driving many advancements in autonomous 
consider both traditional health and safety  
systems, are a growing source of “black-box” 
issues, as well as ethical considerations. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 70The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
software. At least for the foreseeable future,  dangerous behaviors. Even where such processes 
AI developers will likely be unable to build  remain somewhat opaque, technologists should 
systems that are guaranteed to operate exactly  seek indirect means of validating results and 
as intended or hoped for in every possible  detecting harms. 
circumstance. Yet, the responsibility for resulting 
errors and harms remains with the humans that  Candidate Recommendation
design, build, test, and employ these systems. 
Software engineers should employ “black-box” 
(opaque) software services or components 
Candidate Recommendation
only with extraordinary caution and ethical care, 
When systems are built that could impact the  as they tend to produce results that cannot be 
safety or well-being of humans, it is not enough  fully inspected, validated, or justified by ordinary 
to just presume that a system works. Engineers  means, and thus increase the risk of undetected 
must acknowledge and assess the ethical risks  or unforeseen errors, biases, and harms.
involved with black-box software and implement 
mitigation strategies. Further Resources
•  Pasquale, F. The Black Box Society. 
Candidate Recommendation
Cambridge, MA: Harvard University Press, 
Technologists should be able to characterize   2015.
what their algorithms or systems are going  
•  In the United States, in addition to similar 
to do via transparent and traceable standards. 
commercial endeavors by Oracle and other 
To the degree possible, these characterizations 
companies, DARPA (Defense Advanced 
should be predictive, but given the nature  
Research Projects Agency) recently funded  
of A/IS, they might need to be more retrospective 
a 5-year research program in explainable  
and mitigation oriented. Such standards may 
AI (XAI) methodologies. 
include preferential adoption of effective design 
methodologies for building “explainable AI” (XAI) 
•  Ananny, M., and K. Crawford. (2016).  
systems that can provide justifying reasons or 
“Seeing without Knowing: Limitations of  
other reliable “explanatory” data illuminating the 
the Transparency Ideal and Its Application  
cognitive processes leading to, and/or salient 
to Algorithmic Accountability.” New Media  
bases for, their conclusions.
& Society, December 13, 2016.
•  Another excellent resource on these 
Candidate Recommendation
issues can be found in Chava Gourarie’s 
Similar to a flight data recorder in the field 
“Investigating the Algorithms That Govern 
of aviation, this algorithmic traceability can 
Our Lives.” Columbia Journalism Review, 
provide insights on what computations led to 
April 14, 2016. These recommended reads 
specific results that ended up in questionable or 
come at the end of the article:
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 71The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Methodologies to Guide Ethical Research and Design
•  ”How big data is unfair”: A layperson’s  •  “Certifying and removing disparate 
guide to why big data and algorithms are  impact”: The computer scientist’s 
inherently biased. guide to locating and fixing bias in 
algorithms computationally, by Suresh 
•  “Algorithmic accountability reporting:  
Venkatasubramanian and colleagues. 
On the investigation of black boxes”:  
The primer on reporting on algorithms,  •  The Curious Journalist’s Guide to Data: 
by Nick Diakopoulos, an assistant  Jonathan Stray’s gentle guide to  
professor at the University of Maryland  thinking about data as communication, 
who has written extensively on the  much of which applies to reporting  
intersection of journalism and algorithmic  on algorithms as well.
accountability. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 72The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General  
Intelligence (AGI) and Artificial Superintelligence (ASI)
The concept of intelligence can be difficult to precisely define, and there are many 
proposed definitions. Legg and Hutter (2007) surveyed 70-odd definitions of intelligence, 
pulling out the key features and commonalities between them, and settled on the following: 
“intelligence measures an agent’s ability to achieve goals in a wide range of environments.”
In the context of autonomous and intelligent systems (A/IS), artificial general intelligence 
(AGI) is often used to refer to A/IS that perform comparably to humans on intellectual  
tasks, and artificial superintelligence (ASI or superintelligence) is commonly defined  
as “an intellect that is much smarter than the best human brains in practically every field, 
including scientific creativity, general wisdom and social skills” (Bostrom 2014), passing 
some threshold of generality, well-roundedness, and versatility that present-day AI systems 
do not yet achieve.
Although today’s state-of-the-art A/IS do not match humans in this capacity (since today’s 
systems are only capable of performing well in limited and narrow environments or 
domains), many independent researchers and organizations are working on creating AGI 
systems (including leading AI labs like DeepMind, OpenAI, Microsoft, and Facebook’s FAIR), 
and most AI experts expect A/IS to surpass human-level intelligence sometime this century 
(Grace et al. 2017).
When reasoning about the impacts that AGI systems will have, it is tempting to 
anthropomorphize, assume that these systems will have a “mind” similar to that of  
a human, and conflate intelligence with consciousness. Although it should be possible  
to build AGI systems that imitate the human brain, the human brain represents one point 
in a vast space of possible minds (Yampolskiy 2015). AGI systems will not be subject to 
the same constraints and engineering trade-offs as the human brain (a product of natural 
selection). Thus, we should not expect AGI systems to necessarily resemble human 
brains, just as we don’t expect planes to resemble birds, even though both are flying 
machines. This also means that familiar faculties of intelligent entities we know like morality, 
compassion, and common sense will not be present by default in these new intelligences.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 73The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General  
Intelligence (AGI) and Artificial Superintelligence (ASI)
History shows that the largest drivers of change in human welfare, for better and for worse, 
have been developments in science, technology, and economics. Humanity’s ability to  
drive this change is largely a function of our intelligence. Thus, one can think about 
building AGI as automating scientific, technological, and economic innovation. Given the 
disproportionate impact our intelligence has enabled our species to have on the planet  
and our way of life, we should expect AGI systems to have a disproportionate impact on  
our future, on a scale not seen since the Industrial Revolution. As such, the development 
of AGI systems and improvements of those systems toward superintelligence could bring 
about unprecedented levels of global prosperity. However, it is by no means guaranteed 
that the impact of these systems will be a positive one without a concerted effort by  
the A/IS community and other key stakeholders to align them with our interests.
As with other powerful technologies, the development and use of A/IS have always 
involved risk, either because of misuse or poor design (as simple examples being an 
assembly line worker being injured by a robotic arm or a guard robot running over a child’s 
foot). However, as systems approach and surpass AGI, unanticipated or unintended system 
behavior (due to, e.g., architecture choices, training or goal specification failures, mistakes 
in implementation, or mistaken assumptions) will become increasingly dangerous and 
difficult to correct. It is likely that not all AGI-level A/IS architectures are alignable with 
human interests, and as such, care should be taken to analyze how different architectures 
will perform as they become more capable. In addition to these technical challenges, 
technologists will also confront a progressively more complex set of ethical issues during  
the development and deployment of these technologies.
In section 1 which focuses on technical issues, we recommend that A/IS teams working  
to develop these systems cultivate a “safety mindset,” in the conduct of research in  
order to identify and preempt unintended and unanticipated behaviors in their systems, 
and work to develop systems which are “safe by design.” Furthermore, we recommend 
that institutions set up review boards as a resource to researchers and developers, and 
to evaluate relevant projects and their progress. In Section 2 which focuses on general 
principles, we recommend that the A/IS community encourage and promote the sharing 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 74The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General  
Intelligence (AGI) and Artificial Superintelligence (ASI)
of safety-related research and tools, and that all those involved in the development and 
deployment take on the norm that future highly capable transformative A/IS “should  
only be developed in the service of widely shared ethical ideals, and for the benefit  
of all humanity rather than one state or organization.” (Future of Life Institute 2017)
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 75The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General Intelligence (AGI)  
and Artificial Superintelligence (ASI)
Section 1 — Technical
likely to be more severe in systems that are 
more capable (as follows from their increased 
Issue: 
optimization power and broader action space 
As A/IS become more capable,  range) unless action is taken to prevent them 
as measured by the ability to  from arising.
perform with greater autonomy 
In order to foster safety and controllability,  
across a wider variety of  A/IS that are intended to have their capabilities 
domains, unanticipated or  improved to the point where the above issues 
begin to apply should be designed to avoid those 
unintended behavior becomes 
issues preemptively. When considering problems 
increasingly dangerous.
such as these, teams should cultivate a “safety 
mindset” (as described by Schneier [2008] in the 
context of computer security — to anticipate and 
Background preempt adversaries at every level of design and 
implementation), and suggest that many of these 
A/IS with an incorrectly or imprecisely specified 
problems can likely be better understood by 
objective function (or goals) could behave in 
studying adversarial examples (as discussed  
undesirable ways (Amodei et al. 2016, Bostrom 
by Christiano [2016]) and other A/IS robustness 
2014, Yudkowsky 2008). In their paper, Concrete 
and safety research threads.
Problems in AI Safety, Amodei et al. describe 
some possible failure modes, including: scenarios 
Teams working on such advanced levels of A/IS  
where the system has incentives to attempt to 
should pursue the following goals, all of which 
gain control over its reward channel, scenarios 
seem likely to help avert the above problems:
where the learning process fails to be robust 
to distributional shift, and scenarios where the  1.  Contribute to research on concrete problems 
system engages in unsafe exploration (in the  in AI safety, such as those described by 
reinforcement learning sense). Further, Bostrom  Amodei et al. in Concrete Problems in AI 
(2012) and Omohundro (2008) have argued  Safety, Taylor et al. in Alignment for Advanced 
that AGI systems are likely by default to adopt  Machine Learning Systems, and Russell  
“convergent instrumental subgoals” such as  et al. in Research Priorities for Robust and 
resource-acquisition and self-preservation, unless  Beneficial Artificial Intelligence. See also  
the system is designed to explicitly disincentivize  the work of Hadfield-Menell et al. (2016)  
these strategies. These types of problems are  and the references therein. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 76The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General Intelligence (AGI)  
and Artificial Superintelligence (ASI)
2.  Work to ensure that A/IS are transparent,   5.  Ensure that A/IS are corrigible in the sense  
i.e., that their internal reasoning processes  of Soares et al. (2015), i.e., that the systems 
can be understood by human operators.   are amenable to shutdown and modification 
This likely involves both theoretical and  by the operators, e.g., as with Hadfield-
practical research. In particular, teams  Menell (2017) and Russell et al. (2016), and 
should develop, share, and contribute to  assist (or at least do not resist) the operators 
transparency and debugging tools that make  in shutting down and modifying the system 
the behavior of advanced A/IS easier to  (if such a task is non-trivial). See also the 
understand and work with; and teams should  work of Armstrong and Orseau (2016).
perform the necessary theoretical research  
6.  Explore methods for making A/IS capable  
to understand how and why a system 
of learning complex behaviors and goals  
works at least well enough to ensure that 
from human feedback and examples,  
the system will avoid the above failure 
in spite of the fact that this feedback is 
modes (even in the face of rapid capability 
expensive and sometimes inconsistent, e.g., 
gain and/or a dramatic change in context, 
as newer variants of inverse reinforcement 
such as when moving from a small testing 
learning attempt. See Evans et al. (2015)  
environment to a large world).
and Hadfield-Menell et al. (2016).
3.  Work to build safe and secure infrastructure 
7.  Build extensive knowledge layers and 
and environments for development, testing, 
automated reasoning into systems to expand 
and deployment of powerful A/IS. This work 
their contextual awareness and common 
will provide some protection against risks 
sense so undesirable side effects can  
including subversion by malicious external 
be determined and averted dynamically.
attackers, and unsafe behavior arising from 
exploratory learning algorithms. In particular, 
teams should develop, share, and contribute  Candidate Recommendations
to AI safety test environments and tools and 
1.  Teams working on developing AGI systems 
techniques for “boxing” A/IS (see Babcock 
should be aware that many technical 
et al. [2016] and Yampolskiy [2012] for 
robustness and safety issues are even 
preliminary work).
present in today’s systems and that, given 
more research, some corrective techniques 
4.  Work to ensure that A/IS “fail gracefully” 
for those can likely scale with more complex 
(e.g., shutdown safely or go into some other 
problem manifestations.
known-safe mode) in the face of adversarial 
inputs, out-of-distribution errors (see Siddiqui 
2.  Teams working on developing AGI systems 
et al. [2016] for an example), unexpected 
should be prepared to put significantly  
rapid capability gain, and other large context 
more effort into AI safety research as 
changes.
capabilities grow.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 77The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General Intelligence (AGI)  
and Artificial Superintelligence (ASI)
3.  Teams working on developing AGI systems  closer to the search/optimization/meta end of 
should cultivate a “safety mindset” like a  the spectrum, and Deep Blue closer to the other. 
“security mindset,” vigilant of ways they can 
Realistic AGI systems are likely to fall somewhere 
cause harm and invest in preventing those.
in between, and will be built by a combination  
of human design and search/optimization  
(e.g., gradient descent, trial-and-error, etc.). 
Developing AGI systems without these concerns 
Issue:  in mind could result in complicated systems 
that are difficult or impossible to align with the 
Designing for safety may  
interests of its operators, leading to systems  
be much more difficult later  
that are more vulnerable to the concerns  
in the design lifecycle rather   raised above.
than earlier.
A relevant analogy for this issue is the 
development of the C programming language, 
which settled on the use of null-terminated 
Background strings instead of length-prefixed strings for 
reasons of memory efficiency and code elegance, 
Different types of AGI systems are likely to vary 
thereby making the C language vulnerable to 
widely in how difficult they are to align with 
buffer overflow attacks, which are to this day one 
the interests of their operators. As an example, 
of the most common and damaging types of 
consider the case of natural selection, which 
software vulnerability. If the developers of C had 
developed an intelligent “artifact” (brains) by a 
been considering computer security (in addition 
process analogous to a simple hill-climbing search 
to memory efficiency and code elegance), this 
algorithm. Brains are quite difficult to understand, 
long-lasting vulnerability could perhaps have 
and modifying a brain to be trustworthy when 
been avoided. Paying the upfront cost in this case 
given large amounts of resources and unchecked 
would have prevented much larger costs that we 
power would be extremely difficult or impossible.
are still paying today. (It does require skill though 
Similarly, systems developed using search/ to envision the types of downstream costs that 
optimization, especially those using multiple  can result from upstream architectural changes.)
layers of representations, might be difficult to 
Given that some A/IS development methodologies  
modify/align. At the other end of the spectrum, 
will result in AGI systems that are much easier  
we can imagine systems with more principled 
to align with intentions than other methodologies, 
or explicit designs that are perfectly rational, 
and given that it may be quite difficult to switch 
understandable, and easy to modify/align. On 
development methodologies and architectures 
this spectrum, a system like AlphaGo would be 
late in the development of a highly capable A/IS, 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 78The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General Intelligence (AGI)  
and Artificial Superintelligence (ASI)
great care should be taken by teams developing  action space, is not safe by design. Of course,  
systems intended to eventually reach AGI level  all appropriate safety precautions should be used, 
to ensure that their development methodology,  but safeties such as “boxes,” tripwires, monitors, 
techniques, and architecture will result in a system   action limitations, and so on should be treated  
that can be easily aligned. (See also the discussion   as fail-safes rather than as a first line of defense.
of transparency tools above.)
Candidate Recommendation
As a heuristic, when teams develop potentially 
dangerous systems, those systems should be  When designing an advanced A/IS, researchers 
“safe by design,” in the sense that if everything  and developers should pay the upfront costs to 
goes according to plan, then the safety  ensure, to the extent possible, that their systems 
precautions discussed above should not be  are “safe-by-design,” and only use external 
necessary (see Christiano [2015] for a discussion  restrictions on the system as fail-safes rather than 
of a related concept he terms “scalable AI  as a first line of defense. This involves designing 
control”). For example, a system that has strong  architectures using known-safe and more-safe 
incentives to manipulate its operators, but which  technical paradigms as early in the lifecycle  
cannot do so due to restrictions on the system’s  as possible.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 79The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General Intelligence (AGI)  
and Artificial Superintelligence (ASI)
Section 2 — General Principles
developers themselves should be alert to such 
considerations, review boards can provide 
Issue: 
valuable additional oversight by fielding a diversity 
Researchers and developers will   of disciplines and deliberating without direct 
confront a progressively more  investment in the advancement of research goals.
complex set of ethical and 
Organizations should set up review boards to 
technical safety issues in the  support and oversee researchers working on 
development and deployment   projects that aim to create very capable A/IS. 
AI researchers and developers working on such 
of increasingly capable A/IS.
projects should also advocate that these boards 
be set up (see Yampolskiy and Fox [2013] for 
a discussion of review boards for AI projects). 
Background
There is already some precedent for this, such 
Issues A/IS researchers and developers will  as Google DeepMind’s ethics board (though not 
encounter include challenges in determining  much is known publicly about how it functions).
whether a system will cause unintended  
Review boards should be composed of impartial 
and unanticipated harms — to themselves, the 
experts with a diversity of relevant knowledge 
system’s users, and the general public — as well 
and experience. These boards should be 
as complex moral and ethical considerations, 
continually engaged from the inception of the 
including even the moral weight of certain  
relevant project, and events during the course 
A/IS themselves or simulations they may produce 
of the project that trigger special review should 
(Sandberg 2014). Moreover, researchers and 
be determined ahead of time. These types of 
developers may be subject to cognitive biases 
events could include the system dramatically 
that lead them to have an optimistic view of the 
outperforming expectations, performing rapid 
benefits, dangers, and ethical concerns involved 
self-improvement, or exhibiting a failure of 
in their research.
corrigibility. Ideally review boards would adhere  
Across a wide range of research areas in science,  to some (international) standards or best 
medicine, and social science, review boards  practices developed by the industry/field  
have served as a valuable tool in enabling  as a whole, perhaps through groups like the 
those with relevant expertise to scrutinize  Partnership on Artificial Intelligence, our IEEE 
the ethical implications and potential risks of  Global Initiative, or per the Asilomar AI Principles.
research activities. While A/IS researchers and 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 80The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General Intelligence (AGI)  
and Artificial Superintelligence (ASI)
Review boards should be complemented by other  
measures to draw upon diverse expertise and 
Issue: 
societal views, such as advisory groups, relevant 
workshops and conferences, public engagement  Future A/IS may have the 
processes, and other forums for discussion and  capacity to impact the world 
debate. The incorporation of a wide range of 
on a scale not seen since the 
viewpoints, commensurate with the breadth 
Industrial Revolution.
and scale of potential impact, will support A/IS 
researchers and developers in making optimal 
design decisions without relying solely on the 
oversight of review boards. Background
The development of very capable A/IS could 
Given the transformative impact AGI systems 
completely transform not only the economy,  
may have on the world, it is essential that 
but the global political landscape. Future A/IS  
review boards take into consideration the widest 
could bring about unprecedented levels of  
possible breadth of safety and ethical issues. 
global prosperity, health, and overall well-being,  
Furthermore, in light of the difficulty of finding 
especially given the potential impact of 
satisfactory solutions to moral dilemmas and the 
superintelligent systems (in the sense of Bostrom 
sheer size of the potential moral hazard that one 
[2014]). It is by no means guaranteed that this 
team would face when deploying an AGI-level 
transformation will be a positive one without a 
system, technologists should pursue AI designs 
concerted effort by the A/IS community to shape 
that would bring about beneficial outcomes 
it that way (Bostrom 2014, Yudkowsky 2008). 
regardless of the moral fortitude of the research 
team. Teams should work to minimize the extent 
The academic A/IS community has an admirable 
to which beneficial outcomes from the system 
tradition of open scientific communication. 
hinge on the virtuousness of the operators.
Because A/IS development is increasingly  
taking place in a commercial setting, there  
Candidate Recommendation are incentives for that openness to diminish. 
The A/IS community should work to ensure that 
1.  Organizations working on sufficiently 
this tradition of openness be maintained when 
advanced A/IS should set up review boards 
it comes to safety research. A/IS researchers 
to consider the implications of risk-bearing 
and developers should be encouraged to freely 
proposed experiments and development.
discuss AI safety solutions and share best 
2.  Technologists should work to minimize   practices with their peers across institutional, 
the extent to which beneficial outcomes   industry, and national boundaries.
from the system hinge on the virtuousness  
of the operators.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 81The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Safety and Beneficence of Artificial General Intelligence (AGI)  
and Artificial Superintelligence (ASI)
Furthermore, institutions should encourage A/IS  In 2017, broad coalitions of AI researchers, 
researchers and developers, who are concerned  ethicists, engineers, businesspeople, and social 
that their lab or team is not following safety best  scientists came together to form and to endorse 
practices, to raise this to the attention of the  the Asilomar AI Principles (Future of Life Institute 
wider A/IS community without fear of retribution.  2017), which includes the relevant principles  
Any group working to develop capable A/IS   “14) Shared Benefit: AI technologies should 
should understand that, if successful, their  benefit and empower as many people as 
technology will be considered both extremely  possible. ... 15) Shared Prosperity: The economic 
economically and politically significant.  prosperity created by AI should be shared  
Accordingly, for non-safety research and results,  broadly, to benefit all of humanity. ... 23) Common  
the case for openness is not quite so clear-cut.  Good: Superintelligence should only be developed  
It is necessary to weigh the potential risks of  in the service of widely shared ethical ideals,  
disclosure against the benefits of openness,  and for the benefit of all humanity rather than 
as discussed by Bostrom (2016) and Krakovna  one state or organization.”
(2016).
Candidate Recommendations
In his book Superintelligence, philosopher Nick 
Bostrom proposes that we adopt a moral norm  1.  Adopt the stance that superintelligence 
which he calls the common good principle:  should be developed only for the benefit  
“Superintelligence should be developed only   of all of humanity.
for the benefit of all humanity and in the service 
2.  De-stigmatize and remove other soft 
of widely shared ethical ideals” (Bostrom 2014, 
and hard barriers to AI researchers and 
254). We encourage researchers and developers 
developers working on safety, ethics,  
aspiring to develop these systems to take on  
and beneficence, as well as being open 
this norm. It is imperative that the pursuit and  
regarding that work.
realization of AGI systems be done in the  
service of the equitable, long-term flourishing  
of civilization.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 82The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Autonomous and Intelligent systems (A/IS) are developing faster than the supporting 
standards and regulation required for transparency and societal protections can keep pace. 
The impact of these systems on society is direct and considerable.
A/IS require data to fuel learning, and inform automatic decision-making. Increasingly this 
data is personal data, or personally identifiable information, known as PII. PII is defined 
as any data that can be reasonably linked to an individual based on their unique physical, 
digital, or virtual identity. As a result, through every digital transaction (explicit or observed) 
humans are generating a unique digital shadow of their physical self. 
Ethical considerations regarding data are often focused largely on issues of privacy — what 
rights should a person have to keep certain information to themselves or have input into 
how it is shared? However, individuals currently lack clarity around how to access, organize, 
and share their data to ensure unintended consequences are not the Laws are generally 
enforceable result. Without clarity, these issues will continue to reflect negatively on the 
proliferation of the A/IS industry.
The aim of this Committee is to set out the ethical considerations in the collection and  
use of personal data when designing, developing, and/or deploying A/IS. Furthermore,  
to entreat all global (A/IS) technologists (academics, engineers, programmers, manufacturers,  
and policy makers) to proactively prioritize and include individuals in the data processes  
that directly relate to their identity.
There is a fundamental need for people to have the right to define access and provide 
informed consent with respect to the use of their personal data (as they do in the physical  
world). Individuals require mechanisms to help curate their unique identity and personal data  
in conjunction with policies and practices that make them explicitly aware of consequences  
resulting from the bundling or resale of their personal information and life experiences. 
Enabling individuals to curate their identities and manage the ethical implications of their 
data use will remain essential to human culture everywhere in the world. While some may 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 83The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
choose only minimum compliance to legislation like the European General Data Protection 
Regulation (GDPR), forward-thinking organizations will shift their data strategy (marketing, 
product, and sales) to enable methods of harnessing volunteered intentions from customers 
(or in governmental contexts, citizens), versus only invisibly tracking their attention or actions.
For individuals to be at the center of their data, policy makers and society at large will need 
to rethink the nature of standards and human rights as they have been applied to the 
physical world and to re-contextualize their application in the digital world. While standards 
exist, or are in production relating to augmented and virtual reality, human rights law, 
privacy and data, it is still largely not understood how human agency, emotion, and the legal 
issues regarding identity will be affected on a large scale by society once A/IS technologies 
become ubiquitous. 
The goal of the analysis of these ethical issues and considerations by this Committee 
regarding data usage and identity is to foster a positive and inclusive vision for our shared 
future. To accomplish this goal, this document is focused on the following themes: 
1.  Digital Personas
2.  Regional Jurisdiction
3.  Agency and Control
4.  Transparency and Access
5.  Symmetry and Consent
We have also created an Appendix document listing key resources referenced in the  
following section. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 84The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Addressing these issues and establishing safeguards prioritizing the protection and assets 
of individuals regarding privacy and personal data in the realms of A/IS is of paramount 
importance today. To that end, since the creation of the first draft of Ethically Aligned Design 
this Committee recommended ideas for the following IEEE Standards Working Groups which 
have been and approved and are free for all to join (click on links for details): 
•  IEEE P7002™, Data Privacy Process 
•  IEEE P7004™, Standard on Child and Student Data Governance 
•  IEEE P7005™, Standard on Employer Data Governance 
•  IEEE P7006™, Standard for Personal Data Artificial Intelligence (AI) Agent
The goal of this Committee is that our recommendations, in conjunction with the 
development and release of these Standards once adopted, will expedite the prioritization 
and inclusion of all global individuals in the data processes that directly relate to their identity.
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 85The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Section 1 — Digital Personas
While many individuals may not currently have 
the ability to claim their identity (in the case of 
Issue: 
refugees, etc.), as a rule society understands how 
to apply the legal concepts of identity in real-life  Individuals do not understand 
situations. In digital or virtual realms, however,   that their digital personas  
our personas are fluid — individuals can be 
and identity function differently 
avatars in gaming situations or take on a different 
than in real life. This is a concern 
tone in various social networking settings. 
when personal data is not 
Behaviors regarding our personas considered 
normal in real-life are not directly applicable in  accessible by an individual and 
the augmented, virtual and mixed reality worlds  the future iterations of their 
most individuals will soon be inhabiting on a 
personas or identity cannot  
regular basis in the near future. In regards to the 
be controlled by them, but by  
algorithms powering AI, or the affective sensors 
the creators of the A/IS they use. 
becoming standard features in autonomous 
vehicles, or companion robots, etc., how A/IS  
affects our digital personas through use or 
misuse of our data is critical to understand,  Background
monitor, and control. 
A/IS created from personal experiences is 
different from AI created from farming or climate 
data. Society has had traditional safeguards on 
the use and application of personal information 
to encourage innovation and to protect minorities. 
Traditional systems for medicine and law limit 
secrecy and favor regulation of professionals 
at the edges over centralized hierarchical 
corporations. For example, almost 100% of 
intellectual property in the domains of medicine 
and law is open, peer-reviewable, and can be 
taught to anyone, anywhere. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 86The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
However, the emergence of the Internet of   •  Professional training, internship, and work  
Things (IoT) and augmented reality/virtual reality  (tax and employment data)
(AR/VR) means personal information forms  
•  Societal participation (online forums,  
a foundation for every system being designed. 
voting and party affiliation data)
This data acts as the digital representation and 
proxy for our identity. From birth, the different 
•  Contracts, assets, and accidents (insurance 
roles individuals take on in life provide specific 
and legal data)
contexts to the data they generate. Previously 
these contexts and roles enabled individuals to  •  Financial participation (banking and  
maintain some level of privacy due to the siloes  finance data)
of collection. Now, as the prospect of an omni-
•  Death (digital inheritance data)
connected world approaches, those silos are 
being replaced by horizontal integrations that put  By the time individuals reach early adulthood, 
the digital versions of personas and roles at risk.  they are simultaneously acting across these roles, 
It is therefore important that citizens understand  generating vast amounts of personal data that 
these roles and their related data to assess  is highly contextual and easy to identify and link 
the downstream (further) consequences of its  directly to an individual. If an individual’s digital 
aggregation. Digital personas/roles include: shadow is a proxy of their physical self, then 
technologists and policy makers must address  
•  Pre-birth to post-life digital records  
the transparency, control, and asymmetry of  
(health data)
how personal data is collected and used to 
•  Birth and the right to claim citizenship  enable A/IS. A/IS technologists need to recognize  
(government data) the coercive nature of many current identity 
schemes — such as hidden tracking by advertising 
•  Enrollment in school (education data)
brokers — and adopt privacy-preserving identity 
practices such as same-domain pseudonymous 
•  Travel and services (transport data)
identifiers and self-sovereign identity.
•  Cross-border access and visas  
(immigration data) Candidate Recommendation
•  Consumption of goods and services  The ethics of creating secret and proprietary  
(consumer and loyalty data) A/IS from people’s personally identifiable 
information (PII) need to be considered based  
•  Connected devices, IoT and wearables 
on the potential impact to the human condition. 
(telecommunications data)
To preserve human dignity, policies, protections, 
and practices must provide all individuals the 
•  Social and news networks (media and 
same agency and control over their digital 
content data) 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 87The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
personas and identity they exercise in their real- — are emerging alongside legal identities  
world iterations no matter what A/IS may be in  (issued by governments, banks, and regulatory 
place to monitor, assist, or interact with their data.  authorities) to help put individuals at the center 
of their data in the algorithmic age.
Further Resources 
Personas (an identity that acts as a proxy) and 
•  Blockchain Identity (Rebooting Web-of-Trust). pseudonymity are also critical requirements for 
privacy management since they help individuals 
•  W3C Credentials Community Group.
select an identity that is appropriate for the 
context they are in or wish to join. In these 
•  HIE of One.
settings, trust transactions can still be enabled 
without giving up the “root” identity of the user. 
For example, it is possible to validate a user is 
over 18 (for adult content) or eligible for a service 
Issue:  (postcode confirmation). Attribute verification 
(comprising the use of empowered persona 
How can an individual  
usage by an individual) will play a significant role 
deﬁne and organize his/her 
in enabling individuals to select the identity that 
personal data and identity  
provides access without compromising agency. 
in the algorithmic era? This type of access is especially important in 
dealing with the myriad algorithms interacting 
with data representing tiny representations of our 
identity where individuals typically are not aware 
Background
of the context for how their data will be used. 
Identity is emerging at the forefront of the risks 
and opportunities related to use of personal  
Candidate Recommendation
data for A/IS. Across the identity landscape there 
is increasing tension between the requirement   Individuals should have access to trusted identity 
for federated identities (all data linked to a natural  verification services to validate, prove, and 
and identified natural person) versus a range   support the context-specific use of their identity. 
of identities (personas) that are context specific  Regulated industries and sectors such as banking, 
and determined by the use-case, for example  government, and telecommunications should 
opening a bank account, crossing a border, or  provide data-verification services to citizens and 
ordering a product online. New movements, such  consumers to provide greatest usage and control 
as Self-Sovereign Identity — defined as the right  for individuals.
of a person to determine his or her own identity 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 88The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Further Resources  is free and open to anyone wishing to join 
and addresses issues relating to how an 
•  The Inevitable Rise of Self-Sovereign Identity 
individual could have the ubiquitous and 
by The Sovrin Foundation.
always-on services of a personalized AI agent 
•  See Identity Examples in the Appendix  to ensure their identity is protected and has 
Document for this section. symmetry with the A/IS their data comes  
into contact with at all times. 
•  IEEE P7006™, Standard for Personal Data 
Artificial Intelligence (AI) Agent Working 
Group. This Standards Working Group  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 89The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Section 2 — Regional Jurisdiction
Legislation regarding personal data varies  Background
widely around the world. Beyond issues of data 
Ethical considerations regarding data are often 
operability issues when transferring between 
focused largely on issues of privacy — what 
country jurisdictions, rights of individuals and 
rights should a person have to keep certain 
their access and usage of data depends on  
information to themselves, or have input into 
the regions and laws where they live. Much  
how it is shared? While rhetoric in various circles 
of A/IS ethics involves the need to understand 
stating, “privacy is dead” may be someone’s 
cultural aspects of the systems and services an 
personal opinion reflecting their values, privacy 
organization wishes to create for specific users. 
is nonetheless a fundamental human right 
This same attention must be given to how data 
recognized in the UN Declaration of Human 
related to A/IS are positioned from a regional 
Rights, the International Covenant on Civil and 
perspective to best honor the use, or potential 
Political Rights, and in many other international 
abuse of the global citizens’ data. A/IS will also 
and regional treaties.
be subject to regional regulation, for example 
under the General Data Protection Regulation  However, this fundamental right is not universally 
(GDPR), European citizens may have specific  recognized or supported. It is also culturally 
rights of redress where AI or AS has been used. contextual and nuanced. It is therefore critical  
to understand the jurisdictional and specific legal 
requirements that govern the access and use 
of personal information when developing A/IS 
solutions. These include, but are not limited to:
Issue: 
•  Europe; the introduction of the General  
Country-wide, regional,  
Data Protection Regulation (GDPR), Personal 
or local legislation may  
Services Directive II (PSD2), and ePrivacy. 
contradict an individual’s   These new regulations carry substantial  
values or access and control   fines for non-compliance. Depending on the 
nature and circumstances of the violation, 
of their personal data. 
these penalties may include:
•  A warning in writing in cases of first  
and non-intentional non-compliance
•  Regular periodic data protection audits
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 90The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
•  A fine up to 10,000,000 EUR or up   •  Australia: In addition to strict privacy 
to 2% of the annual worldwide turnover  regulation, the Australian Productivity 
of the preceding financial year in case  Commission issued reports in 2016 and  
of an enterprise, whichever is greater   2017 acknowledging that personal 
(Article 83, Paragraph 4) information is a personal asset and therefore 
recognized the need for Australians to have 
•  A fine up to 20,000,000 EUR or up  
control with respect to its collection and  
to 4% of the annual worldwide turnover 
use. At the time of publication, The Australian 
of the preceding financial year in case 
Federal Government is in the process of 
of an enterprise, whichever is greater 
using these reports to inform the drafting  
(Article 83, Paragraph 5 and 6)
of new personal data regulation.
•  United States: The United States lacks  
•  Japan: The Act on the Protection of Personal 
a single “baseline” privacy regime; instead, 
Information was amended in 2016. The act 
policies and procedures affecting the 
precisely defines the definition of personal 
collection and use of PII varies based 
information; however, the concept of privacy 
on type of information and which entity 
is not explicitly stated. In this sense, the act 
possesses the data. Laws, for example, afford 
is deemed as a practice-oriented law. The 
certain procedural requirements around 
new concept of anonymously processed 
financial data, certain protected health 
information is introduced which is produced 
information, and children’s data. Laws are 
to make it impossible to identify a specific 
generally enforceable by state and federal 
individual. In addition, it can be transferred 
regulators (including the Federal Trade 
to, and used by, the third parties without 
Commission and state attorney general), 
the data subject’s consent. The method 
though individuals may have private rights 
of producing anonymously processed 
of action under state law or certain federal 
information will be determined on a sector-
laws such as the Video Privacy Protection 
by-sector basis because each sector has 
Act, which governs disclosures of identifiable 
distinct constraints and purposes of personal 
video rental records, and the Fair Credit 
information.
Reporting Act, which provides access and 
rights to consumer reports used for eligibility  Additionally, there is growing evidence that  
determinations. See also: Jurisdiction  not providing clear consent (regarding personal 
Examples in the Appendix Document for   data usage) decreases mental and emotional 
this section.  well-being. The rapid rise in ad blocking tools  
  or lowering of consumer trust via reports  
  of non-ethically driven online studies provides 
  tangible evidence toward the failure of these 
clandestine efforts. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 91The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Candidate Recommendation Further Resources 
While specific uses of data must be taken in  •  Amended Act on the Protection of Personal 
context of the regions where specific legislation  Information in Japan.
applies, individuals should always be provided 
•  Outline of the Amended Personal Information 
access to, and control of, their data to ensure 
Protection Act in Japan.
their fundamental human rights are honored 
without fear of the risk of breaking applicable laws. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 92The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Section 3 — Agency and Control
Agency is the capacity of individuals to act  Background
independently and to exercise free choice, a 
Different laws and regulations around the globe 
quality fundamental to democratic ideals. Central 
define the scope of PII differently. The use of 
to human agency is control. As society moves 
data analytics to derive new inferences and 
towards complete connectivity, humans will 
insights into both personal data and technical 
require tools and mechanisms to enable agency 
metadata raises new questions about what types 
and control over how their personal data is 
of information should be considered PII. This  
collected and used. When people do not have 
is further complicated by machine learning and 
agency over their identities political participation 
autonomous systems that access and process 
is impossible, and without political participation 
data faster than ever before.
ethics will be decided by others. As the rise  
of algorithms accessing people’s data relating   Multiple global bodies believe PII is a sovereign 
to their identities continues, there is increased  asset belonging to an identified individual. PII,  
risk of loss of agency and well-being, adding   or personal data, is defined as any data that can 
the potential for depression and confusion along  be reasonably linked to an individual based on 
with the lack of clear ways to contribute ideas   their unique physical, digital, or virtual identity.  
in an open and democratic fashion. PII protections are often related to the U.S.  
Fourth Amendment, as the right of the people  
to be secure in their persons, houses, papers, 
and effects.
Issue:  As further clarification, the European Union 
definition of personal data set forth in the  
To understand the role of  
Data Protection Directive 95/46/ECl vi, defines 
agency and control within A/IS,  
personal data as “any information relating to 
it is critical to have a deﬁnition  an identified or identifiable natural person.” 
and scope of personally  Identifiable when? The question asked today  
will have a very different answer tomorrow given 
identiﬁable information (PII).
that all A/IS person-level or device-level data  
is identifiable if the tech advances and the data  
is still available. Agency requires that the control 
be exercised by the subject at the time the data 
is used, not at the time the data is collected. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 93The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Overall, personal data reflects self-determination 
and the inalienable right for an individual to be 
Issue: 
able to access and control the attributes of their 
physical, digital, and virtual identity.  What is the deﬁnition of  
control regarding personal  
Candidate Recommendation data, and how can it be 
Individuals should have access to means that  meaningfully expressed?
allow them to exercise control over use of 
personal data at the time the data is used.  
If that agency and control is not available,  
Background 
person-level data needs to either be aggregated 
Most individuals believe controlling their personal 
into larger cohorts and the person-level data 
data only happens on the sites or social networks 
deleted. PII should be defined as the sovereign 
to which they belong, and have no idea of the 
asset of the individual to be legally protected  
consequences of how that data may be used  
and prioritized universally in global, local, and 
by others tomorrow. Providing individuals with 
digital implementations regardless of whether 
tools, like a personal data cloud, can empower 
deemed to be de-identified in the way it  
users to understand how their data is an asset  
is stored.
as well as how much data they produce. Tools 
like personal data vaults or clouds also let 
Further Resources  individuals organize their data around various 
uses (medical, social, banking). Control enables 
•  Determining What Is Personal Data,  
individuals to also assert a version of their own 
U.K. Information Commissioner’s Office. 
terms and conditions.
•  Electronic Communications Privacy Act.
In the current context of A/IS technologies, and 
•  Open PDS. in the complex and multi-level or secondary 
uses of data, it is important to be clear about the 
•  IEEE Digital Inclusion through Trust and  boundaries of control for use of personal data 
Agency Industry Connection Program. that can affect an individual directly compared 
to collection of data for aggregated or systematic 
•  HIE of One — a patient-owned and controlled 
work (and exceptions for approved research). 
standards-based, open source EHR, so 
For example, an individual subway user’s travel 
patients can collect, aggregate, and share 
card, tracking their individual movements, should 
their own data. 
be protected from uses that identify or profile 
that individual to make inferences about his/her 
likes or location generally, but could be included 
in the overall travel systems management to 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 94The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
aggregate user data into patterns for scheduling  Further Resources
and maintenance as long as the individual-level 
•  Project VRM — vendor relationship 
data is deleted.
management (VRM) tools and frameworks.
The MyData movement combines related 
•  Kuan Hon, W. K., C. Millard, and I. 
initiatives, such as Self Data, Vendor Relationship 
Walden. “The Problem of ‘Personal Data’ 
Management, Internet of Me, and Personal 
in Cloud Computing — What Information 
Information Management Systems (PIMS) under 
Is Regulated? Cloud of Unknowing, Part 
a common cause to empower individuals with 
1.” Queen Mary School of Law Legal 
their personal data. The Declaration of MyData 
Studies Research Paper No. 75/2011; 
Principles highlights human-centric control 
International Data Privacy Law 1, no. 4 
of personal data as one of core principles, 
(2011): 211–228.  
emphasizing that people should be provided 
with the practical means to understand and  •  Boyd, E. B. “Personal.com Creates an 
effectively control who has access to data about  Online Vault to Manage All Your Data.” 
them and how it is used and shared. In detail,  Fast Company, May 7, 2012.  
the MyData Declaration states: “We want privacy, 
•  Meeco Life Management Platform. Personal 
data security and data minimization to become 
cloud, attribute wallet and personal data 
standard practice in the design of applications. 
management tools, consent engine and  
We want organizations to enable individuals to 
dual sided permission APIs. 
understand privacy policies and how to activate 
them. We want individuals to be empowered to 
•  MyData2017. Declaration of MyData 
give, deny or revoke their consent to share data 
Principles.
based on a clear understanding of why, how and 
for how long their data will be used. Ultimately,  •  Poikola, A. K. Kuikkaniemi, and H. Honko 
we want the terms and conditions for using  (Ministry of Transport and Communications). 
personal data to become negotiable in a fair   MyData — A Nordic Model for Human-
way between individuals and organizations.” Centered Personal Data Management  
and Processing. Finland: Prime Minister’s 
Candidate Recommendation Office, 2014. 
Personal data access and consent should be  •  Hasselbalch, G., and P. Tranberg. “Personal 
managed by the individual using systems that  Data Stores” (chapter 12), in Data  
provide notification and an opportunity for  Ethics: The New Competitive Advantage. 
consent at the time the data is used, versus  Publishare, 2016.
outside actors being able to access personal data 
•  GDPR Article 20, Right to Data Portability, 
outside of an individual’s awareness or control.
Article 29 Working Party, Brussels, 2016. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 95The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
•  Thurston, B. “A Radical Proposal for   •  uPort is an open source software project  
Putting People in Charge of Their Data.”   to establish a global, unified, sovereign 
Fast Company, May 11, 2015.  identity system for people, businesses, 
organizations, devices, and bots. The 
•  de Montjoye, Y.-A., Wang, S. S., and Pentland, 
Ethereum based self-sovereign identity 
A. S. “openPDS: Protecting the Privacy of 
system now in alpha testing. 
Metadata through SafeAnswers.” PLoS ONE 
9, no. 7 (2014): e98790. •  Sovrin—identity for all. The Sovrin Foundation 
describes self-sovereign identity (SSI) as  
•  Definition of the right to be forgotten. 
“...an identity that is 100% owned and 
controlled by an individual or organization. 
•  IEEE Digital Inclusion through Trust and 
No one else can read it, use it, turn it  
Agency. The Industry Connection Program 
off, or take it away without its owner’s  
develops comprehensive roadmaps, industry 
explicit consent.” 
action reports, and educational platforms 
working to address issues around cyber-
•  Nichol, P. B. “A Look at India’s Biometric ID 
identity, digital personas, distributed ledger 
System: Digital APIs for a Connected World.” 
technology, and inclusion of underserved and 
CIO Perspectives, February 23, 2017.
vulnerable.
•  See also Appendix 3: Digital Divide and  
•  See “The Attribute Economy 2.0,” a multi-
Pay for Privacy.
authored paper published by Meeco.
•  See also Appendix 4: Examples of Agency 
•  The Path to Self-Sovereign Identity.  
and Transparency.
 
  •  See also Appendix 5: Can Personal Data 
  Remain Anonymous?
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 96The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Section 4 — Transparency and Access
Much of the contention associated with the 
concept of “privacy” actually relates to access. 
Issue: 
Challenges often arise around transparency 
and providing an explicit understanding of the  It is often difﬁcult for users  
consequences of agreeing to the use of people’s  to determine what information 
personal data. This is complicated by the  
a service provider or A/IS 
data-handling processes behind true “consent.” 
application collects about them 
Privacy rights are often not respected in the 
at the time of such aggregation/
design and business model of services using  
said data. They obscure disclosure of the ways  collection (at the time of 
the data is used and make it hard to know what  installation, during usage,  
data was used. This can be especially evident 
even when not in use, after 
via the invisible algorithms representing multiple 
deletion). It is difﬁcult for users 
services that access people’s data long after 
to correct, amend, or manage 
they’ve provided original access to a service  
or their partners. this information. 
If individuals cannot access their personal data 
and account for how it is used, they cannot 
Candidate Recommendation
benefit from the insights that the data could 
provide. Barriers to access would also mean  Service providers should ensure that personal 
that individuals would not be able to correct  data management tools are easy to find and  
erroneous information or provide the most  use within their service interface. Specifically: 
relevant information regarding their lives to 
•  The data management tools should make  
trusted actors. Transparency is also about 
it clear who has access to a user’s data and 
notification. It is important that an individual  
for what purpose, and (where relevant) allow 
is notified when their data is collected, and  
the user to manage access permissions.
what usage is intended. In accordance with  
the GDPR, consent must be informed, explicit, 
•  There should be legal, reputational, and 
and unambiguous.
financial consequences for failing to adhere 
to consent terms.
•  It should be easy for users to remove their 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 97The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
data from the service. (Note: This is a   Background
GDPR requirement. It may not be mandated 
Because the ethical implications of intelligent 
in the United States or for other services in 
systems are so difficult to discern, interested 
countries outside of the EU, but represents  
parties would benefit from analytical tools to 
a best-in-class practice to follow.) 
implement standards and guidelines related to 
Organizations should create open APIs to 
A/IS and privacy impacts. Like an environmental 
their data services so that customers can 
impact study or the GDPR privacy impact 
access their data and governments should 
assessments, A/IS impact assessments would 
share the data they collect about their  
provide organizations with tools to certify their 
users directly with individuals and encourage 
products and services are safe and consistent  
them to ensure its accuracy for mutual  
for the general public.
value to combat the rising issue of dirty data. 
Candidate Recommendation
Further Resources
A system to assess privacy impacts related to A/IS  
•  The User Managed Access Standard, 
needs to be developed, along with best practice 
proposed by The Kantara Initiative, provides  
recommendations, especially as automated 
a useful model to address these types  
decision systems spread into industries that are 
of use cases. 
not traditionally data-rich.
•  Surveys about how adults feel about health 
IT in 2005 and 2016 show that distrust of  Further Resources
health technology has grown from 13% that 
In the GDPR in the EU, there is a requirement 
withheld data from providers due to mistrust 
for a privacy impact assessment. The full report 
to 89%. 
created by PIAF, The Privacy Impact Assessment 
Framework can be found here. In the report,  
of interest is Section 10.3, “Best Elements” 
whose specific recommendations provide  
insights into what could be emulated to  
Issue: 
create an AI impact assessment, including:
How do we create privacy  
•  PIA guidance documents should be aimed 
impact assessments related  
at not only government agencies but also 
to A/IS? 
companies or any organization initiating 
or intending to change a project, product, 
service, program, policy, or other initiative 
  that could have impacts on privacy.
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 98The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
•  PIAs should be undertaken about any project, 
product, service, program, or other initiative, 
Issue: 
including legislation and policy, which are 
explicitly referenced in the Victoria Guide   How can AI interact with 
and the UK Information Commissioner’s  government authorities to 
Office (ICO) Handbook.
facilitate law enforcement and 
Information privacy is only one type of privacy.   intelligence collection while 
A PIA should also address other types of   respecting rule of law and 
privacy, e.g., of the person, of personal behavior, 
transparency for users?
of personal communications, and of location. 
•  PIAF Consortium. “PIAF: A Privacy Impact 
Assessment Framework for Data Protection  Background
and Privacy Rights,” 2011. Section 10.3. 
Government mass surveillance has been  
•  See the Personalized Privacy Assistant   a major issue since allegations of collaboration 
for a project applying these principles. between technology firms and signals 
intelligence agencies such as the U.S. National 
•  While not explicitly focused on PIAs   Security Agency and the U.K. Government 
or AI, IEEE P7002™ Data Privacy Process   Communications Headquarters were revealed. 
is a Standards Working Group still open   Further attempts to acquire personal data by law 
to join focused on these larger issues of   enforcement agencies, such as the U.S. Federal 
data protection required by the enterprise   Bureau of Investigation, have disturbed settled 
for individuals’ data usage.  legal principles regarding search and seizure. 
A major source of the problem concerns the 
•  Usable Privacy Policy project for examples  
current framework of data collection and storage, 
of how difficult privacy policies can be  
which puts corporate organizations in custody of 
to maneuver.
personal data and detached from the generators 
•  See also Appendix 4: Examples of Agency  of that information. Further complicating this 
and Transparency. concern is the legitimate interest that security 
services have in trying to deter and defeat 
 
criminal and national security threats.
 
 
Candidate Recommendations
 
  Personal privacy A/IS tools such as IEEE P7006™ 
have the potential to change the data paradigm 
and put the generators of personal information  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 99The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
at the center of collection. This would re-define  •  Each request for data acquisition must come 
the security services’ investigative methods to  on a case-by-case basis versus an ongoing 
pre-Internet approaches wherein individuals  access form of access, unless the ongoing 
would be able to control their information while  access has become law.
providing custody to corporate entities under 
•  Data-acquisition practices need to factor 
defined and transparent policies. 
in the potential status of purely virtual 
Such a construct would mirror pre-Internet  representations of a citizen’s identity, whether 
methods of information management in which  they do not have formal country of origin 
individuals would deposit information in narrow  (physical) status, or their virtual identity 
circumstances such as banking, healthcare,  represents a legal form of identity.
or in transactions. This personal data AI agent 
•  Phasing in personal privacy AIs will mitigate 
would include root-level settings that would 
risks while pre-empting reactive and 
automatically provide data to authorities after 
disruptive legislation.
they have satisfied sufficiently specific warrants, 
subpoenas, or other court-issued orders, unless 
•  Legal jurisdiction over personal privacy  
authority has been vested in other agencies by 
A/IS access will need to be clarified.
local or national law. Further, since corporately 
held information would be used under the 
Further Resources
negotiated terms that the A/IS agent facilitates, 
authorities would not have access unless legal  •  UNECE. “Evaluating the Potential of 
exceptions were satisfied. This would force  Differential Privacy Mechanisms for Census 
authorities to avoid mass collection in favor   Data.” Work Session on Statistical Data 
of particularized efforts: Confidentiality 2013. Ottawa, October 28, 
2013.
•  The roots of the personal privacy A/IS should 
be devoid of backdoors that allow intrusion  •  CASD — Le Centre D’Accès Sécurisé Aux 
under methods outside of transparent legal  Données (The Secure Data Access Centre) 
authority. Otherwise, a personal A/IS could  is equipment that allows users, researchers, 
feed information to a government authority  data scientists, and consultants to access 
without proper privacy protection. and work with individual and highly detailed 
microdata, which are therefore subject  
•  Nuanced technical and legal techniques 
to confidentiality measures, in the most 
to extract warranted information while 
secure conditions.
segregating and avoiding other information 
will be crucial to prevent overreach.  •  Initiatives such as OPAL (for Open 
  Algorithms), a collaborative project being 
developed by a group of partners committed 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 100The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
to leveraging the power of platforms, big  •  Polonetsky, J., and O. Tene. “Shades of  
data, and advanced analytics for the public  Gray: Seeing the Full Spectrum of Practical 
good in a privacy-preserving, commercially  De-Identification.” Santa Clara Law Review 
sensible, stable, scalable, and sustainable  56, no. 3 (2016): 593–629.
manner. 
•  Narayanan, A., and V. Shmatikov, “Robust  
•  Ohm, P. “Sensitive Information.” Southern  De-anonymization of Large Datasets  
California Law Review 88 (2015):   (How to Break Anonymity of the Netflix  
1125–1196. Prize Dataset).” February 5, 2008.
•  Y.-A. de Montjoye, L. Radaelli, V. K. Singh,  •  de Montjoye, Y.-A., C. A. Hidalgo, M. 
A. S. Pentland. “Unique in the Shopping  Verleysen, and V. D. Blondel. “Unique in 
Mall: On the Reidentifiability of Credit Card  the Crowd: The Privacy Bounds of Human 
Metadata.” Science 347 (2015): 536–539.  Mobility.” Scientific Reports 3, no. 1376 
(2013). doi: 10.1038/srep01376
•  Sanchez, D., S. Martinez., and J. Domingo-
Ferrer. “Comment on ‘Unique in the  •  Coyne, A. “Government Pulls Dataset That 
Shopping Mall: On the Reidentifiability   Jeopardised 96,000 Employees.” iTnews, 
of Credit Card Metadata’.” Science 351,   October 6, 2016.
no. 6279 (2016): 1274–1274. 
•  Cowan, P. “Health Pulls Medicare Dataset 
 
After Breach of Doctor Details.” iTnews, 
September 29, 2016.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 101The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Section 5 — Symmetry and Consent
Widespread data collection followed by the 
emergence of A/IS and other automated/
Issue: 
autonomous data processing has placed 
tremendous strain on existing conceptions   Could a person have a 
of “informed consent.” This has created a vast  personalized privacy AI or 
asymmetry between the volume of organizations 
algorithmic agent or guardian? 
tracking individuals versus the tools allowing 
those individuals to fully understand and  
respond to all these tracking signals. 
Background
Legal frameworks such as the GDPR rely on the 
For individuals to achieve and retain parity 
notion that data subjects must provide “freely 
regarding their personal information in the 
given, specific, informed, and unambiguous” 
algorithmic age, it will be necessary to include  
consent to certain data processing. Heavy 
a proactive algorithmic tool that acts as their 
reliance on a system of “notice and choice”  
agent or guardian in the digital, and “real” world. 
has shifted the burden of data protection away 
(“Real” meaning a physical or public space where 
from data processors and onto individual data 
the user is not aware of being under surveillance 
subjects. A/IS can exacerbate this trend by 
by facial recognition, biometric, or other tools 
complicating risk assessments of data sharing. 
that could track, store, and utilize their data 
When A/IS data transfer is done incorrectly  
without pre-established consent or permission). 
it may alter or eliminate user interfaces, limiting 
The creation of personalized privacy A/IS would 
choice and consent.
provide a massive opportunity for innovation  
in A/IS and corporate communities. There is 
A/IS presents a new opportunity to offer 
natural concern that the rights of the individual 
individuals/end users a “real choice” with respect 
are protected in the face of such opportunities.
to how information concerning them is collected, 
used, and shared. Researchers are working  
The sophistication of data-sharing methodologies 
to solve this issue in some contexts, but design 
has evolved so these scenarios could evolve  
standards and business incentives have yet  
from an “either/or” relationship: “We get all of 
to emerge.
your data for this project, or you provide nothing 
and hinder this work”) to a “Yes and” relationship 
— by allowing individuals to set their preferences 
for sharing and storing their data. An additional 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 102The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
benefit of finer-grained control of consent   set contains elements the personal agent will  
is that individuals are more likely to trust the  not provide, the service may be unavailable.  
organizations conducting research and provide  If the recommended data set will not be 
more access to their data.  provided, the service may be degraded. A user 
should be able to override his/her personal 
The guardian could serve as an educator and 
agents should he/she decide that the service 
negotiator on behalf of its user by suggesting 
offered is worth the conditions imposed.
how requested data could be combined with 
other data that has already been provided, inform  Vulnerable parts of the population will need 
the user if data is being used in a way that was  protection in the process of granting access, 
not authorized, or make recommendations to the  especially given the asymmetry of power 
user based on a personal profile. As a negotiator,  between an individual and entities. 
the guardian could negotiate conditions for 
sharing data and could include payment to the  Candidate Recommendations
user as a term, or even retract consent for the 
Algorithmic guardian platforms should be 
use of data previously authorized, for instance  
developed for individuals to curate and share 
if a breach of conditions was detected. 
their personal data. Specifically: 
Nonetheless, the dominant paradigm for personal 
1.  Such guardians could provide personal 
data models needs to shift away from system 
information control to users by helping 
and service-based models not under the control 
them track what they have agreed to share 
of the individual/human, and toward a model 
and what that means to them, while also 
focused on the individual. Personal data cannot 
scanning each user’s environment to set 
be controlled or understood when fragmented 
personal privacy settings accordingly. 
and controlled by a myriad of entities in legal 
jurisdictions across the world. The object model 
2.  For purposes of privacy, a person must  
for personal data should be associated with that 
be able to set up complex permissions that 
person, and under the control of that person 
reflect a variety of wishes. 
utilizing a personalized privacy A/IS or algorithmic 
guardian.  3.  Default profiles, to protect naive or 
uninformed users, should provide little  
During the handshake/negotiation between the 
or no personal information without explicit 
personal agent and the system or service, the 
action by the personal agent’s owner.
personal agent would decide what data to make 
available and under what terms, and the system  4.  The agent should help a person foresee  
would decide whether to make the service  and mitigate potential ethical implications  
available, and at what level. If the required data  of specific machine learning data exchanges. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 103The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
5.  Control of the data from the agent should  •  Companies are already providing solutions 
vest with the user, as otherwise users could  for early or partial versions of algorithmic 
lose access to his/her own ethical choices,  guardians. Anonyome Labs recently 
and see those shared with third parties  announced their SudoApp that leverages 
without permission.  strong anonymity and avatar identities  
to allow users to call, message, email, shop, 
6.  A guardian should enable machine-to-
and pay — safely, securely, and privately.
machine processing of information to 
compare, recommend, and assess offers   •  Tools allowing an individual to create  
and services. a form of an algorithmic guardian are often 
labeled as PIMS, or personal information 
7.  Institutional systems should ensure support 
management services. Nesta in the United 
and respect the ability for individuals to  
Kingdom was one of the funders of early 
bring their own guardian to the relationship 
research about PIMS conducted by CtrlShift. 
without any constraints that would make 
some guardians inherently incompatible   •  Privacy Assistant from MIT.
or subject to censorship.
Further Resources
•  The IEEE Global Initiative on Ethics of  Issue: 
Autonomous and Intelligent Systems. 
Consent is vital to information 
Personal Data and Individual Access Control 
exchange and innovation in 
Section, in Ethically Aligned Design: A 
Vision for Prioritizing Human Well-being  the algorithmic age. How can 
with Artificial Intelligence and Autonomous  we redeﬁne consent regarding 
Systems, Version 1. IEEE, 2016.
personal data so it respects 
•  IEEE P7006™, Standard for Personal Data  individual autonomy and dignity?
Artificial Intelligence (AI) Agent was launched 
in the summer of 2017 and is currently in 
development. Readers of this section are 
Background
encouraged to join the Working Group if they 
Researchers have long identified some key 
are focused on these issues. 
problems with notice and consent in the digital 
•  We wish to acknowledge Jarno M. Koponen’s  world. First, individuals cannot and will not read  
articles on Algorithmic Angels that provided  all of the privacy policies and data use statements 
inspiration for portions of these ideas.  to which they are exposed, and even if they 
could, these policies are not easy to understand. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 104The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Individual consent is rarely exercised as a  where the primary reason for data collection may 
meaningful choice due to poorly provisioned  mask important secondary uses post-collection. 
user-appropriate design.  In time, however, new mechanisms for facilitating 
dynamic consent rules and core structure as use-
A/IS place further strain on the notice and 
cases change. As data moves from the original 
consent regime as further personalization of 
collection context to a change of context, agile 
services and products should not be used as an 
ethics rules should be deployed.
excuse to minimize organizational transparency 
and choice for individuals to meet ethical and 
Candidate Recommendations
regulatory demand. If individuals opt not to 
provide personal information, they may find  The asymmetric power of institutions (including 
themselves losing access to services or receiving  public interest) over individuals should not 
services based on stereotypes derived from   force use of personal data when alternatives 
the lower quality of data that they do provide. such as personal guardians, personal agents, 
law-enforcement-restricted registries, and other 
When consent is not feasible or appropriate, 
designs that are not dependent on loss of agency 
organizations should engage in a robust audit 
are available. When loss of agency is required  
process to account for processing of personal 
by technical expedience, transparency needs  
data against the interests of individuals. For 
to be stressed in order to mitigate these 
instance, the GDPR permits processing on the 
asymmetric power relationships.
grounds of an entity’s legitimate interests, so 
long as those interests do not outweigh the 
Further Resources
fundamental rights and interests of data subjects. 
Organizations must develop internal procedures  •  Office of the Privacy Commissioner of 
for conducting such an analysis, and external  Canada. “Consultation on Consent Under 
actors and regulators should provide further  the ‘Personal Information Protection and 
guidance and oversight where possible. Electronic Documents Act’.” September 
21, 2017. U.K. Information Commissioner’s 
The needs of local communities, greater society, 
Office. “Consultation: GDPR Consent 
and public good should factor into this process. 
Guidance.” March 2017.
For example, a doctor may need medical data to 
be identified in order to treat a patient. However,  •  United Nations. “United Nations Declaration 
a researcher may require it simply for statistical  on the Rights of Indigenous Peoples.”  
analysis, and therefore does not require the data  107th plenary meeting, September 13, 2007.
to be identifiable. This is particularly important 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 105The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
thought to be private or benign can be linked 
to individuals at a later time. Furthermore, this 
Issue: 
linked data may then be used to train algorithms, 
Data that is shared easily   without transparency or consent, setting in 
or haphazardly via A/IS can   motion unintended consequences. Auditing  
data use and collection for potential ethics risks 
be used to make inferences  
will become increasingly more complex with  
that an individual may not  
A/IS in relation to these issues in the future. 
wish to share. 
Candidate Recommendation
The same A/IS that parses and analyzes data 
Background
should also help individuals understand how 
It is common for a consumer to consent to the  personal information can be used. A/IS can 
sharing of discrete, apparently meaningless data  prove granular-level consent in real time. Specific 
points like credit card transaction data, answers  information must be provided at or near the 
to test questions, or how many steps they walk.  point (or time) of initial data collection to provide 
However, once aggregated these data and  individuals with the knowledge to gauge potential 
their associated insights may lead to complex  privacy risks in the long-term. Data controllers, 
and sensitive conclusions being drawn about  platform operators, and system designers must 
individuals that consumers would not have  monitor for consequences when the user has 
consented to sharing. As analysis becomes more  direct contact with an A/IS system. Positive, 
obfuscated via A/IS, not even data controllers   negative, and unpredictable impacts of accessing 
will necessarily know what or how conclusions  and collecting data should be made explicitly 
are being drawn through the processing of  known to an individual to provide meaningful 
personal data, or how those data are used in   consent ahead of collection. Specifically: 
the whole process. 
•  Terms should be presented in a way that 
Opting out has some consequences. Users   allows the user to easily read, interpret, 
need to understand alternatives to consent   understand, and choose to engage with 
to data collection before they give or withhold it,  the system. To guard against these types 
as meaningful consent. Without understanding  of complexities, consent should be both 
the choices, consent cannot be valid. This places  conditional and dynamic. The downstream 
further strain on existing notions of informed  consequences (positive and negative) 
consent. It raises the need for additional user  must be explicitly called out, such that the 
controls and information access requirements.   individual can make an informed choice, 
As computational power advances and algorithms  and/or assess the balance of value in context.
compound existing data, information that was 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 106The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
•  If a system impacts the ability of  Systems should be designed to enable 
consumers to manage their own data via  personalization and meta system learning 
A/IS, accountability program management  concurrently without the permanent 
(PM) could be deployed to share consent  collection and storage of personal data for 
solutions. A PM could span a diversity of  retargeting. This is a key architectural design 
tools and software applications to collect   challenge that A/IS designers must achieve  
and transfer personal data. A PM can be  if AI is going to be of service to society.
assigned to evaluate consent metrics by 
ethics leadership to provide accountability  Further Resources
reports. An actionable consent framework  
•  Duhigg, C. “How Companies Learn Your 
for personal data would not need to “reinvent 
Secrets.” The New York Times Magazine, 
the wheel.” Existing privacy and personal data 
February 19, 2012.
metrics and frameworks can be integrated 
into consent program management, as it 
•  Meyer, R. “When You Fall in Love, This Is 
becomes relevant. Likewise, resources, user 
What Facebook Sees.” The Atlantic, February 
controls, and policies should be put in place 
15, 2014.
to afford individuals the opportunity to retract 
or erase their data if they feel it is being used  •  Cormode, G. “The Confounding Problem 
in ways they do not understand or desire.  of Private Data Release.” 18th International 
Use limitations are also important and may  Conference on Database Theory (2015): 
be more feasible than collection limitations.  1–12. 
At a minimum, organizations should 
•  Felbo, B., P. Sundsøy, A. Pentland, S. 
commit to not use data to make sensitive 
Lehmann, and Y. de Montjoye. “Using Deep 
inferences or to make important eligibility 
Learning to Predict Demographics from 
determinations absent consent. Because 
Mobile Phone Metadata.” Cornell University 
consent is so challenging in A/IS, it is vital 
Library, arXiv: 1511.06660, February 13, 2016.
that user participation, including data access, 
erasure, and portability, are also incorporated  •  OECD Standard of Data Minimization — 
into ethical designs. Minimum data required for maximum 
service.
•  Moving all computational values to the 
periphery (on the person) seems to be the 
only way to combat all the risks articulated. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 107The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Candidate Recommendations
Issue:  Where the subject does not have a direct 
relationship with the system, consent should 
Many A/IS will collect data  
be dynamic and must not rely entirely on initial 
from individuals they do not  
terms of service or other instruction provided 
have a direct relationship with,   by the data collector to someone other than the 
or the systems are not interacting  subject. A/IS should be designed to interpret 
the data preferences, verbal or otherwise, of all 
directly with the individuals.  
users signaling limitations on collection and use, 
How can meaningful consent  
discussed further below. 
be provided in these situations? 
Further Resources
•  Kaminski, M. “Robots in the Home: What  
Background
Will We Have Agreed To?” Idaho Law Review 
Individuals can be better informed of uses,  51, no. 661 (2015): 551–677.
processing, and risks of data collection when 
•  Jones, M. L. “Privacy Without Screens and  
they interact with a system. IoT presents evolving 
the Internet of Other People’s Things,” Idaho 
challenges to notice and consent. Data subjects 
Law Review 51, no. 639 (2015): 639–660.
may not have an appropriate interface to 
investigate data controller uses and processes. 
•  Cranor, L. F. “Personal Privacy Assistants in 
They may not be able to object to collection  
the Age of the Internet of Things,” presented 
of identifiable information, known or unknown  
at the World Economic Forum Annual 
to them by wireless devices, driven by A/IS.
Meeting, 2016.
When individuals do not have a relationship 
with the data collecting system, they will have 
no way of participating in their data under the   
notice and consent regime. This challenge is   
frequently referenced as the “Internet of Other   
People’s Things.” A/IS embodied in IoT devices   
and value-chains will need better interfaces and   
functionality to help subjects understand and 
participate in the collection and use of their data.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 108The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
•  Design the terms of service (ToS) as 
negotiable to consumers — Combine 
Issue: 
user interface design to control the rate 
How do we make better  and method of data exchange, and provide 
user experience and consent  a corporate terms ombudsman staffed as 
human agency to consumers facing a terms 
education available to  
of service contract. Software developers 
consumers as standard to 
would produce contract management 
express meaningful consent?
platforms appropriate for consumer 
negotiation. This would support features to 
negotiate terms of consent contracts fairly for 
Background meaningful consumer consent. An example 
metric would be a consumer agreement  
Individuals are often not given agency or  
held to 85% of a terms of service agreement 
personal tools to express, invoke, or revoke 
content, as grounds to move forward with 
consent to the terms of service or privacy and/
the contract. Companies conclude what the 
or data use policies in their contracts. In many 
“deal breakers” or non-negotiables are ahead 
cases, individual data subjects were not notified 
of time. 
at all of the transfer of their data in the course  
of business or government exchanges.  •  Provide “privacy offsets” as a business 
alternative to the personal data 
Industry data uses have led to individual  
exchange — Provide a pay alternative to the 
exposure to intangible and tangible privacy 
freemium data exchange model, to limit  
harms, for example, mistaken identity. Inability  
or cap third party vendor access to personal 
to manage or control information has also  
data or limit transactional data to internal 
led to barriers to employment, healthcare, and 
business use only. Business developers 
housing. This dynamic has resulted in some 
would have to cost count individual data 
consumer resignation over the loss of control 
based on a general market profile, or offer 
over personal information, despite a stated  
a flat rate for advertising-free service. If they 
desire for additional control.
know immediately how much money they 
will lose if a new user would not consent to 
Candidate Recommendations
an external data exchange, they have grounds 
Tools, settings, or consumer education are  to pass the cost to new consumers as a 
increasingly available and should be utilized to  privacy offset product. 
develop, apply, and enforce consumer consent.    
Specifically: 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 109The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
•  Apply “consent” to further certify  •  Aggregate and provide visualization 
artificial intelligence legal and as  options for terms of service and privacy 
ethics doctrine — Legal consent principles  statements — One way to provide better 
could be applied to a larger self-regulatory  education and improved user experience, 
or co-regulatory artificial intelligence ethics  with respect to legal terms of use, is to offer 
certification framework for businesses  visual analytics tools as a consumer control 
and governments. This would be similar  point of reference. Potential examples  
to medical certifications in ethics as a  of this sort of effort include the Terms of 
professional requirement, supportive of   Service Didn’t Read Project and the Clarip. 
the Hippocratic Oath. Artificial intelligence  Both tools simplify the content of these 
ethics certification for responsible   policies and may provide users with clarity 
institutions (medical, government, education,  into how services are collecting, making  
corporations) should include education in  use of, and potentially sharing personal and 
applied legal consent principles, situation  other information. 
training regarding forms of consent, ethics 
certification testing, and perhaps a notarized  Further Resources
public declaration to uphold ethical principles 
•  Cavoukian, A. “Privacy by Design: The 7 
of consent. As an ethics board is formed it 
Foundational Principles. Implementation 
might: evaluate complaints, resolve ethical 
and Mapping of Fair Information Practices.” 
conflicts related to artificial intelligence and 
Internet Architecture Board, 2010.
consent issues, improve upon current ethics 
procedures for consent, request independent 
•  “From Consent to Data Control by Design.” 
investigations, review licensure or certification 
Data Ethics, March 20, 2017.
determinations, recommend professional 
penalties or discipline to organizations,   •  Hintze, M. Privacy Statements: Purposes, 
and/or file legal claims based on findings.  Requirements, and Best Practices. 
  Cambridge, U.K.: Cambridge University  
Press, 2017.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 110The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
specific nuances of corporate specific situations.  
It should be clear that no data is collected 
Issue: 
without the consent of the employee. 
In most corporate settings, 
Furthermore, it is critical that the data:
employees do not have clear 
•  Is gathered only for specific, explicitly  
consent on how their personal 
stated, and legitimate purposes
information (including health 
and other data) is used by  •  Is correct and up to date
employers. Given the power 
•  Is only processed if it is lawful
differential between employees 
•  Is processed in a proper manner,  
and employers, this is an area in 
and in accordance with good practice
need of clear best practices.
•  Is not processed for any purpose that  
is incompatible with that for which the data 
was gathered
Background
In the beginning stages of onboarding, many  •  Is rectified, blocked, or erased if it is  
employees sign hiring agreements that license   incorrect or incomplete having regard  
or assign the usage of their data in very non- for the purpose of the processing
specific ways. This practice needs to be updated, 
•  Is not kept for a longer period than  
so that it is clear to the employee what data is 
is necessary
collected, and for what purpose. The employee 
must also have the ability/possibility to request 
Further Resources
privacy for certain data as well as have the 
right to remove the data if/when leaving the  •  The Swedish Personal Data Protection Act  
employment. is taking a generic approach to data protection  
and data privacy, but it is well applicable  
Candidate Recommendation  for the specific case of employee data.
In the same way that companies are doing 
•  IEEE P7005™, Standard for Transparent 
privacy impact assessments for how individual 
Employer Data Governance. This Working 
data is used, companies need to create employee 
Group is open and free for anyone to join. 
data impact assessments to deal with the  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 111The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Personal Data and Individual Access Control 
Candidate Recommendations
Issue:  •  Researchers or developers of A/IS have  
to take into account the issue of vulnerable 
People may be losing their 
people, and try to work out an A/IS that 
ability to understand what kinds 
alleviates their helpless situation to prevent 
of processing is done by A/IS  possible damage caused by misuse of their 
on their private data, and thus  personal data.
may be becoming unable to 
•  Build an AI advisory commission, composed 
meaningfully consent to online  of elder advocacy and mental health self-
terms. The elderly and mentally  advocacy groups, to help developers produce 
a level of tools and comprehension metrics 
impaired adults are vulnerable 
to manifest meaningful and pragmatic 
in terms of consent, presenting 
consent applications. 
consequence to data privacy.
Background
The poor computer literacy of the elderly has 
been well known from the beginning of the 
information and Internet age. Among various 
problems related to this situation, is the financial 
damage caused by the misuse of their private 
information, possibly by malicious third parties. 
This situation is extremely severe for elderly 
people suffering from dementia.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 112The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
Autonomous systems designed to cause physical harm have additional ethical dimensions 
as compared to both traditional weapons and autonomous systems not designed to cause 
harm. Multi-year discussions on international legal agreements around autonomous systems 
in the context of armed conflict are occurring at the United Nations (UN), but professional 
ethics about such systems can and should have ethical standards covering a broad array  
of issues arising from the automated targeting and firing of weapons.
Broadly, we recommend that technical organizations promote a number of measures  
to help ensure that there is meaningful human control of weapons systems: 
•  That automated weapons have audit trails to help guarantee accountability  
and control.
•  That adaptive and learning systems can explain their reasoning and decisions  
to human operators in transparent and understandable ways. 
•  That there be responsible human operators of autonomous systems who are  
clearly identifiable.
•  That the behavior of autonomous functions should be predictable to their operators. 
•  That those creating these technologies understand the implications of their work. 
•  That professional ethical codes are developed to appropriately address the 
development of autonomous systems and autonomous systems intended  
to cause harm.
Specifically, we would like to ensure that stakeholders are working with sensible and 
comprehensive shared definitions, particularly for key concepts relevant to autonomous 
weapons systems (AWS). Designers should always ensure their designs meet the standards 
of international humanitarian law, international human rights law, and any treaties or 
domestic law of their particular countries, as well as any applicable engineering standards, 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 113The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
military requirements, and governmental regulations. We recommend designers not only 
take stands to ensure meaningful human control, but be proactive about providing quality 
situational awareness to operators and commanders using those systems. Professional 
ethical codes should be informed by not only the law, but an understanding of both local- 
and global-level ramifications of the products and solutions developed. This should include 
thinking through the intended use or likely abuse that can be expected by users of AWS.
While the primary focus of this document is with kinetic AWS that cause physical harm, it  
is recognized that many of these concerns and principles may also apply to cyber-weapons. 
This is, of course, also pertinent to cyber-weapons that have kinetic effects, such as those 
that destroy civilian infrastructures or turn civilian objects, vehicles, or infrastructure into 
kinetic weapons. 
Additionally, society must be aware of the variety of political and security threats posed 
by AWS. Miniaturized AWS will pose additional threats because they are small, insidious, 
or obfuscated, and may therefore be non-attributable to the deploying entity. Depending 
upon payload or weapons (such as chemical, biological, or nuclear weapons), these may 
autonomously deploy weapons of mass destruction (WMD), or themselves constitute 
a new form of WMD. Additional ethical recommendations are needed to prevent the 
development of systems having these dangerous properties.
•  Issues 1–3 raise general high-level questions regarding the definition of AWS  
and their relation to existing law and ethics.
•  Issues 4–10 raise socio-political concerns over the likely uses and effects  
of AWS development and use.
•  Issue 11 raises engineering concerns over the specific challenges posed  
by autonomous systems capable of targeting and deploying weapons.
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 114The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
Moreover, the phrases “human in the loop” and 
“human on the loop” also lack clarity and only 
Issue 1: 
contribute further confusion. Depending upon 
Confusions about definitions  what one means, “in the loop” or “on the loop” 
regarding important concepts  means different things to different people. It 
could be used to describe the command chain 
in artificial intelligence (AI), 
that authorizes weapon release, where the 
autonomous systems (AS), and 
commands flow down to a human and a weapon 
autonomous weapons systems 
system to take specific actions. Yet, there are 
(AWS) stymie more substantive  micro-level decisions where a human operator 
discussions about crucial issues. may have an opportunity to question the 
command. What often matters is the time delay 
between the fielding of an autonomous system, 
the decision to engage a weapon against a target, 
Background
and the impact time. 
The potential for confusion about AWS definitions 
Contrarily, “in the loop” obscures another 
is not just an academic concern. The lack of clear 
temporal question: that whether in these 
definitions regarding what constitutes AWS is often 
scenarios clearance to fire at a target entails an 
cited as a reason for not proceeding toward any 
authorization to prosecute that target indefinitely, 
kind of international governance over autonomous 
or whether there are necessarily predetermined 
weapons. As this is both a humanitarian issue 
limits on the amount of time or ordinance 
and an issue of geopolitical stability, the focus 
each clearance provides. Central to this issue 
in this area needs to be on how the weapons 
is how long a target that has been designated 
are controlled by humans rather than about the 
and verified by an authorized human in a given 
weapons’ technology per se.
situational context remains a legitimate target.
The term autonomy is important for 
This notion of autonomy can be applied 
understanding debates about AWS; yet there 
separately to each of the many functions of a 
may be disputes — about what the term means 
weapons system; thus, an automatic weapons 
and whether what the definition identifies is 
system could be autonomous in searching 
technically possible today. This prevents progress 
for targets, but not in choosing which ones 
in developing appropriate policies to regulate 
to attack, or vice versa. It may or may not be 
AWS design, manufacture, and deployment. 
given autonomy to fire in self-defense when 
Consistent and standardized definitions are 
the program determines that the platform is 
needed to enable effective discussions of AWS, 
under attack, and so on. Within each of these 
but they should be general enough to enable 
categories, there are also many intermediate 
flexibility to ensure that those definitions do not 
gradations in the way that human and machine 
become quickly technologically outdated. 
decision-making may be coupled.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 115The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
Candidate Recommendations •  DoD Defense Science Board, Summer Study 
on Autonomy. June 2016.
The term autonomy in the context of AWS should 
•  Young, R. Autonomy: Beyond Negative  
be understood and used in the restricted sense 
and Positive Liberty. New York: St. Martin’s 
of the delegation of decision-making capabilities 
Press, 1986.
to a machine. Since different functions within 
AWS may be delegated to varying extents, and  •  Society of Automotive Engineers. J3016, 
the consequences of such delegation depend  Taxonomy and Definitions for Terms Related 
on the ability of human operators to forestall  to On-Road Motor Vehicle Automated Driving 
negative consequences via the decisions over  Systems. SAE International, 2014.
which they retain effective control, it is important  •  Roff, H. M. “An Ontology of Autonomy: 
to be precise about the control of specific  Autonomy in Weapons Systems,” in The 
functions delegated to a given system, as well as  Ethics of Autonomous Weapons, edited  
the ways in which control over those functions  by C. Finkelstein, D. MacIntosh, and J. D. 
are shared between human operators and AWS. Ohlin. Cambridge, U.K.: Oxford University 
Press, forthcoming.
We support the working definition of AWS 
offered by the International Committee of the  •  Sharkey, N. “Towards a Principle for the 
Red Cross (ICRC) and propose that it be adopted  Human Supervisory Control of Robot 
as the working definition of AWS for the further  Weapons.” Politica and Società 2 (2014): 
development and discussion of ethical standards  305–324.
and guidelines for engineers. The ICRC defines  •  U.K. Ministry of Defence. UK Joint Doctrine 
an AWS as: “any weapon system with autonomy  Note (JDN) 3/10, “Unmanned Aircraft 
in its critical functions. That is, a weapon system  Systems: Terminology, Definitions and 
that can select (i.e. search for or detect, identify,  Classification.” May 2010.
track, select) and attack (i.e. use force against, 
•  U.K. Ministry of Defence. UK Joint Doctrine 
neutralize, damage or destroy) targets without 
Note (JDN) 2/11, “The UK Approach to 
human intervention.”
Unmanned Aircraft Systems.” March 2011.
Further Resources •  United Nations Institute for Disarmament 
Research (UNIDIR). “Framing Discussions 
•  Dworkin, G. The Theory and Practice of 
on the Weaponization of Increasingly 
Autonomy. Cambridge, U.K.: Cambridge 
Autonomous Technologies.” 2014 
University Press, 1988.
•  Frankfurt, H. G. “Freedom of the Will and the  •  International Committee of the Red Cross 
Concept of a Person,” in The Importance  (ICRC). “Autonomous Weapon Systems: 
of What We Care About, Cambridge, U.K.:  Implications of Increasing Autonomy in  
Cambridge University Press, 1987. the Critical Functions of Weapons.” 
September 1, 2016. 
•  DoD Defense Science Board, The Role 
of Autonomy in DoD Systems, Task Force 
Report. July 2012, 48.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 116The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
in which these rights may be threatened by the 
deployment and/or use of AWS, during armed 
Issue 2: 
conflict, policing, or other security operations.
The addition of automated 
There are situational and operational limitations 
targeting and firing functions to 
of all engineered systems, and complete 
an existing weapon system, or 
knowledge is not something that can be expected 
the integration of components  or required. However, there must be a multi-level 
with such functionality, or system  effort to: 
upgrades that impact targeting 
•  Evaluate the conformity of a system to the law
and automated weapon release 
•  Evaluate its reliability and applicability for  
should be considered for review 
a given mission
under Article 36 of Additional 
•  Evaluate its ability to conform to rules  
Protocol I of the Geneva 
of engagement
Conventions.
Further, key decision makers need to  
understand the engineering constraints and 
Background limitations of weapons systems with high  
degrees of autonomy.
According to Article 36 of Additional Protocol 
I to the Geneva Conventions (1977), “In the 
Candidate Recommendations
study, development, acquisition or adoption of 
a new weapon, means or methods of warfare,”  •  All engineering work should conform to the 
weapon systems must be internally reviewed  requirements of international law, including 
for compliance with international humanitarian  both IHL and IHRL, as well as national and 
law (IHL). Alterations to the critical functions or  local laws. While this is not the primary 
targeting and weapons release of an already- responsibility of an individual engineer,  
reviewed weapons systems should be considered  there ought to be opportunities for engineers 
for review, and any system automating those  to learn about their obligations, their 
functions should be reviewed to ensure  responsibilities with respect to AWS,  
meaningful human control. as well as keeping their employing  
agencies accountable.
International human rights law (IHRL) also 
guarantees, by way of international and bilateral  •  Meaningful human control over the critical 
treaties, rights to life, human dignity, fair trial,  functions in weapons systems can help 
and further positive and negative human rights.  ensure that weapons can be used in 
Society and engineers must consider the ways  conformity with the law in each instance. It is 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 117The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
also necessary for all stakeholders to consider 
design and implement accountability 
Issue 3: 
measures to help ensure all weapons are 
used in conformity with the law.  Engineering work should conform 
to individual and professional 
•  Engineering constraints should be clearly 
organization codes of ethics and 
identified, defined, and communicated to 
Article 36 weapons reviewers, to operators  conduct. However, existing codes 
in their training for a system, and to military  of ethics may fail to properly 
commanders and their legal counsel charged 
address ethical responsibility for 
with specifying the rules of engagement. 
autonomous systems, or clarify 
•  All those with responsibilities for weapon  ethical obligations of engineers 
systems should ensure that Article 36 
with respect to AWS. Professional 
reviews will be held and provide all evidence 
organizations should undertake 
needed at them. This should include any 
reviews and possible revisions 
data which will lead to restrictions on their 
use, which will also be needed for Article 36  or extensions of their codes of 
reviews and for military staff to set rules of  ethics with respect to AWS.
engagement for the weapon system’s use.
•  There should be greater engineering input 
into the weapons reviews, and greater  Background
communication between engineers and 
•  The ethical requirements for engineering 
lawyers in the weapons review process  
have an independent basis from the 
to ensure meaningful human control  
law, although they are hopefully aligned 
over weapons.
with written laws and written codes of 
professional ethics. Where agreed upon, 
Further Resources ethical principles are not reflected in  
written laws and ethical codes, individuals 
•  International Committee of the Red Cross 
and organizations should strive to correct 
(ICRC). “Autonomous Weapon Systems: 
those gaps.
Implications of Increasing Autonomy  
in the Critical Functions of Weapons.” 
•  Ethical requirements upon engineers 
September 1, 2016.
designing autonomous weapon systems 
may go beyond the requirements of meeting 
local, national, and international laws.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 118The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
Many professional organizations have codes of  Candidate Recommendations
conduct intended to align individuals’ behaviors 
Codes of conduct should be extended to govern 
toward particular values. However, they seldom 
a member’s choice to create or contribute to 
sufficiently address members’ behaviors in 
the creation of technological innovations that 
contributing toward particular artifacts, such 
are deemed threatening to humanity. Such 
as creating technological innovations deemed 
technologies carry with them a significant 
threatening to humanity, especially when those 
probability of costly outcomes to people and 
innovations have significant probabilities of costly 
society. When codes of conduct are directed 
outcomes to people and society. Foremost 
toward ensuring positive benefits or outcomes 
among these in our view are technologies related 
for humanity, organizations should ensure 
to the design, development, and engineering  
that members do not create technologies that 
of AWS.
undermine or negate such benefits. In cases 
Organizations such as the IEEE, the Association  where created technologies or artifacts fail to 
for Computing Machinery (ACM), the Association  embody or conflict with the values espoused in a 
for the Advancement of Artificial Intelligence  code of conduct, it is imperative that professional 
(AAAI), the UK Royal Academy of Engineering,  organizations extend their codes of conduct 
the Engineering Council, Engineers Canada, and  to govern these instances so members have 
the Japanese Society for Artificial Intelligence  established recourse to address their individual 
(JSAI) have developed codes of ethics. Some of  concerns. Codes of conduct should also more 
these groups are currently reviewing those codes  broadly ensure that the artifacts and agents 
in light of current and future developments   offered into the world by members actively 
in autonomous systems and AI. reflect the professional organization’s standards  
of professional ethics.
While national laws may differ on what 
constitutes responsibility or liability for the design  Professional organizations need to have resources 
of a weapon system, given the level of complicity  for their members to make inquiries concerning 
or the causal contribution to the development  whether a member’s work may contravene (IHL) 
of a technology, ethics looks for lines of moral  or (IHRL).
responsibility. Determining whether an individual 
How one determines the line between ethical 
is morally responsible requires understanding the 
and unethical work on AWS requires that one 
organizations in which they work and to establish 
address whether the development, design, 
relevant facts in relation to the individual’s acts 
production, and use of the system under 
and intentions.
consideration is itself ethical. It is incumbent 
upon a member to engage in reflective 
judgment to consider whether or not his or 
her contribution will enable or give rise to AWS 
and their use cases. Members must be aware 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 119The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
of the rapid, dynamic, and often escalatory  •  The Japanese Society for Artificial Intelligence 
natures of interactions between near-peer  Ethical Guidelines, 2017 
geopolitical adversaries or rivals. It is also 
•  Engineering Council and Royal Academy of 
incumbent upon members of a relevant technical 
Engineering, Statement of Ethical Principles 
organization to take all reasonable measures 
for the Engineering Profession. 
to inform themselves of the funding streams, 
the intended use or purpose of a technology, 
and the foreseeable misuse of their technology 
when their contribution is toward AWS in whole 
Issue 4: 
or in part. If their contribution to a system is 
foreseeably and knowingly to aid in human-aided  The development of AWS 
decisions — that is, as part of a weapon system 
by states is likely to cause 
that is under meaningful human control — this 
geopolitical instability and could 
may act as a justification for their research.
lead to arms races.
Further Resources
•  Kvalnes, Ø. “Loophole Ethics,” in Moral 
Background
Reasoning at Work: Rethinking Ethics in 
Organizations, 55–61. Palgrave Macmillan  The widespread adoption of AWS by nation states 
U.K., 2015. could present a unique risk to the stability of 
international security. Because of the advantages 
•  Noorman, M. “Computing and Moral 
of either countering an adversary through 
Responsibility,” The Stanford Encyclopedia 
concomitant adoption of arms or being the 
of Philosophy, edited by Edward N. Zalta , 
first or prime mover is an offset advantage, the 
Summer 2014 Edition.
pursuit of AWS is likely to spur an international 
arms race. Evidence of states seeking greater 
•  Hennessey, M. “Clearpath Robotics Takes 
adoption of artificial intelligence and quantum 
Stance Against ‘Killer Robots’.” Clearpath 
computing for security purposes already 
Robotics, 2014.
exists. The deployment of machine learning 
•  “Autonomous Weapons: An Open Letter from  and other artificial intelligence applications on 
AI & Robotics Researchers.” Future of Life  weapons systems is not only occurring, but 
Institute, 2015. will continue to advance. Thus it is important 
to look to previous scholarship on arms race 
•  Noorman, M. “Computing and Moral 
dynamics to be informed about the first- and 
Responsibility,” in The Stanford Encyclopedia 
second-order effects of these races, such as the 
of Philosophy (Summer 2014 Edition), edited 
escalatory effects, arms development, decreasing 
by Edward N. Zalta. 
international stability, and arms proliferation. 
•  “Engineers Canada Code of Ethics,” 2017.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 120The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
Candidate Recommendations Autonomous Weapons.” Briefing paper 
prepared for the Informal Meeting of Experts 
Autonomous weapons designers should support 
on Lethal Autonomous Weapons Systems, 
the considerations of the United Nations to 
UN Convention on Certain Conventional 
adopt a protocol to ensure meaningful human 
Weapons, April 2016.  
control over AWS under the Convention on 
Certain Conventional Weapons (CCW) treaty, or  •  United Nations Institute for Disarmament 
other similar effort by other international bodies  Research (UNIDIR). “The Weaponization 
seeking a binding international treaty. of Increasingly Autonomous Technologies: 
Considering How Meaningful Human Control 
It is unethical to design, develop, or engineer 
Might Move the Discussion Forward.” 2014. 
AWS without ensuring that they remain reliably 
subject to meaningful human control. Systems 
created to act outside of the boundaries of 
“appropriate human judgment,” “effective human 
control,” or “meaningful human control,” violate  Issue 5: 
fundamental human rights and undermine legal 
The automated reactions of an 
accountability for weapons use. Various scenarios 
for maintaining meaningful human control over  AWS could result in the initiation 
weapons with autonomous functions should  or escalation of conflicts outside 
be further investigated for best practices by a 
of decisions by political and 
joint workshop of stakeholders and concerned 
military leadership. AWS that 
parties (including, but not limited to, engineers, 
engage with other AWS could 
international humanitarian organizations, and 
militaries), and that those best practices be  escalate a conflict rapidly, before 
promoted by professional organizations as   humans are able to intervene.
well as by international law.
Further Resources
Background
•  Scharre, P., and K. Sayler. “Autonomous 
One of the main advantages cited regarding 
Weapons and Human Control” (poster). 
autonomous weapons is that they can make 
Center for a New American Security,  
decisions faster than humans, enabling rapid 
April 2016.
defensive and offensive actions. When opposing 
autonomous weapons interact with each other, 
•  International Committee for Robot Arms 
conflict might escalate without explicit human 
Control. “LAWS: Ten Problems for Global 
military or political decisions, and escalate more 
Security” (leaflet). April 10, 2015.
quickly than humans on either side will be able to 
•  Roff, H. M., and R. Moyes. “Meaningful  understand or act.
Human Control, Artifical Intelligence and 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 121The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
Candidate Recommendations Background
•  Consider ways of limiting potential harm from  Weapons may not have transparency, auditability, 
automated weapons. For example: limited  verification, or validation in their design or use. 
magazines, munitions, or maximum numbers  Various loci of accountability include those for 
of platforms in collaborative teams. commanders (e.g., what are the reasonable 
standards for commanders to maintain 
•  Explore other technological means for limiting 
meaningful human control?), and operators (e.g., 
escalation, for example, “circuit breakers,” as 
what are the levels of understanding required by 
well as features that can support confidence-
operators to have knowledge of the system state, 
building measures between adversaries. 
operational context, and situational awareness?).
All such solution options ought to precede 
the design, development, deployment, and  Ideally all procurers, suppliers, and users 
use of weapons systems with automated  of weapons systems components have 
targeting and firing functions. accountability for their part of every weapons 
system, potential incorporation in future systems, 
•  Perform further research on how to temper 
and expected and potential users. 
such dynamics when designing these 
systems.
Candidate Recommendations
•  Designers should follow best practices in 
Further Resources
terms of design process, which entails clearly 
•  Scharre, P.  “Autonomous Weapons and 
defined responsibilities for organizations, 
Operational Risk.” Washington, DC: Center 
companies, and individuals within the 
for New American Security, February, 
process.
2016. 
•  Systems and components should be 
designed to deter the easy modification of 
the overall weapon after the fact to operate 
in fully autonomous mode. 
Issue 6: 
There are multiple ways in which  •  Further exploration of black box recording 
of data logs, as well as cryptographic, block-
accountability for the actions of 
chain, and other technical methods for 
AWS can be compromised.
tracing access and authorization of weapons 
targeting and release is needed. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 122The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
•  System engineers must work to the same  •  Weapons systems must have default modes 
high standards and regulations of security for  of operation agreed with campaign planners 
AWS design from a cybersecurity perspective  before operation commences.
than they would for any other work. 
•  Ensure as many aspects of weapons systems 
Weapons systems ought to be designed with 
as possible are designed with fail-safe 
cybersecurity in mind such that preventing 
behaviors.
tampering, or at least undetected tampering, 
is a highly weighted design constraint.
•  Ensure clear embedded lines of 
accountability in the design, deployment, and 
•  Procurement authority: only contract with 
operation of weapons.
contractors who have proper legal and 
security processes; carry out Article 36 
•  Trusted user authentication logs and audit 
reviews at all major steps in the procurement 
trail logs are necessary, in conjunction 
process; maintain database of design, tests, 
with meaningful human control. Thorough 
and review evidence.
human-factors-driven design of user 
interface and human–computer/robot 
•  Contractors: ensure design meets relevant 
interaction design is necessary for situational 
engineering and defense standards for 
awareness, knowability, understandability, 
military products; deliver evidence for Article 
and interrogation of system goals, reasons, 
36 reviews using, but not restricted to, design 
and constraints, such that the user could be 
reviews and simulation models; provide 
held culpable.
evidence requested by user for setting ROE; 
ensure design has clear criteria for decisions 
•  Tamper-proof the equipment used to store 
made by their product.
authorization signals and base this on open, 
auditable designs, as suggested by Gubrud 
•  Acceptance body: have validation and test 
and Altmann (2013). Further, the hardware 
plans for behavior of actual system produced; 
that implements the human-in-the-loop 
test weapons systems in a number of 
requirement should not be physically distinct 
representative scenarios; have plans to 
from operational hardware.
ensure upgrades are reviewed against IHL 
criteria such as Article 36.
There will need to be checks that all these 
bodies and organizations have discharged 
•  User/military commanders: only operate 
their responsibilities according to IHL and their 
weapons systems with meaningful human 
domestic laws. Even if this is the case, weapons 
control and in accordance with delegated 
system operations may be compromised by, 
authority.
for example, equipment failure, actions by 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 123The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
opponents such as cyber-attacks, or deception  •  Owens, D. “Figuring Forseeability.” Wake 
so that the automated functions act according to  Forest Law Review 44 (2009): 1277,  
design but against an incorrect target. 1281–1290.
There are currently weapons systems in use that,  •  Roff, H. M., and R. Moyes. “Meaningful 
once activated, automatically intercept high-speed  Human Control, Artificial Intelligence and 
inanimate objects such as incoming missiles,  Autonomous Weapons Systems.” Briefing 
artillery shells, and mortar grenades. Examples  Paper for the Delegates at the Convention 
include SEA-RAM, C-RAM, Phalanx, NBS Mantis,  on Certain Conventional Weapons Meeting 
and Iron Dome. These systems complete their  of Experts on Lethal Autonomous Weapons 
detection, evaluation, and response process  Systems, Geneva, April 2016. 
within a matter of seconds and thus render 
•  Roff, H. M. “Meaningful Human Control or 
it extremely difficult for human operators to 
Appropriate Human Judgment.” Briefing 
exercise meaningful supervisory control once 
Paper for the Delegates at the 5th Review 
they have been activated, other than deciding 
Conference at the Convention on Certain 
when to switch them off. This is called supervised 
Conventional Weapons, Geneva, December 
autonomy by the U.S. Department of Defense 
2016. 
(DoD) because the weapons require constant 
and vigilant human evaluation and monitoring 
•  Scherer, M. “Who’s to Blame (Part 4): Who’s 
for rapid shutdown in cases of targeting errors, 
to Blame if an Autonomous Weapon Breaks 
change of situation, or change in status of targets. 
the Law?” Law and AI, February 24, 2016.
However, most of these systems are only utilized 
in a defensive posture for close-in weapons  •  Rebecca C, “War Torts: Accountability 
systems support against incoming lethal threats. for Autonomous Weapons.” University of 
Pennsylvania Law Review 164, no. 6 (2016): 
1347–1402.
Further Resources
•  Gubrud, M., and J. Altmann. “Compliance  •  Gillespie, T., and R. West.  “Requirements for 
Measures for an Autonomous Weapons  Autonomous Unmanned Air Systems Set by 
Convention.” International Committee for  Legal Issues.” International C2 Journal 4, no. 
Robot Arms Control, 2013.  2 (2010): 1–32.
•  U.K. Ministry of Defence. “The UK Approach  •  Defense Science Board. “Summer Study on 
to Unmanned Aircraft Systems (UAS),” Joint  Autonomy.” Washington, DC: Office of the 
Doctrine Note 2/11, March 2011. Under Secretary of Defense for Acquisition, 
Technology and Logistics, June 2016. 
•  Sharkey, N. “Towards a Principle for the 
Human Supervisory Control of Robot  •  Rickli, J.-M. “Artificial Intelligence and the 
Weapons.” Politica and Società 2 (2014):  Future of Warfare” (Box 3.2.1). 2017 Global 
305–324. Risk Report, Geneva: World Economic  
Forum, 2017.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 124The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
designed to be semi-autonomous, where the 
control over the critical functions remains with a 
Issue 7: 
human operator, (such as through a human-in-
AWS offer the potential for severe  the-loop hardware interlock). Design for operator 
human rights abuses. Exclusion  intervention must be sensitive to human factors 
and intended to increase, rather than decrease, 
of human oversight from the 
situational awareness. 
battlespace can too easily lead  
to inadvertent violation of human  Under no circumstances is it morally permissible 
to use AWS without meaningful human control, 
rights. AWS could be used  
and this should be prohibited. Ultimately, 
for deliberate violations of 
weapons systems must be under meaningful 
human rights.
human control. As such, design decisions 
regarding human control must be made so 
that a commander has meaningful human 
Background control over direct attacks during the conduct of 
hostilities. In short, this requires that a human 
The ethical disintermediation afforded by AWS 
commander be present and situationally aware of 
encourages the bypassing of ethical constraints 
the circumstances on the ground as they unfold 
on people’s actions that should require the 
to deploy either semi-autonomous or defensive 
consent of multiple people, organizations, or 
anti-materiel AWS. Organizational members must 
chains of commands. This exclusion concentrates 
ensure that the technologies they create enhance 
ethical decision-making into fewer hands. 
meaningful human control over increasingly 
The potential lack of clear lines of accountability  sophisticated systems and do not undermine 
for the consequences of AWS might encourage  or eliminate the values of respect, humanity, 
malicious use of AWS by those seeking to avoid  fairness, and dignity.
responsibility for malicious or illegal acts.
Further Resources
Candidate Recommendations
•  Heller, K. J. “Why Preventive Self-Defense 
Acknowledge that the design, development, or  Violates the UN Charter.” Opinio Juris, March 
engineering of AWS for anti-personnel or anti- 7, 2012.
civilian purposes are unethical. An organization’s 
•  Scherer, M. “Who’s to Blame (Part 5): A 
values on respect and the avoidance of harm 
Deeper Look at Predicting the Actions of 
to persons precludes the creation of AWS that 
Autonomous Weapons.” Law and AI, February 
target human beings. If a system is designed 
29, 2016.
for use against humans, such systems must be 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 125The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
•  Roff, H. M. “Killer Robots on the Battlefield:  those aimed at preventing access to sensitive 
The Danger of Using a War of Attrition  technologies or data, should be designed to not 
Strategy with Autonomous Weapons.” Slate,  cause incidental or intentional harm.
2016.
There are significant concerns about the use of 
•  Roff, H. “Autonomous Weapons and  AWS by non-state actors, or individuals, and the 
Incentives for Oppression.” Duck of Minerva,  potential for use in terror attacks against civilians, 
March 13, 2016. and non-attributable attacks against states. 
Designers should be concerned about  
the potential of systems to be used by  
malicious actors.
Issue 8: 
Candidate Recommendation
AWS could be used for  
Because AWS are delegated authority to use 
covert, obfuscated, and  
force in a particular situation, they are required 
non-attributable attacks.
to be attributable to the entity and human that 
deployed them. Designers should ensure that 
there is a clear and auditable authorization of 
Background actions taken by the AWS when in operation.
The lack of a clear owner of a given AWS 
incentivizes scalable covert or non-attributable  Further Resources
uses of force by state and non-state actors. 
•  Bahr, E. “Attribution of Biological Weapons 
Such dynamics can easily lead to unaccountable 
Use,” in Encyclopedia of Bioterrorism 
violence and societal havoc.
Defense. Hoboken, NJ: John Wiley & Sons, 
2005. 
Features of AWS that may contribute to their 
making covert and non-attributable attacks easier 
•  Mistral Solutions. “Close-In Covert 
include: small size; the ability to swarm; and 
Autonomous Disposable Aircraft (CICADA) 
ability to act at great distance and time from 
for Homeland Security,” 2014.
the deployment of a weapon from responsible 
operators; layers of weapons systems within  •  Piore, A. “Rise of the Insect Drones.” Popular 
other systems. Science. January 29, 2014.
States have a legal obligations to make attacks  •  Gillespie, T., and R. West. “Requirements for 
practically attributable. There are additional  Autonomous Unmanned Air Systems Set by 
legal obligations not to booby trap autonomous  Legal Issues.” International C2 Journal 4, no. 
systems. Self-destructive functions, such as  2 (2010): 1–32.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 126The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
•  There is an obligation to consider the 
foreseeable use of the system, and whether 
Issue 9: 
there is a high risk for misuse.
The development of AWS will 
•  There is an obligation to consider, reflect on, 
lead to a complex and troubling 
or discuss possible ethical consequences of 
landscape of proliferation and 
one’s research and/or the publication of that 
abuse. research.
Background
Use of AWS by a myriad of actors of different  Issue 10: 
kinds, including states (of different types of 
AWS could be deployed by 
regime) and non-state actors (militia, rebel 
domestic police forces and 
groups, individuals, companies, including private 
military contractors), would lead to such systems  threaten lives and safety. AWS 
becoming commonplace anywhere anyone  could also be deployed for 
favors violence due to the disintermediation and 
private security. Such AWS  
scalability afforded by their availability.
may have very different design 
There will be incentives for misuse depending  and safety requirements than 
upon state of conflict and type of actor. For 
military AWS.
example, such misuse may include, but is not 
limited to, political oppression, crimes against 
humanity, intimidation, assassination, and 
Background
terrorism. This can lead to, for example, a single 
warlord targeting an opposing tribe based on their  Outside of military uses of AWS, other likely 
respective interests as declared on Facebook,  applications include use by domestic police 
their DNA, their mobile phones, or their  forces, as well as coast guards, border patrols, 
appearance. and other domestic security applications. Police 
in Dallas, Texas used a bomb disposal robot to 
Candidate Recommendations deliver a bomb to kill a suspect in the summer 
of 2016. While that was a remotely operated 
•  One must design weapons with high degrees 
weapon delivered by a remote operated platform, 
of automation in such a way that avoids 
the path to more autonomous forms of police 
tampering for unintended use. Further work 
robots using weapons seems highly likely.
on technical means for nonproliferation 
should be explored, for example,  Beyond use by governments, AWS could 
cryptographic chain authorization. potentially also be deployed for other private 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 127The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
security applications, such as guarding property, 
patrolling areas, and personal protection.
Issue 11: 
Tyrants and despots might utilize AWS to gain or 
An automated weapons  
retain control over a population which would not 
system might not be predictable 
otherwise support them. AWS might be turned 
(depending upon its design 
against peaceful demonstrators when human law 
enforcement might not do the same. and operational use). Learning 
systems compound the problem 
Candidate Recommendations of predictable use.
•  Police and private security systems should 
not be permitted to deploy weapons without 
meaningful human control. Background
•  Police and security systems should deploy  Autonomous systems that react and adapt to 
non-lethal means to disrupt and avert  environmental and sensor inputs results in 
security threats and threats to the physical  systems that may be predictable in their general 
safety of humans. behavior, but may manifest individual or specific 
actions that cannot be predicted in advance.
Further Resources
As autonomous systems become more complex 
•  Asaro, P.  “Will #BlackLivesMatter to  in their processing of data, the ability of designers 
RoboCop?” WeRobot 2016, University of  to anticipate and predict their behavior becomes 
Miami School of Law, Miami, FL, April 1–2,  increasingly difficult.
2016.
As adaptive systems modify their functional 
•  Asaro, P. “‘Hands Up, Don’t Shoot!’ HRI and  operations through learning algorithms and other 
the Automation of Police Use of Force,”  means, their behavior becomes more dependent 
Special Issue on Robotics Law and Policy,  upon the content of training data and other 
Journal of Human-Robot Interaction 5, no. 3  factors which cannot be anticipated by designers 
(2016): 55–69. or operators.
Even when a single system is predictable, or even 
deterministic, when such systems interact with 
other systems, or in large masses or swarms, 
their collective behavior can become intrinsically 
unpredictable. This includes unpredictable 
interactions between known systems and 
adversarial systems whose operational behavior 
may be unknown.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 128The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
Modeling and simulation of AWS, particularly  •  Commanders and operators should be 
learning systems, may not capture all possible  trained to understand and assess confidence 
circumstances of use or situational interaction.  in the behavior of a system under specific 
They are underconstrained cyberphysical  contexts and scope of operations. They 
systems. Intrinsic unpredictability of adaptive  should maintain situational awareness of 
systems is also an issue: one cannot accurately  those contexts where weapons systems are 
model the systems of one’s adversary and how  deployed, and prevent those systems from 
an adversary will adapt to your system resulting in  being used outside the scope of operations 
an inherently unpredictable act. for which their behavior is predictable.
•  To ensure meaningful human control, 
Candidate Recommendations
operators should be able to query a system 
•  Systems that exhibit intrinsically unpredictable  in real-time. Such a query should offer the 
behavior should be considered illegal and   evidence, explanation, and justification  
not deployed. for critical determinations made by the 
systems, i.e., identification of a target,  
•  Similarly, deploying systems with otherwise 
or key recommendations.
predictable behavior in situations or contexts 
in which the collective behavior of systems  •  Weapons systems with advance automation 
cannot be predicted should be avoided. In  should also keep records and traces of critical 
particular, deploying AWS swarms in which  functional and operational decisions that are 
the emergent dynamics of the swarm have  made automatically. Such traces and records 
a significant impact on the actions of an  should be reviewable in instances where the 
individual AWS must be avoided. behavior of the system was not as predicted.
•  The predictability of weapons systems  •  To the extent that systems contain adaptive 
should be assessed with confidence levels  or learning algorithms, any critical decision 
with respect to specified contexts and  made by systems based upon those 
circumstances of use. Systems should not be  algorithms should be transparent and 
used outside of the contexts of use for which  explainable by the designing engineers.  
their operational behavior is understood  Any data used for training and adaptation 
and predictable. Engineers should explicitly  should be reviewed as to its integrity so  
examine their systems and inform their  as to ensure that learned functions can 
customers of their qualitative and quantitative  behave in reliably predictable ways.
confidence in the predictability of the actions 
of the autonomous functions of weapons 
systems in response to representative 
scenarios, specific contexts of use, and  
scope of operations.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 129The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Reframing Autonomous Weapons Systems 
Further Resources
•  International Committee for Robot Arms  •  Edwards, S. J. A. Swarming and the Future 
Control. “LAWS: Ten Problems for Global  of Warfare, Santa Monica, CA: RAND 
Security” (leaflet). April 10, 2015. Corporation, 2004.
•  Owens, D. “Figuring Forseeability.” Wake  •  Rickli, J.-M. “Some Consideration of the 
Forest Law Review 44 (2009): 1277,   Impact of Laws on International Security: 
1281–1290. Strategic Stability, Non-State Actors and 
Future Prospects.” Meeting of Experts on 
•  Scherer, M. “Who’s to Blame (Part 5): A 
Lethal Autonomous Weapons Systems 
Deeper Look at Predicting the Actions of 
Convention on Certain Conventional 
Autonomous Weapons.” Law and AI, February 
Weapons (CCW) United Nations Office 
29, 2016.
Geneva, April 16, 2015.
•  Arquilla, J., and D. Ronfeldt. Swarming and 
•  Scharre, P. Robotics on the Battlefield Part II: 
the Future of Conflict, Santa Monica, CA: 
The Coming Swarm, Washington, DC: Center 
RAND Corporation, 1997. 
for a New American Security, 2014.
 
 
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 130The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
Autonomous and Intelligent systems (A/IS) provide unique and impactful opportunities 
in the humanitarian space. As disruptive technologies, they promise to upend multiple 
historical institutions and corresponding institutional relationships, offering opportunities to 
“re-intermediate” those settings with more humanitarian and equitably focused structures.
The value of A/IS is significantly associated with the generation of superior and unique 
insights, many of which could help to foster the accomplishment of humanitarian and 
development goals and to achieve positive socio-economic outcomes for both developed 
and developing economies. Among the opportunities for cooperation and collaboration  
at the intersection of A/IS and humanitarian and development issues are the following:
A/IS have been recognized as key enablers for achieving the goals of humanitarian relief, 
human rights, and the United Nations Sustainable Development Goals. This recognition 
provides the opportunity to demonstrate the positive and supportive role that A/IS can  
play in these critical, but perennially under-resourced and overlooked, areas.
A/IS are related to, but hold a unique place within, the larger “ICT for development” 
narrative. This intersection creates opportunities for A/IS to be applied in settings where 
commercial and development agendas meet, and to facilitate advances in the administration 
and impact assessment of development programs.
There is an ongoing narrative on affordable and universal access to communications 
networks and the Internet which invites consideration of how the implementations  
and fruits of A/IS will be made available to populations.
The narrative of “A/IS for the common good” is starting to present itself in various settings. 
Key elements framing this “common good” conversation relate to the need for it to be 
human-centered and include the need for accountability and to ensure that outcomes  
are fair and inclusive. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 131The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
The scaling and use of A/IS represent a genuine opportunity to provide individuals and 
communities — be they rural, semi-urban, or cities — with greater autonomy and choice.  
A/IS will potentially disrupt all manner of economic, social, and political relationships  
and interactions. Those disruptions will provide a historical opportunity to re-establish  
those settings so that they are reflective of more updated and sustainable notions of 
autonomy and choice.
Many of the debates surrounding A/IS take place within advanced countries among 
individuals benefiting from adequate finances and higher-than-average living situations.  
It is imperative that all humans in any condition around the world are considered in  
the general development and application of these systems to avoid the risk of bias, 
excessive imbalances, classism, and general non-acceptance of these technologies.
In the absence of that comprehensive treatment, A/IS policy issues will be addressed 
piecemeal by different jurisdictions and in different sectors. In that context of “distributed 
policy making,” a patchwork of policies and initiatives is the likely result, dissipating potential 
impact. However, some measure of “policy interoperability” can still be served if there is 
a common framing or policy generation process for analysis that can be shared across 
jurisdictions and/or sectors.
The use of A/IS in support of the pragmatic outcomes noted above is best framed within 
four key domains that comprise the following four sections: economics, privacy and 
safety, education, and equal availability. Each of these contexts presents unique 
challenges, attention to which can inform the trustworthy use of A/IS for the common good.
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable.  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 132The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
Section 1 — Economics
While the increase of A/IS and its positive uses  entail a sense of global citizenship and  
in society are undeniable, the financial gains from  of responsibility as members of humanity.
these technologies may favor certain sectors, and 
Beyond considering the humanitarian role of 
are not evenly distributed throughout populations 
A/IS, there is a pressing need to address how 
where it is created or deployed. Likewise, while 
these technologies can contribute to achieving 
A/IS automation of certain human tasks may 
the UN Sustainable Development Goals that 
be beneficial by supplanting arduous jobs, how 
concern eradicating poverty, illiteracy, gender 
employment in aggregate for specific populations 
and ethnic inequality, and combating the impact 
and job verticals will be affected by A/IS needs to 
of climate change.
be addressed.
The inequality gap between the developed 
and the developing nations is disturbingly wide. 
Issue: 
With the introduction of hi-tech, the world had 
A/IS should contribute to  witnessed a considerable increase in the existing 
gap as the new market is dominated by products 
achieving the UN Sustainable 
and services from this new sector. One of the 
Development Goals.
factors contributing to this is the nature of the 
tech economy and its tendency to concentrate 
wealth in the hands of few. The tech economy is 
Background also susceptible to corporate aggregation.
The contribution of A/IS to human and 
We need to answer questions such as “How will 
sustainable development in developing 
developing nations implement A/IS via existing 
countries, and in particular extreme poverty 
resources? Do the economics of developing 
eradication, is inherently connected with 
nations allow for A/IS implementation? What 
its contribution to human well-being in the 
should be the role of the public and the private 
developed world. In a globalizing society, one 
sectors and society in designing, developing, 
part of the world has a direct impact on another. 
implementing, and controlling A/IS? How can 
With a growing level of interdependence 
people without technical expertise maintain 
between communities, the challenges and 
these systems?”
opportunities are truly global. Climate change, 
poverty, globalization, and technology are closely  The risk of unemployment for developing 
interconnected. Ethical commitment should  countries is more serious than for developed 
countries. The industry of most developing 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 133The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
countries is labor intensive. While labor may  •  Developing mechanisms for increasing 
be cheap(er) in developing economies, the  transparency of power structures and justly 
ripple effects will be felt much more than in  sharing the economic and knowledge 
the developed economies as more and more  acquisition benefits of robotics/A/IS.
jobs will be gradually replaced along with the 
•  Facilitating robotics/A/IS research and 
development of robots or A/IS.
development in developing nations.
As an example, in the manufacturing industry, 
•  Empowering the education sector with 
lots of products such as mobile phones and 
advanced courses on A/IS is the first step 
clothes are designed in developed countries, 
toward creating a nation that can handle the 
but made in developing countries. Thus, it is not 
new economic and power shifts.
difficult to predict that the developing countries 
will be at greater risk of unemployment than 
•  Investing in technology transfer will help 
developed countries if those manufacturing 
developing nations reduce the gap.
tasks can be replaced by machines. The 
challenge of unemployment is even bigger  •  Adapting legal and policy frameworks which 
for developing countries than for developed  will help to favor equitable distribution of 
countries, which can exacerbate the economic  wealth, empowering competent international 
and power-structure differences between   organizations to favor a minimally viable 
and within developed and developing nations. competition level on the A/IS markets to 
avoid detrimental monopolistic situations.
Candidate Recommendations
•  Identifying A/IS technologies relevant to the 
The current panorama of applications of A/ UN Sustainable Development Goals such 
IS in sectors crucial to the UN Sustainable  as big data for development (agriculture, 
Development Goals should be studied, and the  medical tele-diagnosis), geographic 
strengths, weaknesses, and potential of some of  information systems (disaster prevention, 
the most significant recent applications drawn  emergency planning), and control systems 
from these sectors should be analyzed. Specific  (naturalizing intelligent cities through energy 
areas to consider include: and traffic control, management of urban 
agriculture).
•  Taking appropriate action to mitigate the 
gap. The private sector should integrate  •  Developing guidelines and 
CSR (corporate social responsibility) at  recommendations for the nurturing and 
the core of development and marketing  implementation of these technologies in 
strategies and operations. Mitigating the  developing countries.
social problems of technology development 
•  Documenting and disseminating successful 
should be a special focus of responsible 
examples of good practice, and evaluations 
companies using A/IS.
and conclusions of experiences.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 134The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
•  Developing appropriate impact indices  Candidate Recommendations
for the evaluation of A/IS technological 
•  Develop mechanisms for increasing 
interventions in developing countries from 
transparency of power structures and justly 
multiple perspectives.
sharing the economic and knowledge 
acquisition benefits of A/IS.
Further Resources
•  Facilitate A/IS research and development 
•  United Nations. “Sustainable Development 
in developing nations. Ensure that 
Goals: 17 Goals to Transform Our World.” 
representatives of developing nations  
September 25, 2015.
are involved.
•  Along with the use of A/IS, discussions 
Issue:  related to identity, platforms, and 
blockchain are needed to ensure that 
It is unclear how developing 
all of the core enabling technologies are 
nations can best implement  
designed to meet the needs of LMICs.
A/IS via existing resources.
Further Resources
•  Ajakaiye, O., and M. S. Kimenyi. “Higher 
Background
Education and Economic Development in 
Do the economics of developing nations allow  Africa: Introduction and Overview.” Journal of 
for A/IS implementation? How can people  African Economies 20, no. 3 (2011): iii3–iii13.
without technical expertise maintain design 
•  Bloom, D. E., D. Canning, and K. Chan. Higher 
specifications and procure these systems? 
Education and Economic Development in 
The potential use of A/IS to create sustainable 
Africa (Vol. 102). Washington, DC: World 
economic growth for LMICs (lower and middle 
Bank, 2006.
income countries) is uniquely powerful. If  
A/IS capacity and governance problems are 
•  Bloom, N. “Corporations in the Age of 
addressed, LMICs will have the ability to use  
Inequality.” Harvard Business Review, April 
A/IS to transform their economies and leapfrog 
21, 2017. 
into a new era of inclusive growth if a clear path 
for development is provided. Particular attention,  •  Dahlman, C. Technology, Globalization, and 
however, should be paid to ensure that the use  Competitiveness: Challenges for Developing 
of A/IS for the common good — especially in the  Countries. Industrialization in the 21st 
context of LMICs — does not reinforce existing  Century. New York: United Nations, 2006.
socio-economic inequities.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 135The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
•  Fong, M. Technology Leapfrogging for 
Developing Countries. Encyclopedia of 
Issue: 
Information Science and Technology, 2nd ed. 
Hershey, PA: IGI Global, 2009 (pp. 3707– The complexities of  
3713). employment are being  
neglected regarding A/IS. 
•  Frey, C. B., and M. A. Osborne. “The Future 
of Employment: How Susceptible Are Jobs to 
Computerisation?” (working paper). Oxford, 
U.K.: Oxford University, 2013. Background
•  Rotman, D. “How Technology Is Destroying  Current attention on automation and 
Jobs.” MIT Technology Review, June 12, 2013. employment tends to focus on the sheer number 
of jobs lost or gained. Other concerns include 
•  McKinsey Global Institute. “Disruptive  changes in traditional employment structures.
Technologies: Advances That Will Transform 
Life, Business, and the Global Economy” 
Candidate Recommendations
(report), May 2013.
It is important to focus the analysis on how 
•  Sauter, R., and J. Watson. “Technology  employment structures will be changed by 
Leapfrogging: A Review of the Evidence,  automation and AI rather than on solely dwelling 
A Report for DFID.” Brighton, England:  on the number of jobs that might be impacted. 
University of Sussex. October 3, 2008. The analysis should focus on how current 
task content of jobs are changed based on a 
•  “The Rich and the Rest.” The Economist. 
clear assessment of the automatibility of the 
October 13, 2012. 
occupational description of such jobs.
•  “Wealth Without Workers, Workers Without 
While there is evidence that robots and 
Wealth.” The Economist. October 4, 2014. 
automation are taking jobs away in various 
•  World Bank. “Global Economic Prospects  sectors, a more balanced, granular, analytical, 
2008: Technology Diffusion in the  and objective treatment of this subject will more 
Developing World.” Washington, DC: World  effectively help inform policy making. Specifics to 
Bank, 2008.  accomplish this include:
 
•  Create an international, independent agency 
 
which can properly disseminate objective 
 
statistics and inform media as well as the 
 
general public about the impact of robotics 
and A/IS on jobs and growth.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 136The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
•  Consider both product and process  public side could facilitate such initiatives 
innovation and look at it from a global  with co-investment in the training programs 
perspective as a way to understand properly  through tax incentives.
the global impact of A/IS on employment 
(refer to Pianta, 2009 and Vivarelli 2007). Further Resources
•  Focus the analysis on how employment  •  RockEU. “Robotics Coordination Action 
structures will be changed by A/IS rather  for Europe Report on Robotics and 
than on the number of jobs that might  Employment,” Deliverable D3.4.1, June 30, 
be impacted. The analysis should focus  2016.
on how current task-content of jobs are 
•  International Federation of Robotics. 
changed based on a clear assessment of the 
“The Impact of Robots on Productivity, 
automatibility of the occupational description 
Employment and Jobs,” A positioning paper 
of such jobs (refer to Bonin et al. 2015 and 
by the International Federation of Robotics, 
RockEU, 2016).
April 2017.
•  Make sure workers can improve their 
•  Brynjolfsson, E., and A. McAfee. The 
adaptability to fast technological changes by 
Second Age of Machine Intelligence: Work 
providing them adequate training programs. 
Progress and Prosperity in a Time of Brilliant 
Those training programs could be available 
Technologies. New York: W. W. Norton & 
to any worker with a special attention to 
Company, 2014.
low-skilled workforce members. Those 
programs can be private (sponsored by the 
employer) or public (offered freely through 
specific public channels and policies), and 
they should be open while the worker is in- Issue: 
between jobs or still employed.
Automation is often viewed  
•  Ensure that not only the worker whose job is  only within market contexts.
concerned benefits from training programs, 
but also any employee in the company so 
everyone has the chance to be up to speed 
Background
with technical changes, even if one’s job 
A/IS are expected to have an impact beyond 
is not immediately concerned (not only 
market domains and business models. Examples 
reaction but also prevention). Thus it should 
of impact include safety, public health, and 
be the responsibility of every company to 
socio-political considerations of deploying A/
increase its investment in the internal training 
IS. This impact will diffuse through the global 
of its workforce based on the profitability 
society.
gains realized thanks to automation. The 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 137The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
Candidate Recommendation White House 2016 report Artificial Intelligence, 
Automation, and the Economy is emblematic  
To understand the impact of A/IS on society, it is 
of what’s at stake: 2.2 to 3.1 million existing  
necessary to consider both product and process 
part- and full-time U.S. jobs are exposed over  
innovation as well as wider implications from a 
the next two decades, although the timeline 
global perspective.
remains uncertain. In particular, between 1.3  
and 1.7 million heavy truck drivers are 
Further Resources
threatened. And this is not trivial, for the 
•  Pianta, M. Innovation and Employment,  profession has symbolized in the collective 
Handbook of Innovation. Oxford, U.K.:  imagination the manifestation of the American 
Oxford University Press, 2003. dream of empowerment, liberty, and social 
ascension whereby less-educated people could 
•  Vivarelli, M. “Innovation and Employment: A 
make it into the middle class.
Survey,” Institute for the Study of Labor (IZA) 
Discussion Paper No. 2621, February 2007. The automation wave calls at least for higher 
investment and probably the need to reinvent 
active labor market programs in the coming 
decades. Such investment should logically be 
funded by fiscal policies targeting the capital.  
Issue: 
The 2016 White House report gave an interesting 
Technological change   order of magnitude applied to the case of the 
is happening too fast for   United States: “increasing funding for job training 
in the U.S. by six-fold — which would match 
existing methods of  
spending as a percentage of GDP to Germany, 
(re)training the workforce.
but still leave the U.S. far behind other European 
countries — would enable retraining of an 
additional 2.5 million people per year.”
Background
A/IS and other digital technologies offer real 
The current pace of technological development 
potential to innovate new approaches to 
will heavily influence changes in employment 
job-search assistance, placement, and hiring 
structure. In order to properly prepare the 
processes in the age of personalized services. 
workforce for such evolution, actions should be 
The efficiency of matching labor supply and 
proactive and not only reactive.
demand can be tremendously enhanced by 
the rise of multi-sided platforms and predictive 
The wave of automation caused by the A/IS 
analytics. The case of platforms, such as LinkedIn 
revolution will displace a very large amount of 
for instance with its 470 million registered users, 
jobs across domains and value chains. The U.S. 
is interesting as an evolution in hiring practices. 
“automated vehicle” case study analyzed in the 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 138The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
Tailored counseling and integrated re-training  •  To lay solid foundations for the profound 
programs also represent promising grounds for  transformation outlined above, more research 
innovation. in at least three complementary areas  
is needed:
This, however, will not be enough. A lot will have 
to be done to create fair and effective life-long  •  First, to devise mechanisms of 
skill development/training infrastructure and  dynamic mapping of tasks and 
mechanisms capable of empowering millions  occupations at risks of automation 
of people to viably transition jobs, sectors, and  and associated employment 
potentially geographies. A lot will also have to be  volumes. This mapping of the 
done to address differential geographic impacts  workforce supply is needed at the 
which exacerbate income and wealth disparities.  macro, but also crucially at the micro, 
Effectively enabling the workforce to be more  levels where labor market programs 
mobile — physically, legally, and virtually — will be  are deployed;
crucial. This implies systemic policy approaches 
•  Integrated with that, more granular 
which encompass housing, transportation, 
and dynamic mapping of the future 
licensing, taxes, and, crucially in the age of A/IS, 
jobs/tasks, workplace-structures, 
broadband access, especially in rural areas.
associated work-habits, and skill-
base spurred by the A/IS revolution 
Candidate Recommendations
are also needed. This mapping of 
•  To cope with the technological pace and  the demand side will be key to 
ensuing progress of A/IS, it will be necessary  innovate, align, and synchronize skill 
for workers to improve their adaptability  development and training programs 
to rapid technological changes through  with future requirements. 
adequate training programs provided to 
•  More policy research on the 
develop appropriate skillsets. Training 
dynamics of professional transitions 
programs should be available to any worker 
in different labor market conditions  
with special attention to the low-skilled 
is required.
workforce. Those programs can be private 
(sponsored by the employer) or public 
•  To maximize intended impact, create 
(offered freely through specific public 
necessary space for trial-and-error strategies, 
channels and policies), and they should be 
and to scale up solutions that work, 
open while the worker is in between jobs or 
implement robust, data-driven evidence-
still employed. Fallback strategies also need 
based approaches. These approaches should 
to be developed for those who cannot be 
be based on experiments and centered on 
re-trained.
outcomes in terms of employment but also 
in terms of earnings. New forms of people-
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 139The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
public-private partnerships involving civil  Further Resources
society as well as new outcome-oriented 
•  Executive Office of the President. Artificial 
financial mechanisms (social impact bonds, 
Intelligence, Automation, and the Economy. 
for instance) that help scale up successful 
December 20, 2016.
innovations should also be considered.
•  Kilcarr, S. “Defining the American Dream for 
•  The next generation of highly qualified 
Trucking ... and the Nation, Too,” FleetOwner, 
personnel should be ready to close skills 
April 26, 2016.
gaps and develop future workforces. New 
programs should be offered possibly earlier  •  OECD, “Labor Market Programs: Expenditure 
than high school, to increase access to  and Participants,” OECD Employment and 
employment in the future.  Labor Market Statistics (database), 2016. 
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 140The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
Section 2 — Privacy and Safety
The growing volumes of private sector data  According to the GSMA, the number of mobile 
(mobile phones, financial transactions, retail,  Internet users in the developing world will 
logistics) hold unique promise in developing  double from 1.5 billion in 2013 to 3 billion 
more robust and actionable disease-monitoring  by 2020, rising from 25% of the developing 
systems that can be empowered by A/IS.  world population to 45% over the period. In 
However, concerns related to privacy, the ability  Sub-Saharan Africa, just 17% of the population 
of individuals to opt out, the cross-border nature  were mobile Internet subscribers in 2013, but 
of data flows, and the political and commercial  penetration is forecast to increase to 37% by 
power dynamics of this data are the key factors   2020–making the generation, storage, use, 
to consider in how to most equitably shape   and sharing of personal data in the developing 
this domain. world an issue that will continue to gain gravity.
In the humanitarian sector, digital technologies 
have streamlined data collection and data 
Issue: 
sharing, frequently enabling improved outcomes. 
There is a lack of access   With a focus on rights and dignity of the 
and understanding regarding  populations served, practitioners and agencies 
have advocated for more data sharing and open 
personal information.
data in the social good sector. Timely access to 
public, social sector, and private data will speed 
response, avoid collection duplications, and 
Background
provide a more comprehensive summary of a 
How to handle privacy and safety issues,  situation, based on multiple data streams and a 
especially as they apply to data in humanitarian  wider range of indicators.
and development contexts? Urgent issues around 
However, there are inherent risks when multiple 
individual consent, potential privacy breaches, 
sources of data are overlaid and combined to 
and potential for harm or discrimination regarding 
gain insights, as vulnerable groups or individuals 
individual’s personal data require attention and 
can be inadvertently identified in the process. 
standardized approaches.
The privacy threat is the most discussed risk: 
This is especially true with populations that are  When is informed consent or opt-in really 
recently online, or lacking a good understanding  ethical and effective? Best practices remain an 
of data use and the ambiguities of data  unresolved issue among practitioners when 
“ownership,” privacy, and how their digital   working with communities with fewer resources, 
access generates personal data by-products   low literacy, lower connectivity, and less 
used by third parties. understanding about digital privacy.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 141The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
The “do no harm” principle is practiced in  •  Improving digital literacy of citizens should be 
emergency and conflict situations. Humanitarian  a high priority for the government and other 
responders have a responsibility to educate  organizations.
the populations about what will happen with 
•  Governments should enforce transparency 
their data in general, and what might happen if 
related to data collection, data ownership, 
it is shared openly; there is often lack of clarity 
data stewardship, and data usage and 
around how these decisions are currently being 
disclosure. 
made and by whom. Remedial steps should 
•  Organizations should be held accountable 
include community education regarding digital 
for data misuse, financial loss, and harm to 
privacy, as well as helping vulnerable groups 
the reputation of the data object if data is 
become more savvy digital citizens.
mishandled. This requires that organizations 
There are perception gaps regarding what 
have appropriate policies and agreements 
constitutes potential and actual harm stemming 
in place, that terms and conditions of the 
from data use practices. A collaborative 
agreements are clearly communicated with 
consensus across sectors is needed on 
the data object and that data misuse cases 
safeguarding against risks in data collection, 
and legitimate use cases are well-defined  
sharing, and analysis — particularly of combined 
in advance.
sets. From the outset, iterative, ethics-based 
approaches addressing data risk and privacy are  Further Resources
key to identify and mitigate risks, informing better 
•  For more on responsible data use, please 
action and decision-making in the process.
see the section “Personal Data and Individual 
Access Control.”
Candidate Recommendation
•  For more on responsible data use, see 
Frameworks such as Privacy by Design can guide 
the Responsible Development Data Book. 
the process of identifying appropriate system 
Oxfam also has a responsible data policy that 
and software requirements in early stages 
provides a field-tested reference.
of design. Such frameworks also encourage 
proactive examination of harms and risks, seek  •  Example Use Case from GSMA: When Call 
to engage the data subject (e.g., consumer, user,  Data Records (CDRs) are used to help in 
stakeholders) in the design of the software,  the response to the Ebola outbreak, mobile 
and recommend best practices and regulatory  operators wish to ensure mobile users’ 
requirements (such as data minimization,  privacy is respected and protected and 
accountability, transparency, options such as   associated risks are addressed.
opt-in, opt-out, encryption) to be embedded  
•  van Rest J., D. Boonstra, M. Everts, M. van 
into the system. In addition:
Rijn, R. van Paassen. “Designing Privacy-by-
Design,” in Privacy Technologies and Policy, 
•  Best practices such as Privacy Impact 
edited by B. Preneel, and D. Ikonomou. 
Assessments will assist with identification of 
Lecture Notes in Computer Science, vol. 
data misuse cases at early stages of system/
8319. Berlin, Germany: Springer, 2012.
software design.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 142The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
Section 3 — Education
It is essential to increase the awareness,  The same is true in other disciplines. However, 
critical understanding, and attitudinal values  where standards are either absent or in the 
of undergraduate and postgraduate students  process of development in a sector, what is 
related to sustainable human development  most appropriately included in undergraduate 
and its relationship with A/IS, so that they are  and graduate curriculum is less clear. That is the 
prepared to assume their responsibilities in  case for a number of areas in the digital world, 
the solution of the current global social crises.  including A/IS. Thus, educators and other parties 
Current and future leaders should be educated  involved in curriculum development should 
in macro-ethics and not only in micro-ethics. consider the opportunity to craft curricula that 
will make their students aware of this absence 
Shared narratives, generated by awareness, 
of standards, and also encourage the exploration 
education, and standard evaluative models 
of various practices as candidates for “best 
are the best pathway to generating the global 
practices” and their possible further elevation to 
support necessary to meet these challenges. 
standards in AI technology and policy.
Programs fostering awareness, education, 
and analytical and governance models should 
Candidate Recommendations
address the opportunities and risks of A/IS  
in development contexts.  The understanding of the global dimension  
of engineering practice should be embedded in 
A/IS curricula. Specifically:
Issue: 
•  Curriculum/core competencies should 
How best to incorporate the  be defined and preparation of course-
“global dimension of engineering”  material repositories and choice of the most 
adequate pedagogical approaches should  
approach in undergraduate and 
be established.
postgraduate education in A/IS.
•  The potential of A/IS applications should 
be emphasized in undergraduate and 
graduate programs specifically aimed at 
Background
engineering in international development 
A/IS presents a unique opportunity for 
and humanitarian relief contexts as well as 
narrative and policy construction in educational 
in the training programs preparing technical 
institutions. Where norms exist, they are taught 
professionals for work in the international 
in schools. Thus, physics majors learn the 
development and humanitarian sectors.
“standard” theories and equations of physics. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 143The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
•  Increased awareness on the opportunities  Further Resource
and risks faced by Lower Middle Income 
•  Global Dimension in Engineering Education 
Countries (LMICs) in the use of A/IS for 
Project (GDEE).
sustainable development and humanitarian 
purposes is critical. Ignoring these 
opportunities and risks will further divide 
the opportunities for development across 
the globe. A/IS presents an opportunity to 
potentially reduce these differentials that 
ultimately strain social fabric and economic 
systems.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 144The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Economics and Humanitarian Issues
Section 4 — Equal Availability
For A/IS to be adopted in an atmosphere of trust  3.  Promote distribution of knowledge and 
and safety, greater efforts must be undertaken to  wealth generated by the latest A/IS,  
increase availability of these resources. including formal financial mechanisms  
(such as taxation or donations to effect 
such equity worldwide).
Issue: 
4.  International organizations, government 
AI and autonomous technologies  bodies, universities, and research  
are not equally available  institutes should promote research into  
A/IS technologies that are readily available 
worldwide.
in developing countries, for example, 
mobile lightweight A/IS applications 
(taking advantage of the widespread use 
Background
of increasingly affordable Internet-enabled 
Equitable distribution of the benefits of A/IS  phones in developing contexts) and  
technology worldwide should be prioritized.  culture-aware systems.
Training, education, and opportunities in A/IS 
5.  National and international development 
worldwide should be provided particularly with 
cooperation agencies and NGOs should  
respect to underdeveloped nations.
draw attention to the potential role of A/IS  
in human and sustainable development.
Candidate Recommendations
Working with appropriate organizations   Further Resources
(e.g., the United Nations) stakeholders from 
•  Hazeltine, B., and C. Bull. Appropriate 
a cross-sectional combination of government, 
Technology: Tools, Choices, and Implications. 
corporate, and non-governmental organization 
New York: Academic Press, 1999.
(NGO) communities should:
•  Akubue, A. “Appropriate Technology for 
1.  Engage in discussions regarding effective 
Socioeconomic Development in Third World 
A/IS education and training.
Countries.” The Journal of Technology 
2.  Encourage global standardization/ Studies 26, no. 1 (2000): 33–43.
harmonization and open source software  
for A/IS.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 145The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
The first edition of the law section for Ethically Aligned Design noted that the early stages 
in development of autonomous and intelligent systems (A/IS) have given rise to many 
complex ethical problems that translate directly and indirectly into discrete legal challenges. 
That is, of course, what the rule of law often intends to answer — how we should behave 
as a society when faced with difficult ethical decisions — and it should come as no surprise 
that the legal implications of A/IS continue to unfold as we witness the forms of its 
expression and use expand.
To consider the ongoing creep of A/IS ethical issues into the legal realm, one need look 
no further than the first section of this document: Legal Status. This section addresses 
what legal status should A/IS be granted and was not a topic in the original edition. That 
is to say, in just one revision of this paper, we felt the need to address the question of 
how A/IS should be labeled in the courts’ eyes: a product that can be bought and sold? 
A domesticated animal with more rights than a simple piece of property, but less than a 
human? A person? Something new?
Our conclusion to that question is that A/IS are not yet deserving of any kind of 
“personhood” — yet the very fact that the question of whether A/IS could, or should, be 
granted such status demonstrates the rate at which the technology and the related legal and 
ethical questions are growing and provide two universal principles echoed throughout this 
document:
The development, design, and distribution of A/IS should fully comply with all applicable 
international and domestic law.
There is much work to be done: the legal and academic community must increase 
engagement in this rapidly developing field from its members.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 146The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
Concerns and recommendations fall into four main areas:
1. Legal Status of A/IS
2. Governmental Use of A/IS: Transparency and Individual Rights
3. Legal Accountability for Harm Caused by A/IS
4. Transparency, Accountability, and Verifiability in A/IS
While much debate continues to surround A/IS, its development, and use, these questions 
must be addressed before the proliferation of A/IS passes some kind of tipping point.  
The authors hope this paper will inform the legislative process and inspire more members 
of the legal community to become involved now.
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 147The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
Section 1 — Legal Status of A/IS
There has been much discussion about how to  appearance. As some types of A/IS begin to 
legally regulate A/IS-related technologies, and  display characteristics that resemble those of 
the appropriate legal treatment of systems that  human actors, some governmental entities and 
deploy these technologies. Lawmakers today  private commentators have concluded that it 
are wrestling with the issue of what status  is time to examine how legal regimes should 
to apply to A/IS. Legal “personhood” (as is  categorize and treat various types of A/IS. These 
applied to humans and certain types of human  entities have posited questions such as, “Should 
organizations) is one possible option for   the law treat such systems as legal ‘persons,’ with 
framing such legal treatment, and the  all the rights and responsibilities that personhood 
implications of granting that status to A/IS  entails?” Such status seems initially remarkable 
applications raises issues that have implications  until consideration is given to the long-standing 
in multiple domains of human interaction  legal personhood status granted to corporations, 
beyond technical issues. governmental entities, and the like — none  
of which are human even though they are  
run by humans.
Issue: 
Alternatively, many entities have asked, should 
What type of legal status (or  some A/IS be treated as mere products and tools 
other legal analytical framework)  of their human developers and users? Perhaps 
A/IS are something entirely without precedent, 
is appropriate for application 
raising the question of whether one or more 
to A/IS, given the legal issues 
types of A/IS might be assigned an intermediate 
raised by deployment of such 
— and perhaps novel — type of legal status?
technologies?
Clarifying the legal status of A/IS in one or 
more jurisdictions is essential in removing the 
uncertainty associated with the obligations and 
Background
expectations for organization and operation of 
The convergence of A/IS and robotics  these systems. Clarification along these lines 
technologies has led to the development  will encourage more certain development and 
of systems and devices with attributes that  deployment of A/IS and will help clarify lines of 
resemble those of human beings in terms of their  legal responsibility and liability when A/IS cause 
autonomy, ability to perform intellectual tasks  harm. Recognizing A/IS as independent “legal 
and, in the case of some robots, their physical  persons” would, for example, limit or eliminate 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 148The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
some human responsibility for subsequent  deployed. This uncertainty, coupled with the 
“decisions” made by such A/IS (for example  multiple legal jurisdictions in which A/IS are being 
under a theory of “intervening causation” — akin  deployed (each of which, as a sovereign, can 
to the “relief” from responsibility of a hammer  regulate A/IS as it sees fit) suggests that there 
manufacturer when a burglar uses a hammer to  are multiple general frameworks through which 
break the window of a house), thus potentially  to consider A/IS legal status. Below are some 
reducing the incentives for designers, developers,  examples.
and users of A/IS to ensure their safety. In 
this example, legal issues that are applied in  Candidate Recommendations 
similar “chain of causation” settings (such as 
1.  While conferring legal personhood on A/
“foreseeability,” “complicity,” “reasonable care,” 
IS might bring some economic benefits, 
“strict liability” for unreasonably dangerous goods, 
the technology has not yet developed 
and other precedential notions) will factor into 
to the point where it would be legally or 
the design process. Different jurisdictions may 
morally appropriate to generally accord A/
reach different conclusions about the nature of 
IS the rights and responsibilities inherent in 
such causation chains, inviting future creative 
the legal definition of personhood, as it is 
legal planners to consider how and where to 
defined today. Therefore, even absent the 
pursue design, development, and deployment of 
consideration of any negative ramifications 
future A/IS in order to receive the most beneficial 
from personhood status, it would be unwise 
legal treatment.
to accord such status to A/IS at this time. A/
The issue of the legal status of A/IS thus  IS should therefore remain to be subject to 
intertwines with broader legal questions regarding  the applicable regimes of property law. 
how to ensure accountability and assign and 
2.  Government and industry stakeholders alike 
allocate liability when A/IS cause harm. The 
should identify the types of decisions and 
question of legal personhood for A/IS also 
operations that should never be delegated 
interacts with broader ethical questions on the 
to A/IS, and adopt rules and standards that 
extent to which A/IS should be treated as moral 
ensure effective human control over those 
agents independent from their human designers 
decisions. Modern legal systems already 
and operators, and whether recognition of A/IS 
address a number of other situations that 
personhood would enhance or detract from the 
could serve as appropriate analogues for the 
purposes for which humans created the A/IS in 
legal status of A/IS and how to allocate legal 
the first place.
responsibility for harm caused by A/IS. These 
A/IS are at an early stage of development where  legal analogues may include the treatment of 
it is premature to assert a single particular legal  pets, livestock, wild animals, employees, and 
status or presumption for application in the many  other “agents” of persons and corporations. 
forms and settings in which those systems are  Governments and courts should review 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 149The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
these various potential legal models and  ensure that the interest of humanity — and 
assess whether they could serve as a proper  not the interests of the autonomous systems 
basis for assigning and apportioning legal  themselves — remains the guiding principle.
rights and responsibilities with respect to the 
deployment and use of A/IS.  Further Resources
3.  In addition, governments should scrutinize  •  Bayern, S. “The Implications of Modern 
existing laws — especially those governing  Business-Entity Law for the Regulation of 
business organizations — for mechanisms  Autonomous Systems.” Stanford Technology 
that could have the practical effect of  Law Review 19, no. 1 (2015): 93–112.
allowing A/IS to have legal autonomy. If 
•  Bayern, S.  et al., “Company Law and 
ambiguities or loopholes in the law could 
Autonomous Systems: A Blueprint for 
create a legal method for recognizing A/IS 
Lawyers, Entrepreneurs, and Regulators.” 
personhood, the government should review 
Hastings Science and Technology Law 
and, if appropriate, amend the pertinent laws.
Journal 9, no. 2 (2017): 135–162. 
4.  Manufacturers and operators should gain 
•  Bhattacharyya, D. “Being, River: The Law, the 
an understanding of how each jurisdiction 
Person and the Unthinkable.” Humanities 
would categorize a given A/IS and how each 
and Social Sciences Online, April 26, 2017.
jurisdiction would treat harm caused by the 
system. Manufacturers and operators should 
•  Calverley, D. J. “Android Science and Animal 
be required to comply with the applicable 
Rights, Does an Analogy Exist?” Connection 
laws of all jurisdictions in which that system 
Science  18, no. 4 (2006): 403–417.
could operate. In addition, manufacturers and 
operators should be aware of standards of  •  Calverley, D. J. “Imagining a Non-Biological 
performance and measurement promulgated  Machine as a Legal Person.” AI & Society  22 
by standards development organization and  (2008): 403–417. 
agencies. 
•  European Parliament Resolution of 16 
5.  As A/IS become more sophisticated,  February 2017 with recommendations to the 
governments should reassess the issue  Commission on Civil Law Rules on Robotics. 
of legal status for these systems. In 
•  Zyga, L. “Incident of Drunk Man Kicking 
considering whether to accord legal 
Humanoid Robot Raises Legal Questions,” 
protections, rights, and responsibilities to 
Techxplore, October 2, 2015. 
A/IS, governments should exercise utmost 
caution. Governments and decision-makers  •  LoPucki, L. M. “Algorithmic Entities.” 
at every level must work closely with  Washington University Law Review 95 
regulators, representatives of civil society,  (forthcoming 2017).
industry actors, and other stakeholders to 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 150The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
•  Scherer, M. “Digital Analogues.” Imaginary  •  Weaver, J. F. Robots Are People Too: How 
Papers, June 8, 2016. Siri, Google Car, and Artificial Intelligence Will 
Force Us to Change Our Laws. Santa Barbara, 
•  Scherer, M. “Is Legal Personhood for AI 
CA: Praeger, 2013.
Already Possible Under Current United States 
Laws?” Law and AI, May 14, 2017. •  European Parliament. European Parliament 
Resolution of 16 February 2017 with 
•  Solum, L. B. “Legal Personhood for Artificial 
Recommendations to the Commission  
Intelligences.” North Carolina Law Review 70, 
on Civil Law Rules on Robotics.  
no. 4 (1992): 1231–1287.
February 16, 2017. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 151The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
Section 2 — Governmental Use of A/IS: 
Transparency and Individual Rights
Surveillance of populations by governments  Candidate Recommendations
and the disruption of free elections will become 
1.  Government stakeholders should identify 
ever easier as we deploy A/IS. How should we 
the types of decisions and operations that 
manage these systems to ensure that they act for 
should never be delegated to A/IS, such as 
the good of society?
when to use lethal force, and adopt rules 
and standards that ensure effective human 
control over those decisions. 
Issue: 
International, national, and local 
2.  Governments should not employ A/IS that 
governments are using A/IS.   cannot provide an account of the law and 
How can we ensure the A/IS   facts essential to decisions or risk scores. 
The determination of, for example, fraud by 
that governments employ do  
a citizen should not be done by statistical 
not infringe on citizens’ rights? 
analysis alone. Common sense in the A/IS 
and an ability to explain its logical reasoning 
must be required. Given the current abilities 
Background of A/IS, under no circumstances should court 
decisions be made by such systems alone. 
Government increasingly automates part or all of 
Parties, their lawyers, and courts must have 
its decision-making. Law mandates transparency, 
reasonable access to all data and information 
participation, and accuracy in government 
generated and used by A/IS technologies 
decision-making. When government deprives 
employed by governments and other  
individuals of fundamental rights, individuals are 
state authorities.
owed notice and a chance to be heard to contest 
those decisions. A key concern is how legal 
3.  A/IS should be designed with transparency 
commitments of transparency, participation, and 
and accountability as primary objectives. 
accuracy can be guaranteed when algorithmic-
The logic and rules embedded in the system 
based A/IS make important decisions about 
must be available to overseers of systems, 
individuals.
if possible. If, however, the system’s logic 
or algorithm cannot be made available for 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 152The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
inspection, then alternative ways must   6.  Investor list(s), developers, and promoters of 
be available to uphold the values   any given A/IS being developed should be 
of transparency. Such systems should   required by law to be made public when the 
be subject to risk assessments and   A/IS are used for governmental purposes. 
rigorous testing. There should also be transparency of the 
specific ethical values promoted by the 
designer, and how they were embedded in 
4.  Individuals should be provided a forum to 
the system. Transparency should also apply 
make a case for extenuating circumstances 
to the input data selection process.
that the A/IS may not appreciate — in other 
words, a recourse to a human appeal. 
Policy should not be automated if it has not  Further Resources
undergone formal or informal rulemaking 
•  Schwartz, P. “Data Processing and 
procedures, such as interpretative rules and 
Government Administration: The Failure 
policy statements.
of the American Legal Response to the 
Computer.” Hastings Law Journal 43 
5.  Automated systems should generate audit 
(1991): 1321–1389.
trails recording the facts and law supporting 
decisions and such systems should be 
•  Citron, D. K. “Technological Due 
amenable to third-party verification to 
Process.” Washington University Law 
show that the trails reflect what the system 
Review 85 (2007): 1249–1313.
in fact did. Audit trails should include a 
comprehensive history of decisions made in 
•  Citron, D. K. “Open Code Governance.” 
a case, including the identity of individuals 
University of Chicago Legal Forum 
who recorded the facts and their assessment 
2008, no. 1 (2008): 355–387.
of those facts. Audit trails should detail 
the rules applied in every mini-decision 
made by the system. Providers of A/IS,  •  Crawford, K., and J. Schultz. “Big Data 
or providers of solutions or services that  and Due Process: Toward a Framework to 
substantially incorporate such systems,  Address Predictive Privacy Harms.” Boston 
should make available statistically sound  College Law Review 55, no. 1 (2014): 
evaluation protocols through which they  93–128.
measure, quality assure, and substantiate 
their claims of performance, for example,  •  Pasquale, F. Black Box Society. Cambridge, 
relying where available on protocols and  MA: Harvard University Press, 2014. 
standards developed by the National Institute 
of Standards and Technology (NIST) or other 
standard-setting bodies.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 153The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
•  Bamberger, K. “Technologies of  •  Rainie, L., J. Andesrson, and J. Albright. “The 
Compliance: Risk and Regulation in the  Future of Free Speech, Trolls, Anonymity and 
Digital Age.” Texas Law Review 88, no. 4  Fake News Online.” Pew Research Center, 
(2010): 669–739. March 29, 2017. 
•  Kroll, J. Accountable Algorithms. Princeton,  •  Marwick, A., “Are There Limits to Online  
NJ: Princeton University Press, 2015. Free Speech?” Data & Society: Points, 
January 5, 2017. 
•  Desai, D., and J. A. Kroll. “Trust But Verify: A 
Guide to Algorithms and the Law.” Harvard  •  Neier, A., “Talking Trash: What’s More 
Journal of Law and Technology, forthcoming. Important, Human Dignity or Freedom of 
Speech?” Columbia Journalism Review, 
September/October 2012. 
•  ICRC. “Views of International Committee of 
Red Cross (ICRC) on Autonomous Weapon 
System.” April 11, 2016.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 154The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
Section 3 — Legal Accountability for 
Harm Caused by A/IS
As A/IS becomes more prevalent while also  1. Designers should consider adopting an identity 
potentially becoming more removed from the  tag standard — that is, no A/IS agent should 
human developer/manufacturer, what is the  be released without an identity tag to maintain 
correct approach to ensure legal accountability  a clear line of legal accountability.
for harms caused by A/IS?
2. Lawmakers and enforcers need to ensure that 
the implementation of A/IS is not abused 
by businesses and entities employing the A/
Issue: 
IS to avoid liability or payment of damages. 
How can A/IS be designed to  Governments should consider adopting 
guarantee legal accountability for  regulations requiring insurance or other 
guarantees of financial responsibility so that 
harms caused by these systems?
victims can recover damages for harm that A/
IS cause.
Background
3. Companies that use and manufacture A/
One of the fundamental assumptions most laws 
IS should be required to establish written 
and regulations rely on is that human beings are 
policies governing how the A/IS should be 
the ultimate decision-makers. As autonomous 
used, including the real-world applications 
devices and A/IS become more sophisticated and 
for such AI, any preconditions for its effective 
ubiquitous, that will increasingly be less true. The 
use, who is qualified to use it, what training 
A/IS industry legal counsel should work with legal 
is required for operators, how to measure the 
experts to identify the regulations and laws that 
performance of the A/IS, and what operators 
will not function properly when the “decision-
and other people can expect from the A/IS. 
maker” is a machine and not a person.
This will help to give the human operators 
and beneficiaries an accurate idea of what to 
Candidate Recommendations
expect from the A/IS, while also protecting 
Any or all of the following can be chosen. The  the companies that make the A/IS from future 
intent here is to provide as many options as  litigation. 
possible for a way forward for this principle.  
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 155The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
4. Because the person who activates the A/IS  responsible for installing post-harm fixes on 
will not always be the person who manages  their products designed to make the product 
or oversees the A/IS while it operates, states  safer. In other words, because courts have 
should avoid adopting universal rules that  recognized that it is good public policy to 
assign legal responsibility and liability to the  encourage companies to fix dangerous design 
person who “turns on” the A/IS. For example,  flaws, retroactively fixing a design flaw that has 
liability may attach to the manufacturers or to  caused injury is not considered an admission 
the person who directs, monitors, and controls  or a sign of culpability. The same approach 
the A/IS’s operations, or has the responsibility  should be used in A/IS litigation. 
to do so.
Further Resources
6. For the avoidance of repeated or future harm, 
companies that use and manufacture A/IS  •  Allan, T., and R. Widdison. “Can Computers 
should consider the importance of continued  Make Contracts?” Harvard Journal of Law 
algorithm maintenance. Maintenance is an  and Technology 9 (1996): 25–52.
essential aspect of design. Design does not 
•  Asaro, P. M. “The Liability Problem for 
end with deployment. Thus, there should  
Autonomous Artificial Agents.” Palo Alto, CA: 
be a clear legal requirement of (1) due 
Association for the Advancement of Artificial 
diligence, and (2) sufficient investment 
Intelligence, 2015. 
in algorithm maintenance on the part of 
companies that use and manufacture  
•  Chopra, S., and L. F. White. A Legal Theory 
A/IS that includes monitoring of outcomes, 
for Autonomous Artificial Agents. Ann Arbor, 
complaint mechanism, inspection, correction, 
MI: University of Michigan Press, 2011.
and replacement of harm-inducing algorithm, 
if warranted. Companies should be prohibited  •  Colonna, K, “Autonomous Cars and Tort 
from contractually delegating this responsibility  Liability.” Case Western Journal of Law, 
to unsophisticated end-users. Technology & The Internet 4 no. 4 (2012): 
81–130.
7. Promote international harmonization of 
national legislations related to liability in the  •  Field, C. “South Korean Robot Ethics Charter 
context of A/IS design and operation (through  2012.” PhD thesis (part), Sydney, Aus.: 
bi- or multilateral agreements) to enhance  University of Technology, 2010.
interoperability, and facilitate transnational 
•  Grossman, M. R., and G. V. Cormack. 
dispute resolution.
“Technology-Assisted Review in E-Discovery 
8. Courts weighing A/IS litigation cases based  Can Be More Effective and More Efficient 
on some form of injury should adopt a similar  Than Exhaustive Manual Review.” Richmond 
scheme to that of product liability litigation,  Journal of Law and Technology 17, no. 3 
wherein companies are not penalized or held  (2011): 1–48.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 156The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
•  Kalra, N., J. Anderson, and M. Wachs.  •  Wachter, S., B. Mittelstadt, and L. Floridi. 
“Liability and Regulation of Autonomous  “Transparent, Explainable, and Accountable 
Vehicle Technologies.” State of California  AI for Robotics.” Science Robotics 2, no. 6 
Department of Transportation Technical  (May 31, 2017).  DOI: 10.1126/scirobotics.
Report. Berkeley, CA: Institute of  aan6080.
Transportation Studies, University of 
•   Weaver, J. F.. Robots Are People Too: How 
California, 2009.　
Siri, Google Car, and Artificial Intelligence 
•  Krakow, C. E. A. “Liability for Distributed  Will Force Us to Change Our Laws. Santa 
Artificial Intelligences.” Berkeley Technology  Barbara, CA: Praeger, 2013.
Law Journal 11, no. 1 (1996): 147–204.
•  Weiss, A. “Validation of an Evaluation 
•  Rivard, M. D. “Toward a General Theory of  Framework for Human-Robot Interaction. 
Constitutional Personhood: A Theory of  The Impact of Usability, Social Acceptance, 
Constitutional Personhood for Transgenic  User Experience, and Societal Impact on 
Humanoid Species.” UCLA Law Review 39,  Collaboration with Humanoid Robots.” PhD 
no. 5 (1992): 1425–1510. thesis, University of Salzburg, 2010.
•  Scherer, M., “Regulating Artificial Intelligence  •  Wooldridge, M., and N. R. Jennings. 
Systems: Risks, Challenges, Competencies,  “Intelligent Agents: Theory and Practice.” 
and Strategies.” Harvard Journal of Law and  The Knowledge Engineering Review no. 2 
Technology 29, no. 2 (2016): 353–400. (1995): 115–152.
•  Tobin, R., and E. Schoeman. “The New 
Zealand Accident Compensation Scheme: 
The Statutory Bar and the Conflict of Laws.” 
The American Journal of Comparative Law 
53, no. 2 (2005): 493–514. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 157The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
Section 4 — Transparency, Accountability, 
and Verifiability in A/IS
Transparency around A/IS is a difficult issue  have the potential to be more fair, and less 
because it impinges on the differing needs of  biased than humans, provided that the systems 
developers for trade secrets and users to be  are designed well. This requires, in particular, that 
able to understand the technology to guard  effective preventative measures are put in place 
against problems occurring with it, and to hold  to avoid an algorithm-based information and/or 
accountable the correct entity in the event of a  value bias.
system failure.
At the same time, most users of A/IS will not 
be aware of the sources, scale, varying levels of 
accuracy, intended purposes, and significance of 
Issue: 
uncertainty in the operations of A/IS, or that they 
How can we improve the  are interacting with A/IS in the first place. The 
accountability and verifiability  sources of data used to perform these tasks are 
also often unclear. Furthermore, users might not 
in autonomous and intelligent 
foresee the inferences that can be made about 
systems?
them or the consequences when A/IS are used. 
The proliferation of A/IS will result in an increase 
in the number of systems that rely on machine 
Background learning and other developmental systems whose 
actions are not pre-programmed, and that may 
Decision-making algorithms can be designed 
not produce logs or a record of how the system 
for various purposes, and the applications 
reached its current state.
are wide-ranging for both the public and the 
private sectors. We must assume that virtually 
These systems are often opaque (frequently 
every decision that we make as humans can be 
referred to as “black boxes”) and create 
mediated or replaced by an algorithm. Therefore, 
difficulties for everyone, from the engineer,  
we cannot overestimate both the current and 
to the lawyer in court, to the online shopper, to 
future role of A/IS across different sectors. 
the social media user. The result is an abundance 
Algorithms and automated decision-making (e.g., 
of ethical issues of ultimate accountability.
resume/cv screening during job applications) 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 158The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
Candidate Recommendations 4.  A/IS should be programmed so that, under 
certain high risk situations where human 
1.  Given that many of the desired design 
decision-making is involved, they proactively 
specifications regarding accountability and 
inform users of uncertainty even when not 
verifiability are not technologically possible 
asked.
at this time, for now, this is an ethical issue 
that is best addressed by disclosure. If users  5.  With any significant potential risk of 
are aware that they are interacting with an A/ economic or physical harm, designers should 
IS in the first place, and know exactly what  conspicuously and adequately warn users 
information is being transferred to it, they  of the risk and provide a greater scope of 
will be better suited to tailor their inputs. A  proactive disclosure to the user. Designers 
government-approved labeling system like  should remain mindful that some risks 
the skull and crossbones found on household  cannot be adequately warned against and 
cleaning supplies that contain poisonous  should be avoided entirely.
compounds could be used for this purpose 
to improve the chances that users are aware  6.  To reduce the risk of A/IS that are 
when they are interacting with A/IS.  unreasonably dangerous or that violate the 
law from being marketed and produced, 
2.  Designers and manufacturers must remain  we recommend lawmakers provide 
accountable for the risks or externalities  whistleblower incentives and protections. As 
their systems cause. This is a balancing  in many industries, insiders may often be the 
act since the level of risk that is acceptably  first to know that the A/IS are acting illegally 
mitigated through disclosure is not always  or dangerously. A well-crafted law to protect 
clear. Recommending specific levels (whether  whistleblowers and allow a public interest 
a manufacturer of A/IS acts responsibly,  cause of action would improve accountability 
or whether there is enough disclosure, or  and aid in prevention of intentional, reckless, 
whether total disclosure would even be  or negligent misuses of A/IS.
enough to mitigate the risk to users) is often 
a fact-specific discussion that doesn’t suit  7.  Government and industry groups should 
itself well to broad rules. consider establishing standards that require 
A/IS to create logs (or other means of 
3.  There is a demand for algorithmic operation  verification of their decision-making process) 
transparency. Although it is acknowledged  regarding key aspects of their operations 
this cannot be done currently, A/IS should be  and store those logs for a specified period 
designed so that they always are able, when  of time. Designers should leverage current 
asked, to show the registered process which  computer science regarding accountability 
led to their actions to their human user, identify  and verifiability for code. New verification 
to the extent possible sources of uncertainty,  techniques may need to be developed 
and state any assumptions relied upon.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 159The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
to overcome the technical challenges in  new regulation where appropriate, including 
verifiability and auditability of A/IS operations;  rules subjecting the market launch of new 
A/IS oversight systems (“A/IS guardians”) or  A/IS driven technology to prior testing and 
methods such as Quantitative Input Influence  approval by appropriate national and/or 
(“QII”) measures could facilitate this process.  international agencies. Companies should 
Making sure, ex ante, that such information  establish an A/IS ethics statement that 
is, or can be made, available will also provide  includes statements about discrimination, 
a higher degree of trust in verifiability and a  addressing in that matter data-driven profiling 
sense of transparency in A/IS operations. and commitment to take measures to avoid 
user discrimination. In addition, companies 
8.  In Europe, the discussion on the so called 
should have internal systems that allow 
“right to explanation” when automated 
employees to identify and escalate issues 
decision-making occurs is important to 
related to discrimination in data and A/IS. 
address. Even though it is not yet guaranteed 
Laws should create whistleblower protection 
in Europe, future jurisprudence or Member 
for those who can and wish to reveal explicit 
State laws could grant individuals the right 
violation of discrimination law. In particular, 
to ask for an explanation when a solely 
a well-crafted law to protect whistleblowers 
automated decision (e.g., refusal of an 
and to allow a public interest cause of action 
online credit application or e-recruiting 
would improve accountability and aid in 
practices) is being made about them that 
prevention of intentional misuse of A/IS.
has legal or other significant effects. Such 
a right could provide a mechanism to 
10. The general public should be informed 
increase the transparency and accountability 
when articles/press releases related to 
of A/IS, and should therefore be seriously 
political figures or issues are posted by an 
considered. In addition, other accountability 
A/IS, such as a bot. 
enhancing tools such as ethical audits or 
certification schemes for algorithms should 
Further Resources
be explored. In addition, users should have 
the right to be informed, possibly through an  •  Barocas, S., and A. D. Selbst. “Big Data’s 
interactive training program, on the areas of  Disparate Impact.” California Law Review 104 
uncertainty, risks, and circumstances where  (2016): 671–732.
safety or harm issues could arise, without 
•  Datta, A., S. Sen, and Y. Zick. “Algorithmic 
this increasing user’s accountability for A/IS 
Transparency via Quantitative Input Influence: 
decision-making consequences.
Theory and Experiments with Learning 
9.  Lawmakers on national and international  Systems.” 2016 IEEE Symposium on Security 
levels should be encouraged to consider and  and Privacy, May 22–26, 2016. DOI: 
carefully review a potential need to introduce  10.1109/SP.2016.42
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 160The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Law
•  Etzioni, A., O. Etzioni. “Designing AI  •  Wachter, S., B. Mittelstadt, and L. Floridi. 
Systems That Obey Our Laws and Values.”  “Why a Right to Explanation of Automated 
Communications of the ACM 59, no. 9  Decision-Making Does Not Exist in the 
(2016): 29–31. General Data Protection Regulation.” 
International Data Privacy Law 7, no. 2 
•  Kroll, J. A., and J. Huey, S. Barocas, E. W. 
(2017): 76–99.
Felten, J. R. Reidenberg, D. G. Robinson, 
and H. Yu. “Accountable Algorithms.” (March  •  Zarsky, T. “The Trouble with Algorithmic 
2, 2016). University of Pennsylvania Law  Decisions: an Analytic Roadmap to Examine 
Review 165 (2017 Forthcoming); Fordham  Efficiency and Fairness in Automated 
Law Legal Studies Research Paper No.  and Opaque Decision Making.” Science, 
2765268.   Technology & Human Values 41, no. 1 
(2016): 118–132.
•  Mittelstadt, B., P. Allo, M. Taddeo, S. Wachter, 
and L. Floridi. “The Ethics of Algorithms: 
Mapping the Debate.” Big Data & Society 
(July–December, 2016): 1–21.
•  Regulation (EU) 2016/679 of the European 
Parliament and of the Council, General 
Data Protection Regulation (). “On the 
Protection of Natural Persons with Regard to 
the Processing of Personal Data and on the 
Free Movement of Such Data, and Repealing 
Directive 95/46/EC.” April 27, 2016.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 161The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Affect is a core aspect of intelligence. Drives and emotions, such as excitement and 
depression, are used to coordinate action throughout intelligent life, even in species that 
lack a nervous system. We are coming to realize that emotions are not an impediment  
to rationality, arguably they are integral to rationality in humans. Emotions are one evolved 
mechanism for satisficing — for getting what needs to be done in the time available with  
the information at hand. Emotions are core to how individuals and societies coordinate  
their actions. Humans are therefore susceptible to emotional influence both positively  
and negatively.
We would like to ensure that AI will be used to help humanity to the greatest extent 
possible in all contexts. In particular, artifacts used in society could cause harm either by 
amplifying or damping human emotional experience. It is quite possible we have reached  
a point where AI is affecting humans psychologically more than we realize. Further, even  
the rudimentary versions of synthetic emotions already in use have significant impact  
on how AI is perceived by policy makers and the general public.
This subcommittee addresses issues related to emotions and emotion-like control in both 
humans and artifacts. Our working groups have put forward candidate recommendations  
on a variety of concerns: considering how affect varies across human cultures, the particular  
problems of artifacts designed for intimate relations, considerations of how intelligent 
artifacts may be used for “nudging,” how systems can support (or at least not interfere with)  
human flourishing, and appropriate policy concerning artifacts designed with their own 
affective systems.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 162The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Document Sections
•  Systems Across Cultures
•  When Systems Become Intimate 
•  System Manipulation/Nudging/Deception
•  Systems Supporting Human Potential (Flourishing) 
•  Systems with Their Own Emotions
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 163The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Systems Across Cultures
1.  Affective systems should be careful in using 
small talk. Although small talk is useful  
Issue: 
for acting friendly, some communities  
Should affective systems   see people that use small talk as insincere 
interact using the norms  and hypocritical, while other cultures see 
the opposite and tend to consider people 
appropriate for verbal and 
that do not use small talk as unfriendly, 
nonverbal communication 
uncooperative, rude, arrogant, or ignorant. 
consistent with the societal 
Additionally speaking with proper vocabulary, 
norms where they are located? grammar, and sentence structure is often 
in contrast to the typical interactions that 
people have. In many mature economies, 
the latest trend, TV show, or other media 
Background
can significantly influence what is viewed as 
Societies and therefore individuals around 
appropriate vocabulary and interaction style.
the world have different ways to maintain eye 
contact, express intentions through gestures,  2.  Affective systems should recognize that  
interpret silence, etc. These particularities could  the amount of personal space (proxemics) 
be incorporated into the affective systems in  given is very important for human interaction. 
order to transmit the intended message. It would  People from different cultures have different 
seem that an extensive study surrounding the  comfort zone distances to establish smooth 
norms/values of the community where the  communication. Crossing these limits without 
affective system will be deployed is essential   permission can transmit negative messages, 
to the system acceptability.  such as hostile or sexual overtures.
3.  Eye contact is an essential component in 
Candidate Recommendations
social interaction for certain cultures, while 
Any successful affective system should have   for others, it is not essential and may even 
a minimum set of ethical values/norms   generate misunderstandings or conflicts. 
in its knowledge base that should be used   It is important to recognize this in the 
in a specific cultural context. Some examples   development of such systems.
are listed below:
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 164The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
4.  Hand gestures and other non-verbal  •  Elmer, D. Cross-Cultural Connections: 
interaction are very important for social  Stepping Out and Fitting In Around the 
interaction, but should be used with caution  World. Westmont, IL: InterVarsity Press,  
across cultures and should be acknowledged  2002.
in the design of affective systems. For instance,  
•  Price, M. “Facial Expressions—Including  
although a “thumbs-up” sign is commonly 
Fear—May Not Be as Universal as We 
used to indicate approval, in some countries 
Thought.” Science, October 17, 2016. 
this gesture can be considered an insult.
 
5.  Facial expressions are often used to 
detect emotions and facilitate emotional 
conversations. While it is tempting to 
Issue: 
develop A/IS that can recognize, analyze, 
and even display facial expressions for social  Long-term interaction with 
interaction, it should be noted that facial 
affective artifacts lacking  
expressions may not be universal across 
cultural sensitivity could  
cultures and that an AI system trained with  
alter the way people interact  
a dataset from one culture may not be  
readily usable in another culture. in society. 
Further Resources
Background
The following documents/organizations can  
be used as additional resources to support   Systems that do not have cultural knowledge 
the development of ethical affective systems. incorporated into their knowledge base may 
change the way people interact, which may 
•  Cotton, G. “Gestures to Avoid in Cross-
impact not only individuals, but also an entire 
Cultural Business: In Other Words, ‘Keep  
society. Humans often use mirroring in order 
Your Fingers to Yourself!’” Huffington Post, 
to understand and develop their principles and 
June 13, 2013.
norms for behavior. At the same time, certain 
•  “Cultural Intelligence & Paralanguage:   machine learning approaches focus on how 
Using Your Voice Differently Across Cultures.”  to more appropriately interact with humans 
Sydney, Aus.: Culture Plus Consulting, 2016. by mirroring human behavior. So learning via 
mirroring can go in both directions. If affective 
•  Cotton, G. Say Anything to Anyone,  artifacts without cultural sensitivity interact with 
Anywhere: 5 Keys To Successful Cross- impressionable humans, they could alter the 
Cultural Communication. Hoboken, NJ:   norms, principles, and therefore actions of that 
Wiley, 2013. person. This creates a situation where the impact 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 165The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
of interacting with machines could significantly  •  Bielby, J. “Comparative Philosophies in 
alter societal and cultural norms. For instance,  Intercultural Information Ethics.” Confluence: 
children interacting with these systems can learn  Online Journal of World Philosophies 2,  
social and cultural values, which may be different  no. 1 (2015): 233–253.
from those present in their local community. 
•  Bryson, J., “Why Robot Nannies Probably 
Won’t Do Much Psychological Damage.”  
Candidate Recommendations
A commentary on an article by N. Sharkey 
1.  It is necessary to survey and analyze the  and A. Sharkey, The Crying Shame of Robot 
long-term interaction of people with affective  Child Care Companions. Interaction Studies 
systems with different protocols and metrics  11, no. 2 (2010): 161–190.
to measure the modifications of habits, 
•  Sharkey, A., and N. Sharkey. “Children,  
norms, and principles as well as the cultural 
the Elderly, and Interactive Robots.” IEEE 
and societal impacts.
Robotics & Automation Magazine 18,  
2.  Responsible parties (e.g., parents,  no. 1 (2011): 32–38.
nurse practitioners, social workers, and 
governments) should be trained to detect  
the influence due to AI and in effective 
mitigation techniques. In the most extreme 
Issue: 
case it should always be possible to shut 
down harmful A/IS. When affective systems  
are inserted across cultures,  
Further Resources
they could affect negatively  
The following documents can be used as guides  the cultural/socio/religious 
to support the development of ethical affective 
values of the community  
systems.
where they are inserted.
•  Nishida, T., and C. Faucher. Modelling 
Machine Emotions for Realizing Intelligence: 
Foundations and Applications. Berlin, 
Background
Germany: Springer-Verlag, 2010.
Some philosophers believe there are no universal 
•  Pauleen, D. J. et al. “Cultural Bias in  ethical principles; instead they argue that ethical 
Information Systems Research and Practice:  norms vary from society to society. Regardless 
Are You Coming From the Same Place   of whether universalism or some form of ethical 
I Am?” Communications of the Association  relativism is true, affective systems need to 
for Information Systems 17 (2006): 1–36. respect the values of the cultures within which 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 166The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
they are embedded. To some it may be that we  an emotional response should be designed 
should be designing affective systems which  to be easily changed. Similar to how  
can reflect the values of those with which the  software today externalizes the language  
systems are interacting. There is a high likelihood  and vocabulary to be easily changed based 
that when spanning different groups, the values  on location, affective systems should 
imbued by the developer will be different from  externalize some of the core aspects of  
the operator or customer of that affective system.  their actions. 
Differences between affective systems and 
societal values can generate conflict situations  Further Resources
(e.g., gestures being misunderstood, or prolonged 
The following documents/organizations can  
or inadequate eye contact) that may produce 
be used as guides to support the development  
undesirable results, perhaps even physical violence.  
of ethical affective systems.
Thus, affective systems should adapt to reflect 
the values of the community (and individuals) 
•  Bielby, J. “Comparative Philosophies in 
where they will operate in order to avoid conflict. 
Intercultural Information Ethics.” Confluence: 
Online Journal of World Philosophies 2,  
Candidate Recommendation no. 1 (2015): 233–253.
Assuming the affective systems have a minimum 
•  Velasquez, M., C. Andre, T. Shanks, and  
subset of configurable ethical values incorporated 
M. J. Meyer. “Ethical Relativism.”Markkula 
in their knowledge base:
Center for Applied Ethics, Santa Clara, CA: 
Santa Clara University, August 1, 1992. 
1.  They should have capabilities to identify 
differences between their values and the 
•  Culture reflects the moral values and  
values of those they are interacting with and  
ethical norms governing how people should 
alter their interactions accordingly. As societal 
behave and interact with others. “Ethics,  
values change over time, any affective system  
an Overview.” Boundless Management. 
needs to have the capability to detect this 
evolution and adapt its current ethical values  •  Donaldson, T. “Values in Tension: Ethics 
to be in accordance with other people’s values. Away from Home.” Harvard Business Review. 
September–October 1996. 
2.  Those actions undertaken by an affective 
system that are most likely to generate   •  The Center for Nonviolent Communication. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 167The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
When Systems Become Intimate
Candidate Recommendation
Issue:  As this technology develops, it is important to 
monitor research in this realm and support those 
Are moral and ethical  
projects that enhance the user’s development  
boundaries crossed when the 
of intimate relationships in positive and therapeutic  
design of affective systems  ways while critiquing those that contribute  
allows them to develop intimate  to problematic intimate relations, specifically:
relationships with their users?
1.  Intimate systems must not be designed  
or deployed in ways that contribute to 
sexism, negative body image stereotypes, 
Background gender or racial inequality. 
While robots capable of participating in an  2.  Intimate systems must avoid the sexual/
intimate relationship are not currently available,  psychological manipulation of the users  
the idea that they could become intimate sexual  of these systems unless the user is made 
partners with humans (e.g., sex robots) is one  aware they are being manipulated in this  
that captures the attention of the public and  way (opt-in).
the media. Because the technology is already 
drawing much ethical scrutiny and may raise  3.  Intimate systems should not be designed  
significant ethical concerns, it is important that  in a way that contributes to user isolation 
policy makers and the professional community  from other human companions.
participate in developing guidelines for ethical 
4.  Designers of affective robotics, especially 
research in this area. Part of the goal is to 
intimate systems, must foresee and publicly 
highlight potential ethical benefits and risks  
acknowledge that these systems can interfere 
that may emerge, if and when affective systems 
with the relationship dynamics between 
develop intimacy with their users. Robots for 
human partners, causing jealousy or feelings 
use in the sex industry may help lessen human 
of disgust to emerge between human 
trafficking and the spread of STIs, but there  
partners. 
is also the possibility that these systems could 
negatively impact human-to-human intimate  5.  Intimate systems must not foster deviant  
relations. Human-to-human relations are currently  or criminal behavior. Sex robots should not 
viewed as being more rewarding, but also much  be built in ways that lead to the normalization 
more difficult to maintain than, for example,   of taboo, unethical, or illegal sexual practices, 
use of future robotic sex workers. such as pedophilia or rape. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 168The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
6.  Commercially marketed AI should not be  •  Campaign against Sex Robots. 
considered to be a person in a legal sense,  
•  Whitby, B. “Do You Want a Robot Lover? 
nor marketed as a person. Rather its artifactual  
The Ethics of Caring Technologies,” in Robot 
(authored, designed, and built deliberately) 
Ethics: The Ethical and Social Implications  
nature should always be made as transparent 
of Robotics, edited by P. Lin, K. Abney,  
as possible, at least at point of sale and  
and G. A. Bekey, 233–248. Cambridge,  
in available documentation (as noted  
MA: MIT Press, 2012.
in the Systems Supporting Human Potential 
Section below).
•  Danaher, J., and N. McArthur. Robot Sex: 
Sexual and Ethical Implications. Cambridge, 
Further Resources MA: MIT Press, 2017.
The following documents/organizations are 
provided for further research.
•  Levy, D. Love and Sex with Robots: The 
Issue: 
Evolution of Human-Robot Relationships. 
New York: HarperCollins Publishers, 2007 Can and should a ban  
or strict regulations be placed  
•  Scheutz, M. “The Inherent Dangers of 
Unidirectional Emotional Bonds Between  on the development of sex 
Humans and Social Robots,” in Robot   robots for private use or in  
Ethics: The Ethical and Social Implications  
the sex industry?
of Robotics, edited by P. Lin, K. Abney,  
and G. Bekey,  205. Cambridge, MA: MIT 
Press, 2011.
Background
•  Richardson, K. “The Asymmetrical 
The very idea of sex robots has sparked 
‘Relationship’: Parallels Between Prostitution 
controversy even before many of these systems 
and the Development of Sex Robots.”  
have become available. At this time, sex robots 
ACM SIGCAS Newsletter, SIGCAS Computers 
tend to be expensive love dolls made of silicone 
& Society 45, no. 3 (2015): 290–293.
placed over a metal skeleton. These dolls 
•  Sullins, J. P. “Robots, Love, and Sex:   can include robotic systems such as heating 
The Ethics of Building a Love Machine.”   elements, sensors, movement, and rudimentary 
IEEE Transactions on Affective Computing 3,  AI. The current state of the technology is a far cry 
no. 4 (2012): 398–409. from the sex robots imagined in novels and other 
media but they may just be the first step toward 
•  Yeoman, I., and M. Mars. “Article Robots,   more advanced systems. There is ongoing debate 
Men and Sex Tourism.” Futures 44, no. 4  around these systems. Critics are calling for strict 
(2012): 365–371.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 169The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
regulation or even a full ban on the development  means a further tendency to objectify women,  
of this technology, while others argue that social  given that the majority of clients for these 
value could be found by developing intimate  technologies are heterosexual men.
robots, including on religious grounds.
2.  The availability of the technology could 
Sex robots are already used for prostitution   disrupt intimate relationships between 
and this trend is likely to continue in many  human beings.
regions of the world. Some researchers report 
Human sexuality is an important human 
that robot prostitutes will completely revolutionize 
activity, but it comes associated with difficult 
the sex tourism industry by 2050. For example, 
ethical issues related to power and desire. 
by that time, Amsterdam’s Red Light District 
This means that robot sexual partners will 
may be dominated by a variety of android 
always be an ethically contentious technology. 
systems with various capabilities (Yeoman and 
A comprehensive/global ban on sex robots 
Mars, 2012). However there are critics of the 
is unlikely given that a large market for these 
technology, including those who are calling  
technologies may already exist and is part 
for an outright ban.
of the current demand for sex toys and 
Despite being illegal, prostitution commonly  devices. However, there are important issues/
occurs in many societies. Yet it is rarely done  considerations that the designers of these 
without creating deep ethical problems for   technologies need to consider.
the sex workers themselves and the societies 
in which they operate. Sex robots may alleviate  Candidate Recommendation
some of these ethical concerns; for instance  
1.  We recommend regulation, not a ban,  
it has been argued that: 
in accordance with cultural norms.
1.  Sex robots might be less likely to be a vector 
2.  Existing laws regarding personal imagery 
for the transmission of sexually transmitted 
need to be reconsidered in light of  
infections (STIs).
robot sexuality.
2.  Sex robots could greatly lessen human 
3.  If it is proven through scientific studies that 
trafficking of sex workers.
therapeutic uses of this technology could 
3.  Sex robots could be regulated by policies on  reduce recidivism in those who commit sex 
controlling prices, hours of operations, sexual  crimes, controlled use for those purposes 
services, and other aspects of prostitution. only should be permitted, under legal and/
or medical supervision.
However the technology can create serious 
ethical problems such as: 4.  Robot prostitution and sex tourism need  
to be monitored and controlled to fit local 
1.  This technology would likely further 
laws and policies. 
normalize the sex industry, and that typically 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 170The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Further Resources •  Sullins, J. P. “Robots, Love, and Sex: The Ethics  
of Building a Love Machine.” IEEE Transactions  
•  Danaher, J., and N. McArthur. Robot Sex: 
on Affective Computing 3, no. 4 (2012): 
Sexual and Ethical Implications. Cambridge, 
398–409.
MA: MIT Press, 2017.
•  Yeoman, I., and M. Mars. “Robots, Men  
•  Richardson, K. “The Asymmetrical 
and Sex Tourism.” Futures 44, no. 4 (2012): 
‘Relationship’: Parallels Between Prostitution 
365–371.
and the Development of Sex Robots.”  
ACM SIGCAS Newsletter, SIGCAS Computers  •  Campaign against Sex Robots. 
& Society 45, no. 3 (2015): 290–293.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 171The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
System Manipulation/Nudging/Deception 
de Quintana Medina and Hermida Justo, 2016). 
Another key, and potentially more controversial, 
Issue: 
issue to be addressed is whether an affective 
Should affective systems   system should be designed to nudge a user,  
be designed to nudge people   and potentially intrude on individual liberty,  
when doing so may benefit someone else. 
for the user’s personal  
benefit and/or for the  
Candidate Recommendations
benefit of someone else? 
1.  Systematic analyzes are needed that examine 
the ethics of designing affective systems  
to nudge human beings prior to deployment.
Background
Emotional manipulation can be defined   2.  We recommend that the user be able to 
as an exercise of influence, with the intention   recognize and distinguish between different 
to seize control and power at the person’s  types of nudges, including ones that seek  
expense. Thaler and Sunstein (2008) call the  to promote beneficial social manipulation 
tactic of subtly modifying behavior a “nudge.”  (e.g., healthy eating) versus others where  
Nudging mainly operates through the affective  the aim is psychological manipulation or  
system. Making use of a nudge might be  the exploitation of an imbalance of power 
considered appropriate in situations like teaching  (e.g., for commercial purposes).
children, treating drug dependency, healthcare, 
3.  Since nudging alters behavior implicitly,  
and when the global community benefits surpass 
the resulting data on infantilization effects 
individual benefits. Yet should affective systems 
should be collected and analyzed.
be deployed to influence a user’s behavior for 
that person’s own good? Nudging can certainly  4.  Nudging in autonomous agents and robots 
trigger behaviors that worsen human health,   must have an opt-in system policy with 
but could the tactic be used by affective   explicit consent.
systems to cue behaviors that improve it? Several 
5.  Additional protections must be put in place 
applications are possible in health, well-being, 
for vulnerable populations, such as children, 
education, etc. Yet a nudge could have opposite 
when informed consent cannot be obtained, 
consequences on different people, with different 
or when it may not be a sufficient safeguard.
backgrounds and preferences (White, 2013,  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 172The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
6.  Nudging systems must be transparent and  “Ethics in Robotics Research: CERNA 
accountable, implying that data logging   Recommendations,” IEEE Robotics and 
is required. This should include recording   Automation Magazine 24, no. 3 (2017): 
the user responses when feasible. 139–145. 
•  “Designing Moral Technologies: Theoretical, 
Further Resources
Practical, and Ethical Issues” Conference  
The following documents/organizations can   July 10–15, 2016, Monte Verità, Switzerland.
be used as additional resources to support  
the development of ethical affective systems.
•  Thaler, R., and C. R. Sunstein. Nudge: 
Improving Decision about Health, Wealth 
Issue: 
and Happiness, New Haven, CT: Yale 
University Press, 2008. Governmental entities often  
use nudging strategies,  
•  Bovens, L. “The Ethics of Nudge,” in 
for example to promote the 
Preference change: Approaches from 
Philosophy, Economics and Psychology,  performance of charitable acts. 
edited by T. Grüne-Yanoff and S. O. Hansson,  But the practice of nudging for 
207–219. Berlin, Germany: Springer. 
the benefit of society, including 
•  de Quintana Medina, J., and P. Hermida Justo.  through the use of affective 
“Not All Nudges Are Automatic: Freedom   systems, raises a range  
of Choice and Informative Nudges.”  
of ethical concerns.
Working paper presented to the European 
Consortium for Political Research, Joint 
Session of Workshops, 2016 Behavioral 
Background
Change and Public Policy, Pisa, Italy, 2016.
A profoundly controversial practice that could 
•  White, M. D. The Manipulation of Choice. 
be on the horizon is allowing a robot or another 
Ethics and Libertarian Paternalism.  
affective system to nudge a user for the good 
New York: Palgrave Macmillan, 2013.
of society (Borenstein and Arkin, 2016). For 
•  Scheutz, M. “The Affect Dilemma for Artificial  instance, if it is possible that a well-designed 
Agents: Should We Develop Affective Artificial  robot could effectively encourage humans  
Agents?” IEEE Transactions on Affective  to perform charitable acts, would it be ethically 
Computing 3, no. 4 (2012): 424–433.  appropriate for the robot to do so? This design 
possibility illustrates just one behavioral outcome 
•  Grinbaum, A., R. Chatila, L. Devillers,   that a robot could potentially elicit from a user.  
J.-G. Ganascia, C. Tessier, and M. Dauchet.   
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 173The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Given the persuasive power that an affective 
system may have over a user, ethical concerns 
Issue: 
related to nudging must be examined. This 
includes the significant potential for misuse. A nudging system that does  
not fully understand the  
Candidate Recommendations context in which it is operating 
As more and more computing devices subtly and   may lead to unintended 
overtly influence human behavior, it is important  consequences.
to draw attention to whether it is ethically 
appropriate to pursue this type of design pathway.  
There needs to be transparency regarding who 
Background
the intended beneficiaries are, and whether  
any form of deception or manipulation is going   This kind of system needs to have sophisticated 
to be used to accomplish the intended goal.  enough technical capabilities for recognizing  
the context in which it is applying nudging 
strategies. We could imagine a technical license 
Further Resources
(“permits”) (Omohundro, 2013).
The following documents/organizations can  
be used as guides to support the development  
Candidate Recommendation
of ethical affective systems.
1.  When addressing whether affective systems 
•  Borenstein, J., and R. Arkin. “Robotic Nudges: 
should be permitted to nudge human 
The Ethics of Engineering a More Socially 
beings, user autonomy is a key and essential 
Just Human Being.” Science and Engineering 
consideration that must be taken into 
Ethics 22, no. 1 (2016): 31–46.
account.
•  Borenstein, J., and R. C. Arkin. “Nudging 
2.  We recommend that when appropriate, 
for Good: Robots and the Ethical 
an affective system that nudges human 
Appropriateness of Nurturing Empathy  
beings should have the ability to accurately 
and Charitable Behavior.” AI and Society 32,  
distinguish between users, including 
no. 4 (2016): 499–507. 
detecting characteristics such as whether  
 
the user is an adult or a child.
 
  3.  Affective systems with nudging strategies 
should be carefully evaluated, monitored,  
and controlled.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 174The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Further Resources happiness. Given the diversity of views on the 
ethical appropriateness of deception, how should 
The following documents/organizations can  
affective systems be designed to behave? 
be used as guides to support the development  
of ethical affective systems.
Candidate Recommendations
•  Borenstein, J., and R. Arkin. “Robotic Nudges: 
It is necessary to develop recommendations 
The Ethics of Engineering a More Socially 
regarding the acceptability of deception in the 
Just Human Being.” Science and Engineering 
design of affective autonomous agents with 
Ethics 22, no. 1 (2016): 31–46.
respect to when and under which circumstances, 
•  Arkin, R. C., M. Fujita, T. Takagi, and R.  if any, it is appropriate.
Hasegawa. “An Ethological and Emotional 
1.  In general, deception is acceptable in an 
Basis for Human-Robot Interaction.” Robotics 
affective agent when it is used for the benefit 
and Autonomous Systems 42, no. 3–4 
of the person being deceived, not for the 
(2003): 191–201.
agent itself. For example, deception might  
•  Omohundro, S. “Autonomous Technology  be necessary in search and rescue operations,  
and the Greater Human Good.” Journal  elder- or child-care.
of Experimental and Theoretical Artificial 
2.  For deception to be used under any 
Intelligence 26, no. 3 (2014): 303–315.
circumstance, a logical and reasonable 
justification must be provided by the designer,  
and this rationale must be approved by  
an external authority.
Issue:  3.  Deception must follow an opt-in strategy 
and must be transparent to the user, i.e., the 
When, if ever, and under  
context under which the system is allowed  
which circumstances  
to deceive.
is deception performed by 
affective systems acceptable?  Further Resources
•  Arkin, R. C., “Robots That Need to Mislead: 
Biologically-inspired Machine Deception.” 
Background IEEE Intelligent Systems 27, no. 6 (2012): 
Deception is commonplace in everyday human- 60–75.
human interaction. According to Kantian ethics, 
•  Shim, J., and R. C. Arkin. “Other-Oriented 
it is never ethically appropriate to lie, while 
Robot Deception: How Can a Robot’s 
utilitarian frameworks would indicate that  
Deceptive Feedback Help Humans in HRI?”  
it can be acceptable when it increases overall 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 175The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Eighth International Conference on Social  Safety, Security, and Rescue Robotics (SSRR 
Robotics (ICSR 2016), Kansas, Mo.,  2015), West Lafayette, IN, October 2015.
November 2016.
•  Shim, J., and R. C. Arkin. “A Taxonomy of 
•  Shim, J., and R. C. Arkin. “The Benefits   Robot Deception and its Benefits in HRI.” 
of Robot Deception in Search and Rescue:  Proceedings of IEEE Systems, Man and 
Computational Approach for Deceptive  Cybernetics Conference, Manchester England, 
Action Selection via Case-based Reasoning.”  October 2013.
2015 IEEE International Symposium on 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 176The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Systems Supporting Human Potential  
(Flourishing)
Candidate Recommendations
Issue:  1.  It is important that human workers within 
an organization have direct interactions 
Extensive use of artificial 
with each other, rather than always being 
intelligence in society may make 
intermediated by affective systems (or other 
our organizations more brittle  technology) which may filter out useful, 
by reducing human autonomy  unexpected communication. Similarly, 
we recommend human points of contact 
within organizations, and  
be available to customers and other 
by replacing creative, affective, 
organizations.
empathetic components  
2.  In particular, although there will be many 
of management chains.
cases where AI is less expensive, more 
predictable, and easier to control than human 
employees, we recommend maintaining 
Background
a core number of human employees at 
As human workers are replaced by AI, their  every level of decision-making with clear 
former employers (e.g., corporations and  communication pathways. 
governments) may find they have eliminated 
3.  More generally, management and 
the possibility of employees and customers 
organizational theory should be extended 
discovering new equilibria outside the scope 
to consider appropriate use of affective 
of what the organizations’ leadership originally 
and autonomous systems to enhance their 
foresaw. Even in ordinary, everyday work, a lack 
business model and the efficacy of their 
of empathy based on shared needs and abilities 
workforce.
disadvantages not only the liberty of individuals 
but also the corporations and governments that 
Further Resource
exist to serve them, by eliminating opportunities 
for useful innovation. Collaboration requires  The following document can be used as an 
sufficient commonality of collaborating  additional resource to support the development 
intelligences to create empathy — the capacity   of ethical affective systems.
to model the other’s goals based on one’s own. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 177The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
•  Bryson, J. J. “Artificial Intelligence and   3.  Utilization of “customers” to perform  
Pro-Social Behavior,” in Collective Agency  basic corporate business processes such 
and Cooperation in Natural and Artificial  as data entry as a barter for lower prices, 
Systems, edited by Catrine Misselhorn,  resulting also in reduced tax revenues. 
281–306, Springer, 2015.
The loss of individual autonomy could lead 
to more fragmented or fragile societies, and 
(because diversity is associated with creativity)  
a reduction of innovation. This concern relates  
Issue:  to issues of privacy and security, but also  
to social and legal liability for past expressions. 
The increased access to  
personal information about  
Candidate Recommendations
other members of our society, 
1.  Organizations, including governments, must 
facilitated by artificial intelligence, 
put a high value on individuals’ privacy and 
may alter the human affective 
autonomy, including restricting the amount 
experience fundamentally,  and age of data held on individuals.
potentially leading to a  
2.  Educational countermeasures should be 
severe and possibly rapid  
taken to encourage individuation and prevent 
loss in individual autonomy. loss of autonomy.
Further Resources
Background
The following documents can be used as 
Theoretical biology tells us that we should expect  additional resources to support the development 
increased communication — which AI facilitates  of ethical affective systems.
— to increase group-level investment. This could 
•  Bryson, J. J. “Artificial Intelligence and  
have the effect of reducing individual autonomy 
Pro-Social Behavior,” in Collective Agency 
and increasing in its place group-based identities. 
and Cooperation in Natural and Artificial 
Candidate examples of this sort of social 
Systems, edited by Catrine Misselhorn, 
alteration include:
281–306, Springer, 2015.
1.  Increased investment in monitoring and 
•  Cooke, M.. “A Space of One’s Own: 
controlling children’s lives by parents. 
Autonomy, Privacy, Liberty.” Philosophy & 
2.  Decreased willingness to express opinions for  Social Criticism, 25, no. 1, (1999): 22–53. 
fear of surveillance or long-term unexpected   
consequences.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 178The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
•  Roughgarden, J., M. Oishi, and E. Akçay.  Candidate Recommendations
“Reproductive Social Behavior: Cooperative 
We recommend vigilance and research for 
Games to Replace Sexual Selection.”  
identifying situations where A/IS are already 
Science 311, no. 5763 (2006): 965–969.
affecting human well-being, both positively and 
negatively. We should look for evidence such as 
correlations between the increased use of A/IS 
and any suspected impacts. However, we should 
Issue:  not be paranoid nor assume that correlation 
indicates causation. We recommend robust, 
A/IS may negatively affect 
ongoing, multidisciplinary research.
human psychological and 
emotional well-being in   Further Resource
ways not otherwise foreseen. 
The following document can be used as an 
additional resource to support the development 
of ethical affective systems.
Background
•  Kamewari, K., M. Kato, T. Kanda, H. Ishiguro, 
A/IS has unprecedented access to human  and K. Hiraki. “Six-and-a-Half-Month-Old 
culture and human spaces — both physical and  Children Positively Attribute Goals to Human 
intellectual — for something that is not a human.  Action and to Humanoid-Robot Motion.” 
A/IS may communicate via natural language,  Cognitive Development 20, no. 2, (2005): 
it may move in humanlike forms, and express  303–320.
humanlike identity. As such, it may affect  
human well-being in ways not yet anticipated. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 179The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
Systems With Their Own Emotions
Candidate Recommendations
Issue:  1.  Commercially marketed AI should not  
be considered to be a person in a legal 
Synthetic emotions may  
sense, nor marketed as a person. Rather  
increase accessibility of AI,  
its artifactual (authored, designed, and built 
but may deceive humans   deliberately) nature should always be made 
into false identification with   as transparent as possible, at least at point  
of sale and in available documentation. 
AI, leading to overinvestment  
of time, money, trust, and   2.  Some systems will, due to their application, 
human emotion.  require opaqueness in some contexts  
(e.g., emotional therapy). Transparency  
in such instances should not be necessarily 
during operation, but the systems’ working 
Background
should still be available to inspection  
Deliberately constructed emotions are designed  by responsible parties.
to create empathy between humans and artifacts,  
which may be useful or even essential for 
Further Resources
human-AI collaboration. However, this could  
The following documents can be used as 
lead humans to falsely identify with the A/IS,  
additional resources to support the development 
and therefore fail to realize that — unlike in 
of ethical affective systems.
evolved intelligence — synthetic emotions can  
be compartmentalized and even entirely removed.  
•  Arkin, R. C., P. Ulam, and A. R. Wagner.  
Potential consequences are over-bonding,  
“Moral Decision-making in Autonomous 
guilt, and above all, misplaced trust. Because 
Systems: Enforcement, Moral Emotions, 
there is no coherent sense in which designed 
Dignity, Trust and Deception,” Proceedings  
and engineered AI can be made to suffer, because  
of the IEEE 100, no. 3 (2012): 571–589.
any such affect, even if possible, could be avoided  
at the stage of engineering, or reengineered.  •  Arkin, R., M. Fujita, T. Takagi, and R. Hasegawa.  
Consequently, AI cannot be allocated moral  “An Ethological and Emotional Basis for 
agency or responsibility in the senses that have  Human-Robot Interaction,” Robotics and 
been developed for human sociality.  Autonomous Systems 42, no. 3–4 (2003): 
191–201.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 180The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Affective Computing
•  Arkin, R. C.. “Moving Up the Food Chain:  •  Novikova, J., and L. Watts. “Towards Artificial 
Motivation and Emotion in Behavior-based  Emotions to Assist Social Coordination in 
Robots,” in Who Needs Emotions: The Brain  HRI.” International Journal of Social Robotics 
Meets the Robot, edited by J. Fellous and  7 no. 1, (2015): 77–88.
M. Arbib. New York: Oxford University Press, 
•  Scheutz, M. “The Affect Dilemma for Artificial 
2005.
Agents: Should We Develop Affective Artificial 
•  Boden, M., J. Bryson, D. Caldwell, K. et al.  Agents?” IEEE Transactions on Affective 
“Principles of Robotics: Regulating Robots   Computing 3 (2012): 424–433.
in the Real World.” Connection Science 29, 
•  Sharkey, A., and N. Sharkey. “Children, the 
no. 2 (2017): 124–129.
Elderly, and Interactive Robots.” IEEE Robotics 
•  Bryson, J. J., M. E. Diamantis, and T. D. Grant.  & Automation Magazine 18.1 (2011): 32–38. 
“Of, For, and By the People: The Legal Lacuna 
of Synthetic Persons.” Artificial Intelligence  
& Law 25, no. 3 (2017): 273–291.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 181The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
Autonomous and intelligent systems (A/IS) are a part of our society. The use of these  
new, powerful technologies promotes a range of social goods, and may spur development 
across the economies and society through its numerous applications, including in commerce, 
employment, healthcare, transportation, politics, privacy, public safety, national security, civil 
liberties, and human rights. To protect the public from adverse consequences, intended  
or otherwise, resulting from these applications, effective A/IS public policies and government  
regulations are needed.
The goals of an effective A/IS policy center on the protection and promotion of safety, 
privacy, intellectual property rights, human rights, and cybersecurity, as well as the public 
understanding of the potential impact of A/IS on society. Without policies designed with 
these considerations in mind, there may be critical technology failures, loss of life, and  
high-profile social controversies. Such events could engender policies that unnecessarily 
stifle entire industries, or regulations that do not effectively advance public interest  
and protect human rights. 
To ensure that A/IS best serves the public interest, we believe that effective A/IS policies 
should embody a rights-based approach1 that achieves five principal objectives:
1.  Support, promote, and enable internationally recognized legal norms
2.  Develop workforce expertise in A/IS technology
3.  Include ethics as a core competency in research and development leadership
4.  Regulate A/IS to ensure public safety and responsibility
5.  Educate the public on societal impacts of A/IS
 
1 This approach is rooted in internationally recognized economic, social, cultural, and political rights.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 182The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
As autonomous and intelligent systems (A/IS) become a greater part of our everyday lives, 
managing the associated risks and rewards will become increasingly important. Technology 
leaders and policy makers have much to contribute to the debate on how to build trust, 
prevent drastic failures, and integrate ethical and legal considerations into the design  
of A/IS technologies.
Disclaimer: While we have provided recommendations in this document, it should be understood these are not formal policy 
recommendations endorsed by IEEE and do not represent a position or the views of IEEE but the informed opinions of Policy 
Committee members providing insights designed to provide expert directional guidance regarding A/IS. In no event shall IEEE 
or IEEE-SA Industry Connections Activity Members be liable for any errors or omissions, direct or otherwise, however caused, 
arising in any way out of the use of this work, regardless of whether such damage was foreseeable.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 183The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
internationally recognized political, social, 
economic, and cultural rights. For business actors, 
Objective: 
this means considering their obligation to respect 
Ensure that A/IS support,  international human rights, as laid out in the  
promote, and enable  UN Guiding Principles for Business and Human 
Rights (OHCHR, 2011), also known as the  
internationally recognized  
Ruggie principles.
legal norms.
When discussing the responsibility of private 
actors, the UN Guiding Principles on Business 
and Human Rights should be reflected. These 
Background
principles have been widely referenced and 
A/IS technologies have the potential to negatively 
endorsed by corporations and led to the adoption 
impact internationally recognized economic, 
of several corporate social responsibility (CSR) 
social, cultural, and political rights, through 
policies in various companies. As such,  
unintended outcomes or outright design 
they have led to a better understanding of the 
decisions (as is the case with certain unmanned 
role of businesses in protection and promotion  
aircraft systems (Bowcott, 2013). In addition  
of human rights and ensured that the most 
to the military application of A/IS, the domestic 
crucial human values and legal standards of 
use of A/IS in predictive policing (Shapiro, 2017), 
human rights are respected by A/IS technologists.
banking (Garcia, 2017), judicial sentencing 
(Osoba and Welser, 2017), job hunting and hiring 
Candidate Recommendations
practices (Datta, Tschantz, and Datta, 2014), 
and even service delivery of goods (Ingold and  A rights-based approach means using the 
Soper, 2016) can negatively impact human rights  internationally recognized legal framework  
by automating certain forms of discrimination,  for human rights standards that is directed  
inhibiting the right to assembly, freedom of  at accounting for the impact of technology 
expression, and access to information. To ensure  on individuals. This framework also addresses 
A/IS are used as a force for good, it is crucial   inequalities, discriminatory practices, and the 
to formulate policies that prevent such violations  unjust distribution of resources. A/IS right-based 
of political, social, economic, and cultural rights. policies will reflect the following principles:
A/IS regulation, development, and deployment  •  Responsibility: The rights-based approach 
should, therefore, be based on international  shall identify the right holders and the duty 
human rights standards and standards of  bearers, and ensure that duty bearers have 
international humanitarian laws (in the case  an obligation to realize all human rights;  
of armed conflicts). This can be achieved if  this should guide the policy development 
both states and private actors consider their  and implementation of A/IS.
responsibility to respectively protect and respect 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 184The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
•  Accountability: As duty bearers, states should  Further Resources
be obliged to behave responsibly, seek to 
•  Human rights-based approaches have 
represent the greater public interest, and be 
been applied to development, education 
open to public scrutiny of their A/IS policy.
and reproductive health. See: the UN 
•  Participation: the rights-based approach  Practitioners’ Portal on Human Rights Based 
demands a high degree of participation   Programming. 
of all interested parties.
•  Bowcott, O. “Drone Strikes By Us May Violate 
•  Non-discrimination: Principles of non- International Law, Says UN.” The Guardian, 
discrimination, equality, and inclusiveness  October 18, 2013. 
should underlie the practice of A/IS.  
•  Shapiro, A.“Reform Predictive Policing.” 
The rights-based approach should also 
Nature News 541, no. 7638 (2017): 458. 
ensure that particular focus is given to 
vulnerable groups, to be determined locally,  •  Garcia, M. “How to Keep Your AI from Turning 
such as minorities, indigenous peoples,   Into a Racist Monster.” Wired, April 21, 2017.
or persons with disabilities.
•  Osoba, O. A., and W. Welser. “An Intelligence 
•  Empowerment: The rights-based approach   in Our Image: The Risks of Bias and Errors 
to A/IS should empower right holders to  in Artificial Intelligence.” Santa Monica, CA: 
claim and exercise their rights. RAND Corporation, 2017.
•  Corporate responsibility: Companies must  •  Datta, A., M. C. Tschantz, and A. Datta. 
ensure that when they are developing their  “Automated Experiments on Ad Privacy 
technologies based on the values of a certain  Settings: A Tale of Opacity, Choice, and 
community, they do so only to the extent   Discrimination.” arXiv:1408.6491 [Cs], 2014. 
that such norms or values fully comply with 
•  Ingold, D., and S. Soper. “Amazon Doesn’t 
the rights-based approach. Companies must 
Consider the Race of Its Customers. Should It?”  
also not willingly provide A/IS technologies  
Bloomberg, April 21, 2016.
to actors that will use them in ways that  
lead to human rights violations. 
•  United Nations. Guiding Principles on 
 
Business and Human Rights: Implementing 
 
the United Nations “Protect, Respect and 
 
Remedy” Framework. United Nations Office 
of the High Commissioner of Human Rights. 
New York and Geneva: UN, 2011. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 185The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
Candidate Recommendations
Objective:  A high level of technical expertise is required 
to create a public policy, legal, and regulatory 
Develop and make available  
environment that allows innovation to flourish 
to government, industry,  
while protecting the public and gaining public 
and academia a workforce   trust.1 Policy makers and market leaders  
of well-qualified A/IS personnel. should pursue several strategies for developing 
this expertise:
•  Expertise can be furthered by setting up 
Background technical fellowships, or rotation schemes, 
There is a clear consensus among private sector  where technologists spend an extended time 
and academic stakeholders that effectively  in political offices, or policy makers work with 
governing A/IS and related technologies requires  organizations that operate at the intersection 
a level of technical expertise that governments  of tech-policy, technical engineering, and 
currently do not possess. Effective governance  advocacy (like the American Civil Liberties 
requires more experts who understand and  Union, Article 19, the Center for Democracy 
can analyze the interactions between A/IS  and Technology, or Privacy International). 
technologies, programmatic objectives, and  This will enhance the technical knowledge  
overall societal values. With current levels of  of policy makers and strengthen ties between  
technical understanding and expertise, policies  political and technical communities, needed 
and regulations may fail to support innovation,  to make good A/IS policy. 
adhere to national principles, and protect  
•  A culture of sharing best practices around  
public safety.
A/IS legislation, consumer protection, 
At the same time, the A/IS personnel should not  workforce transformation, and economic 
only possess a necessary technology knowledge,  displacement stemming from A/IS-based 
but also receive adequate ethical training, and  automation should be fostered across 
have access to other resources on human rights  borders. This can be done by doing 
standards and obligations, along with guidance   exchange governmental delegation trips, 
on how to make them a fundamental component  transcontinental knowledge exchanges, 
of their work.  and by building A/IS components into 
  existing venues and efforts surrounding 
  good regulation (General Data Protection 
Regulation (GDPR)). 
1  This recommendation concurs with the multiple recommendations of the United States National Science and Technology Council,  
One Hundred Year Study of Artificial Intelligence, Japan’s Cabinet Office Council, European Parliament’s Committee on Legal  
Affairs and others.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 186The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
•  In order to ensure that the next generation  
of policy makers is tech savvy, it is necessary 
Objective: 
to rely upon more than their “digital 
nativeness.” Because A/IS are evolving  Support research and 
technologies, long-term educational  development needed to ensure 
strategies are needed, e.g., providing children 
continued leadership in A/IS.
access to coding and computer science 
courses starting from primary school,  
and extending into university or vocational 
Background
courses. 
Greater national investment in ethical A/IS 
Further Resources research and development would stimulate the 
economy, create high-value jobs, and improve 
•  Holdren, J., and M. Smith. “Preparing for the 
governmental services to society. A/IS can 
Future of Artificial Intelligence.” Washington, 
significantly improve our societies: the use of 
DC: Executive Office of the President, 
A/IS in computer vision and human-computer 
National Science and Technology Council, 
interactions will have far-reaching implications. 
2016. 
Intelligent robots will perform difficult and 
•  Stanford University. “Artificial Intelligence   dangerous tasks that require human-like 
and Life in 2030: One Hundred Year Study  intelligence. Self-driving cars will revolutionize 
on Artificial Intelligence.” Stanford, CA:  automobile transportation and logistics systems 
Stanford University, 2016. and reduce traffic fatalities. A/IS will improve 
quality of life through smart cities and decision 
•  “Japan Industrial Policy Spotlights AI, Foreign  support in healthcare, social services, criminal 
Labor.” Nikkei Asian Review, May 20, 2016.  justice, and the environment. However, to ensure 
such a positive impact, more support for R&D, 
•  Weng, Y.-H. “A European Perspective on 
with a particular eye for the ethical impact  
Robot Law: Interview with Mady Delvaux-
of A/IS, is needed.
Stehres.” Robohub, July 15, 2016. 
 
Candidate Recommendations
 
  Investment in A/IS research and development 
  (including ethical considerations) is essential 
  to maximizing societal benefits, mitigating any 
  associated risks, and enabling efficient and 
  effective public sector investment. To enable 
efficient and effective public and private sector 
investment, there should be benchmarks 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 187The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
for A/IS technologies and applications with  •  The Networking and Information Technology 
continuing focus on identifying promising future  Research and Development Program, 
applications of A/IS. An important government  “Supplement to the President’s Budget, 
role is to strategically educate the public and  FY2017.” NITRD National Coordination  
private sectors on key A/IS technologies and  Office, April 2016.
applications. We recommend the following:
•  Furber, S. B., F. Galluppi, S. Temple, and L. A. 
•  Enable a cross-disciplinary research  Plana. “The SpiNNaker Project.” Proceedings 
environment that encourages research  of the IEEE 102, no. 5 (2014): 652–665.
on the fairness, security, transparency, 
•  Markram, H. “The Human Brain Project.” 
understandability, privacy, and societal 
Scientific American 306, no. 2 (June 2012): 
impacts of A/IS and that incorporates  
50–55.
independent means to properly vet, audit, 
and assign accountability to the A/IS 
•  L. Yuan. “China Gears Up in Artificial-
applications.
Intelligence Race.” Wall Street Journal,  
August 24, 2016.
•  Governments should create research 
pools that incentivize research on A/IS that 
benefits the public, but which may not be 
commercially viable.
Objective: 
Further Resources
Provide effective regulation  
•  Kim, E. T. “How an Old Hacking Law Hampers 
of A/IS to ensure public  
the Fight Against Online Discrimination.”  
safety and responsibility while 
The New Yorker, October 1, 2016. 
fostering a robust AI industry.
•  National Research Council. “Developments  
in Artificial Intelligence, Funding a Revolution: 
Government Support for Computing 
Background
Research.” Washington, DC: National 
Academy Press, 1999. Governments must ensure consistent and 
appropriate policies and regulations for  
•  Chen, N., L. Christensen, K. Gallagher,  
A/IS. Effective regulation should address 
R. Mate, and G. Rafert (Analysis Group). 
transparency, understandability, predictability,  
“Global Economic Impacts of Artificial 
and accountability of AI algorithms, risk 
Intelligence,” February 25, 2016.
management, data protection, and safety. 
Certification of systems involving A/IS is  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 188The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
a key technical, societal, and industrial issue.  •  Establish policies that foster the development 
Good regulation encourages innovation, and  of economies able to absorb A/IS, while 
harmonizing policy internationally will reduce  providing broad job opportunities to those 
barriers to trade. who might otherwise be alienated or 
unemployed. In addition, the continued 
Good regulation can take many different forms, 
development of A/IS talent should be 
and appropriate regulatory responses are context-
fostered through international collaboration.
dependent. There is no one-size-fits-all for A/IS 
regulation, but it is important that such regulation  •  Continue research into the viability of 
is developed through an approach that is based  universal basic income. Such a non-conditional  
on human rights2 and has human well-being   and government-provided addition to 
as a key goal.  people’s income might lighten the economic 
burden that comes from automation and 
Candidate Recommendations economic displacement caused by A/IS.
•  To ensure consistent and appropriate  •  Ambiguity regarding whether and how 
policies and regulations across governments,  proprietary A/IS may be reverse engineered 
policymakers should seek informed input  and evaluated by academics, journalists, 
from a range of expert stakeholders, including  and other researchers can stifle innovation 
academic, industry, and government  and public safety. Elimination of these 
officials, to consider questions related to the  impediments is essential.
governance and safe employment of A/IS. 
Further Resources
•  To foster a safe international community of 
A/IS users, policymakers should take similar  •  Stanford University. “Artificial Intelligence  
work being carried out around the world into  and Life in 2030: One Hundred Year Study 
consideration. Due to the transnational nature  on Artificial Intelligence.” Stanford, CA: 
of A/IS, globally synchronized policies can  Stanford University, 2016.
have a greater impact on public safety and 
•  Calo, R. “The Case for a Federal Robotics 
technological innovation.
Commission.” The Brookings Institution, 
•  Law schools should offer interdisciplinary  2014.
courses such as “Introduction to AI and 
•  Mannes, A. “Institutional Options for Robot 
Law” to reduce the gap between regulators, 
Governance,” 1–40, in We Robot 2016, 
lawyers, and A/IS researchers and 
Miami, FL, April 1–2, 2016.  
developers.
2 H uman rights–based approaches have been applied to development, education, and reproductive health.  
See: the UN Practitioner’s Portal on Human Rights Based Programming.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 189The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
•  Marchant, G. E., K. W. Abbott, and B. Allenby,  The success of A/IS technology depends on the 
Innovative Governance Models for Emerging  ease with which people use and adapt to A/IS  
Technologies. Cheltenham, U.K.: Edward   applications. While improving public understanding  
Elgar Publishing, 2014. of A/IS technologies through education is 
becoming increasingly important, so is the need  
•  Weng, Y. H., Y. Sugahara, K. Hashimoto, and 
to educate the public about the social and 
A. Takanishi. “Intersection of ‘Tokku’ Special 
cultural issues of A/IS. The way A/IS interact  
Zone, Robots, and the Law: A Case Study 
with final users, build cognitive models  
on Legal Impacts to Humanoid Robots.” 
of their power and limits, and so help their 
International Journal of Social Robotics 7,  
adoption and sense of control, are key 
no. 5 (2015): 841–857.
technological objectives.
If society approaches these technologies primarily 
with fear and suspicion, societal resistance may 
result, impeding important work on ensuring  
Objective: 
the safety and reliability of A/IS technologies.  
Facilitate public understanding   On the other hand, if society is informed of  
the positive contributions and the opportunities 
of the rewards and risks of A/IS.
A/IS create, then the technologies emerging from 
the field could profoundly transform  
society for the better in the coming decades.3 
Background
Another major societal issue — and the subject  
Perception drives public response. A/IS 
of much ongoing debate — is whether A/IS 
technologies and applications can both capture 
should have, or could develop, any sense of 
the imagination such as self-driving cars, and 
ethical behavior. A/IS will require a commonly 
instill fear. Therefore, it is imperative for industry, 
accepted sense of ethical behavior, or, at the 
academia, and government to communicate 
very least, possess behaviors with ethical 
accurately both the positive potential of A/IS 
implications. Therefore, technology awareness 
and the areas that require caution. Developing 
and understanding of social and ethical issues  
strategies for informing and engaging the public 
of A/IS are new literacy skills society must 
on A/IS benefits and challenges are critical to 
embrace if A/IS applications are to be accepted 
creating an environment conducive to effective 
and trusted as an integral part of modern living. 
decision-making. 
 
3 One hundred year study of AI (AI100), Stanford University, August, 2016.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 190The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
Candidate Recommendations •  Conduct media outreach to illustrate A/IS  
beneficial uses, and the important steps  
•  Encourage A/IS development to serve the 
being taken to ensure safety and transparency.  
pressing needs of humanity by promoting 
Public opinion related to trust, safety, privacy, 
dialogue and continued debate over the 
employment, and the economy will drive 
social and ethical implications of A/IS.  
public policy. It is critical to creating an 
To better understand the societal implications 
environment conducive to effective decision-
of A/IS, we recommend that funding be 
making, particularly as more government 
increased for interdisciplinary research on 
services come to rely on A/IS, that strategies 
topics ranging from basic research into 
are developed to inform and engage  
intelligence to principles on ethics, safety, 
the public on AI benefits and challenges.  
privacy, fairness, liability, and trustworthiness 
Care must be taken to augment human 
of A/IS technology. Societal aspects should 
interaction with A/IS and to avoid 
be addressed not only at an academic 
discrimination against segments of society.
level but also through the engagement 
of business, public authorities, and policy 
Further Resources
makers. While technical innovation is a 
goal, it should not be prioritized over the  •  Networking and Information Technology 
protection of individuals. Research and Development (NITRD) 
Program. “The National Artificial Intelligence 
•  Begin an international multi-stakeholder 
Research and Development Strategic Plan.” 
dialogue to determine the best practices 
Washington, DC: Office of Science and 
for using and developing A/IS, and codify 
Technology Policy, 2016. 
this dialogue into international norms and 
standards. Many industries, in particular  •  Saunders, J., P. Hunt, and J. S. Hollywood. 
system industries (automotive, air and  “Predictions Put into Practice: A Quasi-
space, defense, energy, medical systems,  Experimental Evaluation of Chicago’s 
manufacturing) are going to be significantly  Predictive Policing Pilot,” Journal of 
changed by the surge of A/IS. A/IS algorithms  Experimental Criminology 12, no. 347, 
and applications must be considered as  (2016): 347–371. doi:10.1007/s11292-
products owned by companies, and therefore  019272-0
the companies must be responsible for the 
A/IS products not being a threat to humanity.  •  Edelman, B., and M. Luca. “Digital 
Discrimination: The Case of Airbnb.com.” 
•  Empower and enable independent journalists  Harvard Business School Working Paper  
and media outlets to report on A/IS, both   14-054, 2014.  
by providing access to technical expertise    
and funding for independent journalism. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 191The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Policy
•  Garvie, C., A. Bedoya, and J. Frankle.   •  Arkin, R. C. “Ethics and Autonomous  
“The Perpetual Line-Up: Unregulated Police  Systems: Perils and Promises [Point of 
Face Recognition in America.” Washington,  View].” Proceedings of the IEEE 104,  
DC: Georgetown Law, Center on Privacy   no. 10, (1779–1781): 2016.
& Technology, 2016.
•  Eurobarometer Survey on Autonomous 
•  Chui M., and J. Manyika, “Automation,  Systems (published June 2015 by DG 
Jobs, and the Future of Work.” Seattle, WA:  Connect) looks at Europeans’ attitudes to 
McKinsey Global Institute, 2014.  robots, driverless vehicles, and autonomous 
drones. The survey shows that those who 
•  The IEEE Global Initiative for Ethical 
have more experience with robots (at home, 
Considerations in Artificial Intelligence  
at work or elsewhere) are more positive 
and Autonomous Systems. Ethically Aligned 
toward their use.
Design: A Vision for Prioritizing Human 
Well-being with Artificial Intelligence and 
Autonomous Systems, Version 1. IEEE, 2016. 
 
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 192The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
The task of the Committee for Classical Ethics in Autonomous and Intelligent Systems  
is to apply classical ethics methodologies to considerations of algorithmic design in 
autonomous and intelligent systems (A/IS) where machine learning may or may not reflect 
ethical outcomes that mimic human decision-making. To meet this goal, the Committee 
has drawn from classical ethics theories as well as from the disciplines of machine ethics, 
information ethics, and technology ethics.
As direct human control over tools becomes, on one hand, further removed, but on  
the other hand, more influential than ever through the precise and deliberate design  
of algorithms in self-sustained digital systems, creators of autonomous systems must  
ask themselves how cultural and ethical presumptions bias artificially intelligent creations, 
and how these created systems will respond based on such design. 
By drawing from over two thousand years’ worth of classical ethics traditions, the Classical 
Ethics in Autonomous and Intelligent Systems Committee will explore established ethics 
systems, addressing both scientific and religious approaches, including secular philosophical 
traditions such as utilitarianism, virtue ethics, and deontological ethics and religious- 
and-culture-based ethical systems arising from Buddhism, Confucianism, African Ubuntu 
traditions, and Japanese Shinto influences toward an address of human morality in the 
digital age. In doing so the Committee will critique assumptions around concepts such  
as good and evil, right and wrong, virtue and vice and attempt to carry these inquiries  
into artificial systems decision-making processes.
Through reviewing the philosophical foundations that define autonomy and ontology,  
the Committee will address the potential for autonomous capacity of artificially intelligent 
systems, posing questions of morality in amoral systems, and asking whether decisions 
made by amoral systems can have moral consequences. Ultimately, it will address notions 
of responsibility and accountability for the decisions made by autonomous systems and 
other artificially intelligent technologies.
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 193The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
Section 1 — Definitions for  
Classical Ethics in Autonomous  
and Intelligent Systems Research
and the consequences of being a part of the 
outside world. The moral autonomous subject 
Issue: 
of modernity became thus a worldless isolated 
Assigning foundations   subject. This process is important to understand 
for morality, autonomy,   in terms of ethics for artificial intelligence since  
it is, paradoxically, the kind of autonomy that  
and intelligence.
is supposed to be achieved by intelligent 
machines in the very moment in which we, 
humans, begin to change our being into digitally 
Background 
networked beings.
Classical theories of economy in the Western 
There lies a danger in uncritically attributing 
tradition, starting with Plato and Aristotle, 
classical concepts of anthropomorphic autonomy 
embrace three domains: the individual, the 
to machines, including using the term artificial 
family, and the polis. The forming of the individual 
intelligence to describe them since, in the 
character (ethos) is intrinsically related to others, 
attempt to make them “moral” by programming 
as well as to the tasks of administration of work 
moral rules into their behavior, we run the risk 
within the family (oikos) and eventually all this 
of assuming economic and political dimensions 
expands into the framework of the polis, or public 
that do not exist, or that are not in line with 
space (poleis). This means that when we discuss 
contemporary human societies. As noted above, 
ethical issues of autonomous and intelligent 
present human societies are being redefined 
systems we should consider all three traditional 
in terms of digital citizenship via digital social 
economic dimensions that evolved in modernity 
networks. The present public debate about 
into an individual morality disconnected from 
the replaceability of human work by intelligent 
economics and politics. This disconnection was 
machines is a symptom of this lack of awareness 
partly questioned by thinkers such as Adam 
of the economic and political dimensions  
Smith, Hegel, Marx, and others. In particular, 
as defined by classical ethics, reducing ethical 
Immanuel Kant’s ethics located morality within 
thinking to the “morality” of a worldless and 
the subject (see: categorical imperative) and 
isolated machine (a mimic of the modern subject).
separated morality from the outside world 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 194The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
Candidate Recommendations Freedom in the Cyberworld. Berlin:  
Walter de Gruyter, 2013. 
•  Via a return to classical ethics foundations, 
enlarge the discussion on ethics in  •  Chalmers, D. “The Singularity: A Philosophical 
autonomous and intelligent systems   Analysis.” Journal of Consciousness Studies 
(A/IS) to include a critical assessment   17, (2010): 7–65.
of anthropomorphic presumptions of ethics 
and moral rules for A/IS. Keep in mind 
that machines do not, in terms of classical 
autonomy, comprehend the moral or  
legal rules they follow, but rather move  Issue: 
according to what they are programmed  
Distinguishing between  
to do, following rules that are designed  
agents and patients.
by humans to be moral.
•  Enlarge the discussion on ethics for  
A/IS to include an exploration of the  
Background
classical foundations of economy, outlined 
Of concern for understanding the relationship 
above, as potentially influencing current  
between human beings and A/IS is the 
views and assumptions around machines 
uncritically applied anthropomorphistic approach 
achieving isolated autonomy.
toward A/IS that many industry and policy makers 
are using today. This approach erroneously blurs 
Further Resources
the distinction between moral agents and moral 
•  Bielby, J., ed. “Digital Global Citizenship.”  patients (i.e., subjects), otherwise understood 
International Review of Information Ethics   as a distinction between “natural” self-organizing 
23 (November 2015). systems and artificial, non-self-organizing 
devices. As noted above, A/IS devices cannot, 
•  Bendel, O. “Towards a Machine Ethics.” 
by definition, become autonomous in the sense 
Northwestern Switzerland: University of 
that humans or living beings are autonomous. 
Applied Sciences and Arts, 2013. 
With that said, autonomy in machines, when 
critically defined, designates how machines act 
•  Bendel, O. “Considerations about the 
and operate independently in certain contexts 
Relationship Between Animal and Machine 
through a consideration of implemented order 
Ethics.” AI & Society 31, no. 1 (2016): 
generated by laws and rules. In this sense,  
103–108.
A/IS can, by definition, qualify as autonomous, 
•  Capurro, R., M. Eldred, and D. Nagel.   especially in the case of genetic algorithms  
Digital Whoness: Identity, Privacy and  and evolutionary strategies. However, attempts 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 195The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
to implant true morality and emotions, and thus  terminology cannot be used metaphorically, but 
accountability (i.e., autonomy) into A/IS is both  the difference must be maintained, especially  
dangerous and misleading in that it encourages  as A/IS begins to resemble human beings 
anthropomorphistic expectations of machines   more closely. Terms like “artificial intelligence” 
by human beings when designing and interacting  or “morality of machines” can be used as 
with A/IS. metaphors, and it does not necessarily lend to 
misunderstanding to do so. This is how language 
Thus, an adequate assessment of expectations 
works and how humans try to understand their 
and language used to describe the human-A/IS 
natural and artificial environment.
relationship becomes critical in the early stages  
of its development, where unpacking subtleties   However the critical difference between human 
is necessary. Definitions of autonomy need   autonomy and autonomous systems involves 
to be clearly drawn, both in terms of A/IS and  questions of free will, predetermination, and 
human autonomy. On one hand A/IS may in  being (ontology). The questions of critical 
some cases manifest seemingly ethical and moral  ontology currently being applied to machines 
decisions, resulting for all intents and purposes   are not new questions to ethical discourse and 
in efficient and agreeable moral outcomes.   philosophy and have been thoroughly applied  
Many human traditions, on the other hand,   to the nature of human being as well. John Stuart 
can and have manifested as fundamentalism  Mill, for example, is a determinist and claims that 
under the guise of morality. Such is the   human actions are predicated on predetermined 
case with many religious moral foundations,  laws. He does, however, argue for a reconciliation 
where established cultural mores are neither  of human free will with determinism through  
questioned nor assessed. In such scenarios,   a theory of compatibility. Millian ethics provides 
one must consider whether there is any  a detailed and informed foundation for defining 
functional difference between the level of  autonomy that could serve to help combat 
autonomy in A/IS and that of assumed agency  general assumptions of anthropomorphism  
(the ability to choose and act) in humans via  in A/IS and thereby address the uncertainty 
the blind adherence to religious, traditional,  therein (Mill, 1999). 
or habitual mores. The relationship between 
assumed moral customs (mores), the ethical  Candidate Recommendation
critique of those customs (i.e., ethics), and the 
When addressing the nature of “autonomy” 
law are important distinctions.
in autonomous systems, it is recommended 
The above misunderstanding in definitions of  that the discussion first consider free will, civil 
autonomy arise in part because of the tendency  liberty, and society from a Millian perspective 
for humans to shape artificial creations in their  in order to better grasp definitions of autonomy 
own image, and our desire to lend our human  and to combat general assumptions of 
experience to shaping a morphology of artificially  anthropomorphism in A/IS.
intelligent systems. This is not to say that such 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 196The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
Further Resources
•  Capurro, Rafael. “Toward a Comparative  Issue: 
Theory of Agents.” AI & Society 27, no. 4 
There is a need for  
(2012): 479–488.
an accessible classical  
•  King, William Joseph, and Jun Ohya.   ethics vocabulary. 
“The representation of agents: 
Anthropomorphism, agency, and intelligence.” 
Conference Companion on Human Factors  
Background
in Computing Systems. ACM, 1996.
Philosophers and ethicists are trained in 
•  Hofkirchner, W. “Does Computing Embrace 
vocabulary relating to philosophical concepts 
Self-Organization?” in Information and 
and terminology. There is an intrinsic value 
Computation, Essays on Scientific and 
placed on these concepts when discussing 
Philosophical Understanding of Foundations 
ethics and AI, since the layered meaning behind 
of Information and Computation, edited 
the terminology used is foundational to these 
by G. Dodig-Crnkovic, M. Burgin, 185–202. 
discussions, and is grounded in a subsequent 
London: World Scientific, 2011.
entrenchment of values. Unfortunately, using 
philosophical terminology in cross-discipline 
•  International Center for Information Ethics.
instances, for example, in conversation with 
•  Mill, J. S. On Liberty. London: Longman,  technologists and policymakers is often ineffective  
Roberts & Green, 1869. since not everyone has the education to be able 
to encompass the abstracted layers of meaning 
•  Verbeek, P.-P. What Things Do: Philosophical 
contained in philosophical terminology. 
Reflections on Technology, Agency, and 
Design. University Park, PA: Penn State   However, not understanding a philosophical 
Press, 2010.    definition does not detract from the necessity 
  of its utility. While ethical and philosophical 
  theories should not be over-simplified for popular 
  consumption, being able to adequately translate 
  the essence of the rich history of ethics traditions 
  will go a long way in supporting a constructive 
  dialogue on ethics and A/IS. As access and 
  accessibility concerns are also intricately linked 
with education in communities, as well as 
secondary and tertiary institutions, society needs 
to take a vested interest in creating awareness 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 197The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
for government officials, rural communities, and 
school teachers. Creating a more “user-friendly” 
Issue: 
vocabulary raises awareness on the necessity and 
application of classical ethics to digital societies.  Presenting ethics to  
the creators of autonomous  
Candidate Recommendation and intelligent systems.
Support and encourage the efforts of groups 
raising awareness for social and ethics 
committees whose roles are to support ethics  Background
dialogue within their organizations, seeking 
The question arises as to whether or not classical 
approaches that are both aspirational and values-
ethics theories can be used to produce meta-
based. A/IS technologists should engage in 
level orientations to data collection and data  
cross-discipline exchanges whereby philosophy 
use in decision-making. The key is to embed 
scholars and ethicists attend and present at 
ethics into engineering in a way that does not 
non-philosophical courses. This will both raise 
make ethics a servant, but instead a partner  
awareness and sensitize non-philosophical 
in the process. In addition to an ethics-in-practice 
scholars and practitioners to the vocabulary. 
approach, providing students and engineers with 
the tools necessary to build a similar orientation 
Further Resources
into their devices further entrenches ethical 
•  Capurro, R. “Towards an Ontological  design practices. In the abstract this is not so 
Foundation of Information Ethics.”   difficult to describe, but very difficult to encode 
Ethics and Information Technology 8,   into systems. 
no. 4 (2006): 175–186.
This problem can be addressed by providing 
•  Flinders, D. J. “In Search of Ethical Guidance:  students with job-aids such as checklists, 
Constructing a Basis for Dialogue 1.”  flowcharts, and matrices that help them select 
Qualitative Studies in Education 5, no. 2  and use a principal ethical framework, and then 
(1992): 101–115. exercise use of those devices with steadily more 
complex examples. In such an iterative process, 
•  Saldanha, G. S. “The Demon in the Gap  
students will start to determine for themselves 
of Language: Capurro, Ethics and Language 
what examples do not allow for perfectly clear 
in Divided Germany.” Information Cultures 
decisions, and in fact require some interaction 
in the Digital Age. Wiesbaden, Germany: 
between frameworks. Produced outcomes such  
Springer Fachmedien, 2016. 253–268. 
as videos, essays, and other formats – such  
 
as project-based learning activities – allow  
for a didactical strategy which proves effective  
in artificial intelligence ethics education. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 198The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
The goal is to provide students a means to  Candidate Recommendation
use ethics in a manner analogous to how they 
Find ways to present ethics where the 
are being taught to use engineering principles 
methodologies used are familiar to engineering 
and tools. In other words, the goal is to help 
students. As engineering is taught as a collection 
engineers tell the story of what they’re doing.
of techno-science, logic, and mathematics, 
•  Ethicists should use information flows and  embedding ethical sensitivity into these objective 
consider at a meta-level what information  and non-objective processes is essential.
flows do and what they are supposed to do. 
Further Resources
•  Engineers should then build a narrative 
•  Bynum, T. W., and S. Rogerson. Computer 
that outlines the iterative process of ethical 
Ethics and Professional Responsibility. 
considerations in their design. Intentions  
Malden, MA: Wiley-Blackwell, 2003.
are part of the narrative and provide  
a base to reflect back on those intentions. 
•  Seebauer, E. G., and R. L. Barry. 
Fundamentals of Ethics for Scientists and 
•  The process then allows engineers to 
Engineers. New York: Oxford University  
better understand their assumptions and 
Press, 2001.
adjust their intentions and design processes 
accordingly. They can only get to these  
•  Whitbeck, C. “Teaching Ethics to Scientists 
by asking targeted questions. 
and Engineers: Moral Agents and Moral 
Problems.“ Science and Engineering Ethics  
This process, one with which engineers are  
1, no. 3 (1995): 299–308.
quite familiar, is basically Kantian and Millian 
ethics in play.
•  Zevenbergen, B. et al. “Philosophy Meets 
Internet Engineering: Ethics in Networked 
The aim is to produce what in computer 
Systems Research.” GTC workshop outcomes 
programming lexicon is referred to as a macro. 
paper. Oxford, U.K.: Oxford Internet Institute, 
A macro is code that takes other code as its 
University of Oxford, 2015.
input(s) and produces unique outputs. This 
macro is built using the Western ethics tradition 
•  Perez Á., and M. Ángel, “Teaching Information 
of virtue ethics. 
Ethics.” International Review of Information 
 
Ethics 14 (12/2010): 23–28.
 
  •  Verbeek, P-P. Moralizing Technology: 
  Understanding and Designing the Morality  
  of Things. Chicago: University of Chicago 
Press, 2011.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 199The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
Candidate Recommendation
Issue:  Bridge the language gap between technologists, 
philosophers, and policymakers. Understanding 
Access to classical ethics by 
the nuances in philosophical language is  
corporations and companies.
critical to digital society from IoT, privacy, and 
cybersecurity to issues of Internet governance. 
Background Further Resources
Many companies, from start-ups to tech giants,  •  Bhimani, A. “Making Corporate Governance 
understand that ethical considerations in tech  Count: The Fusion of Ethics and Economic 
design are increasingly important, but are  Rationality.” Journal of Management & 
not quite sure how to incorporate ethics into  Governance 12, no. 2 (2008): 135–147.
their tech design agenda. How can ethical 
considerations in tech design become an  •  Carroll, A. B. “A History of Corporate Social 
integrated part of the agenda of companies,  Responsibility.” in The Oxford Handbook of 
public projects, and research consortia? Many  Corporate Social Responsibility, edited by 
corporate workshops and exercises that attempt  Chrisanthi A., R. Mansell, D. Quah, and R. 
to consider ethics in technology practices present  Silverstone. Oxford, U.K.: Oxford University 
the conversation as a carte blanche for people   Press, 2008.
to speak about their opinions, but serious  
•  Lazonick, W. “Globalization of the ICT 
ethical discussions are often lacking. As it stands, 
Labor Force.” in The Oxford Handbook 
classical ethics is not accessible enough to 
of Information and Communication 
corporate endeavors in ethics, and as such, are 
Technologies, edited by Chrisanthi A.,  
not applicable to tech projects. There is often,  
R. Mansell, D. Quah, and R. Silverstone. 
but not always, a big discrepancy between the 
Oxford, U.K.: Oxford University Press, 2006.
output of engineers, lawyers, and philosophers 
when dealing with computer science issues   •  IEEE P7000™, Model Process for Addressing 
and a large difference in how various disciplines  Ethical Concerns During System Design. 
approach these issues. While this is not true   This standard will provide engineers and 
in all cases, and there are now several  technologists with an implementable process 
interdisciplinary approaches in robotics and  aligning innovation management processes, 
machine ethics as well as a growing number   IS system design approaches and software 
of scientists that hold double and interdisciplinary  engineering methods to minimize ethical  
degrees, there remains a vacuum for the wider  risk for their organizations, stakeholders and 
understanding of classical ethics theories in the  end users. The Working Group is currently  
interdisciplinary setting. in process, and is free and open to join. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 200The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
become mutually responsive to each other with 
a view to the (ethical) acceptability, sustainability 
Issue: 
and societal desirability of the innovation process 
Impact of automated systems   and its marketable products (in order to allow a 
on the workplace. proper embedding of scientific and technological 
advances in our society).”1
When RRI methodologies are used in the ethical 
Background considerations of A/IS design, especially in 
response to the potential bias of A/IS in the 
The impact of A/IS on the workplace and the 
workplace, theoretical deficiencies are then often 
changing power relationships between workers 
exposed that would not otherwise have been 
and employers requires ethical guidance.  
exposed, allowing room for improvement in 
Issues of data protection and privacy via big  
design at the development stage rather than from 
data in combination with the use of autonomous 
a retroactive perspective. RRI in design increases 
systems by employers is an increasing issue, 
the chances of both relevance and strength  
where decisions made via aggregate algorithms 
in ethically aligned design.
directly impact employment prospects. The 
uncritical use of A/IS in the workplace in employee/ 
employer relations is of utmost concern due   Candidate Recommendation
to the high chance for error and biased outcome.
It is recommended that through the application 
of RRI, as founded in classical ethics theory, 
The concept of responsible research and 
research in A/IS design utilize available tools 
innovation (RRI), a growing area, particularly 
and approaches to better understand the design 
within the EU, offers potential solutions to 
process, addressing ethical concerns from the 
workplace bias and is being adopted by several 
very beginning of the design stage of the project, 
research funders such as the EPSRC, who include 
thus maintaining a stronger more efficient 
RRI core principles in their mission statement. 
methodological accountability throughout. 
RRI is an umbrella concept that draws on classical 
ethics theory to provide tools to address ethical 
concerns from the outset of a project (design  Further Resources
stage and onwards). 
•  Burget, M., E. Bardone, and M. Pedaste. 
“Definitions and Conceptual Dimensions  
Quoting Von Schomberg, “Responsible Research 
of Responsible Research and Innovation:  
and Innovation is a transparent, interactive 
A Literature Review.” Science and 
process by which societal actors and innovators 
Engineering Ethics 23, no. 1 (2016): 1–9.
1  Von Schomberg (2011) ‘Prospects for Technology Assessment in a framework of responsible research and innovation’ in: 
M. Dusseldorp and R. Beecroft (eds). Technikfolgen abschätzen lehren: Bildungspotenziale transdisziplinärer Methoden, 
Wiesbaden: Vs Verlag, in print, P.9.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 201The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
•  Von Schomberg, R. “Prospects for Technology  •  Stahl, B. C., and B. Niehaves. “Responsible 
Assessment in a Framework of Responsible  Research and Innovation (RRI).” 
Research and Innovation,” in Technikfolgen 
•  IEEE P7005™, Standard for Transparent 
Abschätzen Lehren: Bildungspotenziale 
Employer Data Governance is designed  
Transdisziplinärer Methode, 39–61, 
to provide organizations with a set of clear 
Wiesbaden, Germany: Springer VS, 2011.
guidelines and certifications guaranteeing 
•  Stahl, B. C. et al. “From Computer Ethics  they are storing, protecting, and utilizing 
to Responsible Research and Innovation in  employee data in an ethical and transparent 
ICT: The Transition of Reference Discourses  way. The Working Group is currently  
Informing Ethics-Related Research in  in process, and is free and open to join. 
Information Systems.” Information & 
Management 51, no. 6 (2014): 810–818.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 202The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
Section 2 — Classical Ethics From  
Globally Diverse Traditions 
What is it that one refers to by the term Western 
ethics? By Western ethics, does one refer 
Issue: 
to philosophical ethics (ethics as a scientific 
The monopoly on ethics   discipline) or is the reference to Western morality? 
by Western ethical traditions.
The West (however it may be defined) is an 
individualistic society, arguably more so than 
much of the rest of the world, and thus in some 
Background
aspects should be even less collectively defined 
As human creators, our most fundamental   than say, “Eastern” ethical traditions. If one is 
values are imposed on the systems we design.   referring to Western values, one must designate 
It becomes incumbent on a global-wide  which values, and values of which persons 
community to recognize which sets of values  and institutions. Additionally, there is a danger 
guide the design, and whether or not A/IS   in intercultural information ethics (however 
will generate problematic (e.g., discriminatory)  unconsciously or instinctively propagated) to not 
consequences without consideration of non- only group together all Western traditions under  
Western values. There is an urgent need to  a single banner, but to negatively designate any 
broaden traditional ethics in its contemporary  and all Western influence in global exchange  
form of “responsible innovation” (RI) beyond   to representing an abusive collective of colonial-
the scope of “Western” ethical foundations,   influenced ideals. Just because there exists 
e.g., utilitarianism, deontology, and virtue  a monopoly of influence by one system over 
ethics; and include other traditions of ethics  another does not mean that said monopoly is 
in RI, including those inherent to, for example,  devoid of value, even for systems outside itself. 
Buddhism, Confucianism, and Ubuntu traditions.  In the same way that culturally diverse traditions 
have much to offer Western tradition(s),  
However, this venture poses problematic  so too do they have much to gain from them.
assumptions even before the issue above can  
be explored, when, in classifying Western values,  In order to establish mutually beneficial 
we also group together thousands of years   connections in addressing globally diverse 
of independent and disparate ideas originating  traditions, it is of critical import to first properly 
from the Greco-Roman philosophical tradition  distinguish between subtleties in Western 
with its Christian-infused cultural heritage.   ethics (as a discipline) and morality (as its 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 203The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
object or subject matter). It is also important  ethical value systems, especially when it comes 
to differentiate between philosophical ethics  to standardization. As Wong notes:
(as scientific ethics) and theological ethics. 
Standardization is an inherently value-laden 
As noted above, the relationship between 
project, as it designates the normative criteria 
assumed moral customs (mores), the ethical 
for inclusion to the global network. Here, 
critique of those customs (i.e., ethics), and the 
one of the major adverse implications of the 
law is an established methodology in scientific 
introduction of value-laden standard(s) of 
communities. Western and Eastern philosophy 
responsible innovation (RI) appears to be the 
are very different, as well as are Western and 
delegitimization of the plausibility of RI based 
Eastern ethics. Western philosophical ethics uses 
on local values, especially when those values 
scientific methods, e.g., the logical, discursive, 
come into conflict with the liberal democratic 
dialectical approach (models of normative ethics) 
values, as the local values (or, the RI based 
and the analytical and hermeneutical approach. 
on local values) do not enable scientists and 
The Western tradition is not about education 
technology developers to be recognized as 
and teaching of social and moral values, but 
members of the global network of research 
rather about the application of fundamentals, 
and innovation (Wong, 2016).
frameworks, and explanations. However, several 
contemporary globally relevant community 
It does however become necessary for those 
mores are based in traditional and theological 
who do not work within the parameters of 
moral systems, requiring a conversation around 
accepted values monopolies to find alternative 
how best to collaborate in the design and 
methods of accommodating different value 
programming of ethics in A/IS amidst differing 
systems. Liberal values arose out of conflicts 
ethical traditions.
of cultural and subcultural difference and are 
designed to be accommodating enough to 
While experts in Intercultural Information Ethics, 
include a rather wide range of differences. 
such as Pak-Hang Wong, highlight the dangers  
of the dominance of “Western” ethics in  
Responsible innovation (RI) enables policy-
AI design, noting specifically the appropriation 
makers, scientists, technology developers, and 
of ethics by liberal democratic values to the 
the public to better understand and respond  
exclusion of other value systems, it should be 
to the social, ethical, and policy challenges  
noted that those same liberal democratic values 
raised by new and emerging technologies.  
are put in place and specifically designed to 
Given the historical context from which RI 
accommodate such differences. However, while 
emerges, it should not be surprising that the 
the accommodation of differences are, in theory, 
current discourse on RI is predominantly based 
accounted for in dominant liberal value systems, 
on liberal democratic values. Yet, the bias toward 
the reality of the situation reveals a monopoly  
liberal democratic values will inevitably limit  
of, and a bias toward, established Western  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 204The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
the discussion of RI, especially in the cases   •  Wong, P.-H. “What Should We Share?: 
where liberal democratic values are not taken   Understanding the Aim of Intercultural 
for granted. Against this background, it   Information Ethics.” ACM SIGCAS Computers 
is important to recognize the problematic  and Society 39, no. 3 (2009): 50–58.
consequences of RI solely grounded on,  
•  Wong, P.-H. “Responsible Innovation for 
or justified by, liberal democratic values.
Decent Nonliberal Peoples: A Dilemma?” 
Journal of Responsible Innovation 3, no. 2 
Candidate Recommendation
(2016): 154–168.
In order to enable a cross-cultural dialogue  
•  Zeuschner, R. B. Classical Ethics, East and 
of ethics in technology, discussions in ethics and 
West: Ethics from a Comparative Perspective. 
A/IS must first return to normative foundations 
Boston: McGraw-Hill, 2000.
of RI to address the notion of “responsible 
innovation” from value systems not predominant 
•  Mattingly-Jordan, S., Becoming a Leader  
in Western classical ethics, including nonliberal 
in Global Ethics, IEEE, 2017. 
democratic perspectives. Pak-Hang Wong’s paper, 
“Responsible Innovation for Decent Nonliberal 
Peoples: A Dilemma?” demonstrates the 
problematic consequences of RI solely grounded 
on, or justified by, liberal democratic values and  Issue: 
should be consulted as a guide to normative 
The application of classical 
foundations in RI.
Buddhist ethical traditions  
to AI design.
Further Resources
•  Bielby, J. “Comparative Philosophies in 
Intercultural Information Ethics.” Confluence: 
Background
Journal of World Philosophies 2 (2016).
According to Buddhism, ethics is concerned with 
•  Hongladarom, S. “Intercultural Information 
behaving in such a way that the subject ultimately 
Ethics: A Pragmatic Consideration.” 
realizes the goal of Liberation. The question  
Information Cultures in the Digital Age, 
“How should I act?” is answered straightforwardly; 
191–206. Wiesbaden, Germany: Springer 
one should act in such a way that one realizes 
Fachmedien, 2016. 
Liberation (nirvana) in the future, achieving 
what in Buddhism is understood as “supreme 
•  Rodríguez, L. G., and M. Á. P. Álvarez. Ética 
happiness.” Thus Buddhist ethics are clearly 
Multicultural y Sociedad en Red. Fundación 
goal-oriented. In the Buddhist tradition, people 
Telefónica, 2014.
attain Liberation when they no longer endure 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 205The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
any unsatisfactory conditions, when they have  it. The relevant question in Buddhism is not 
attained the state where they are completely   about methodological reflection, but about  
free from any passions, including desire, anger,  how to attain Liberation from the necessity  
and delusion (to name the traditional three),  for such reflection. 
which ensnare one’s self against freedom.  
Thus, Buddhist ethics contains potential for 
In order to attain Liberation, one engages oneself 
conflict with Western ethical value systems which 
in mindful behavior (ethics), concentration 
are founded on ideas of questioning moral and 
(meditation), and what in Buddhism is deemed 
epistemological assumptions. Buddhist ethics  
as wisdom, a term that remains ambiguous  
is different from, for example, utilitarianism, which 
in Western scientific approaches to ethics.
operates via critical analysis toward providing the 
Thus ethics in Buddhism is concerned exclusively  best possible situation to the largest number of 
with how to attain the goal of Liberation, or  people, especially as it pertains to the good life. 
freedom. In contrast to Western ethics, Buddhist  These fundamental differences between the 
ethics is not concerned with theoretical questions  traditions need to be first and foremost mutually 
concerning the source of normativity or what  understood and then addressed in one form  
constitutes the good life. What makes an action  or another when designing A/IS that span  
a “good” action in Buddhism is always concerned  cultural contexts. 
with whether the action leads, eventually, to 
The main difference between Buddhist and 
Liberation or not. In Buddhism, there is no 
Western ethics is that Buddhism is based  
questioning as to why Liberation is a good thing. 
upon a metaphysics of relation. Buddhist ethics 
It is simply assumed. Such an assumption places 
emphasizes how action leads to achieving  
Buddhism, and ethical reflection from a Buddhist 
a goal, or in the case of Buddhism, the final  
perspective, in the camp of mores rather than 
Goal. In other words, an action is considered  
scientifically led ethical discourse, and it is 
a good one when it contributes to realization of 
approached as an ideology or a worldview. 
the Goal. It is relational when the value  
While it is critically important to consider,  of an action is relative to whether or not it leads 
understand, and apply accepted ideologies  to the Goal, the Goal being the reduction and 
such as Buddhism in A/IS, it is both necessary  eventual cessation of suffering. In Buddhism, 
to differentiate the methodology from Western  the self is constituted through the relationship 
ethics, and respectful to Buddhist tradition   between the synergy of bodily parts and mental 
not to require it be considered in a scientific  activities. In Buddhist analysis, the self does  
context. Such assumptions put it at odds with,  not actually exist as a self-subsisting entity. 
and in conflict with, the Western foundation of  Liberation, or nirvana, consists in realizing that 
ethical reflection on mores. From a Buddhist  what is known to be the self actually consists  
perspective, one does not ask why supreme  of nothing more than these connecting episodes 
happiness is a good thing; one simply accepts   and parts. To exemplify the above, one can draw 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 206The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
from the concept of privacy as oft explored via  Candidate Recommendation
intercultural information ethics. The Buddhist 
In considering the nature of human and 
perspective understands privacy as a protection, 
autonomous systems interactions, the above 
not of self-subsisting individuals, because such  
notion of “proper relationships” through  
do not exist ultimately speaking, but a protection 
Buddhist ethics can provide a useful platform  
of certain values which are found to be necessary 
that results in ethical statements formulated  
for a well-functioning society and one which  
in a relational way, instead of an absolutist 
can prosper in the globalized world. 
way, and is recommended as an additional 
The secular formulation of the supreme  methodology, along with Western values 
happiness mentioned above is that of the  methodologies, to addressing human/computer 
reduction of the experience of suffering, or  interactions.
reduction of the metacognitive state of suffering 
as a result of lifelong discipline and meditation  Further Resources
aimed at achieving proper relationships with 
•  Capurro, R. “Intercultural Information Ethics: 
others and with the world. This notion of the 
Foundations and Applications.” Journal  
reduction of suffering is something that can 
of Information, Communication & Ethics  
resonate well with certain Western traditions, 
in Society 6, no. 2 (2008): 116.
such as epicureanism and the notion of ataraxia, 
freedom from fear through reason and discipline,  •  Ess, C. “Ethical Pluralism and Global 
and versions of consequentialist ethics that   Information Ethics.” Ethics and Information 
are more focused on the reduction of harm.   Technology 8, no. 4 (2006): 215–226.
It also encompasses the concept of phronesis  
•  Hongladarom, S. “Intercultural Information 
or practical wisdom from virtue ethics. 
Ethics: A Pragmatic Consideration,” in 
Relational ethical boundaries promote ethical  Information Cultures in the Digital Age 
guidance that focuses on creativity and growth  edited by K. M. Bielby, 191–206. Wiesbaden, 
rather than solely on mitigation of consequence  Germany: Springer Fachmedien Wiesbaden, 
and avoidance of error. If the goal of the  2016. 
reduction of suffering can be formulated in 
•  Hongladarom, S. et al. “Intercultural 
a way that is not absolute, but collaboratively 
Information Ethics.” International Review  
defined, this leaves room for many philosophies 
of Information Ethics 11 (2009): 2–5. 
and related approaches to how this goal can be 
 
accomplished. Intentionally making space for 
 
ethical pluralism is one potential antidote  
 
to dominance of the conversation by liberal 
thought, with its legacy of Western colonialism.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 207The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
•  Nakada, M. “Different Discussions on  1.  Members of the A/IS research community
Roboethics and Information Ethics Based 
2.  A/IS programmers/computer scientists
on Different Contexts (Ba). Discussions 
on Robots, Informatics and Life in the 
3.  A/IS end-users
Information Era in Japanese Bulletin Board 
Forums and Mass Media.” Proceedings  4.  Autonomous and intelligent systems 
Cultural Attitudes Towards Communication 
Ubuntu is a Sub-Saharan philosophical tradition. 
and Technology (2010): 300–314.
Its basic tenet is that a person is a person 
•  Mori, Ma. The Buddha in the Robot.  through other persons. It develops further in the 
Suginami-ku, Japan: Kosei Publishing, 1989. notions of caring and sharing as well as identity 
and belonging, whereby people experience their 
lives as bound up with their community. A person 
is defined in relation to the community since the 
sense of being is intricately linked with belonging. 
Issue: 
Therefore, community exists through shared 
The application of   experiences and values: “to be is to belong to  
a community and participate” also motho ke 
Ubuntu ethical traditions  
motho ka batho “A person is a person because 
to A/IS design.
of other people.”
Very little research, if any at all, has been 
conducted in light of Ubuntu ethics and A/IS, 
Background
but its focus will be within the following moral 
In his article, “African Ethics and Journalism 
domains:
Ethics: News and Opinion in Light of Ubuntu,” 
Thaddeus Metz frames the following question:  1.  Between the members of the A/IS research 
“What does a sub-Saharan ethic focused on the  community
good of community, interpreted philosophically 
2.  Between the A/IS community/programmers/
as a moral theory, entail for the duties of various 
computer scientists and the end-users
agents with respect to the news/opinion media”? 
(Metz, 2015, 1). When that question is applied  3.  Between the A/IS community/programmers/
to A/IS) viz: “If an ethic focused on the good of  computer scientists and A/IS
community, interpreted philosophically as a moral 
theory, is applied to autonomous and intelligent  4.  Between the end-users and A/IS
systems, what would the implications be on the 
5.  Between A/IS and A/IS
duties of various agents”? Agents in this regard 
would therefore be the following:  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 208The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
Considering a future where A/IS will become  be “how does A/IS affect the community in 
more entrenched in our everyday lives, one must  which it is situated”? This question links with 
keep in mind that an attitude of sharing one’s  the initial question concerning the duties of 
experiences with others and caring for their well- the various moral agents within the specific 
being will be impacted. Also by trying to ensure  community. Motivation becomes very important, 
solidarity within one’s community, one must  because if A/IS seek to detract from community 
identify factors and devices that will form part  it will be detrimental to the identity of this 
of their lifeworld. If so, will the presence of A/IS  community, i.e., in terms of job losses, poverty, 
inhibit the process of partaking in a community,  lack in education and skills training. However, 
or does it create more opportunities for doing   should A/IS seek to supplement the community, 
so? One cannot classify A/IS as only a negative   i.e., ease of access, support systems, etc., then  
or disruptive force; it is here to stay and its  it cannot be argued that it will be detrimental.  
presence will only increase. Ubuntu ethics must  It therefore becomes imperative that whosoever 
come to grips with and contribute to the body   designs the systems must work closely both with 
of knowledge by establishing a platform for  ethicists and the target community/audience/
mutual discussion and understanding. end-user to ascertain whether their needs are 
identified and met.
Such analysis fleshes out the following suggestive 
comments of Desmond Tutu, renowned former 
Candidate Recommendations
chair of South Africa’s Truth and Reconciliation 
Commission, when he says of Africans, “(we say)  •  It is recommended that a concerted effort  
a person is a person through other people...  be made toward the study and publication  
I am human because I belong” (Tutu, 1999).   of literature addressing potential relationships 
I participate, I share. Harmony, friendliness,   between Ubuntu ethical traditions and  
and community are great goods. Social harmony  A/IS value design. 
is for us the summum bonum — the greatest 
•  A/IS designers and programmers must 
good. Anything that subverts or undermines  
work closely with the end-users and target 
this sought-after good is to be avoided (2015:78).
communities to ensure their design aims  
In considering the above, it is fair to state that  are aligned with the needs of the end-users 
community remains central to Ubuntu. In situating   and target communities. 
A/IS within this moral domain, it will have to 
adhere to the principles of community, identity  Further Resources
and solidarity with others. While virtue ethics 
•  Lutz, D. W. “African Ubuntu Philosophy and 
questions the goal or purpose of A/IS and 
Global Management.” Journal of Business 
deontological ethics questions the duties, the 
Ethics 84 (2009): 313–328.
fundamental question asked by Ubuntu would  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 209The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
•  Metz, T. “African Ethics and Journalism Ethics:  unique to technological relationships in world 
News and Opinion in Light of Ubuntu,”  cultures, since the Shinto tradition is arguable the 
Journal of Media Ethics: Exploring Questions  only animistic and naturalistic tradition that can  
of Media Morality 30 no. 2 (2015): 74–90.  be directly connected to contemporary digital 
doi: 10.1080/23736992.2015.1020377 culture and A/IS. From the Shinto perspective,  
the existence of A/IS, whether manifested 
•  Tutu, D. No Future Without Forgiveness. 
through robots or other technological 
London: Rider, 1999.
autonomous systems, is as natural to the  
world as are rivers, forests, and thunderstorms. 
As noted by Spyros G. Tzafestas, author of 
Roboethics: A Navigating Overview, “Japan’s 
harmonious feeling for intelligent machines 
Issue: 
and robots, particularly for humanoid ones,” 
The application of Shinto-
(Tzafestas, 2015, 155) colors and influences 
influenced traditions   technological development in Japan, especially 
to A/IS design. robot culture.
The word Shinto can be traced to two Japanese 
concepts, Shin, meaning spirit, and “to”, the 
Background philosophical path. Along with the modern 
concept of the android, which can be traced 
Alongside the burgeoning African Ubuntu 
back to three sources — one, to its Greek 
reflections on A/IS, other indigenous techno-
etymology that combines “άνδρας”: andras 
ethical reflections boast an extensive engagement.  
(man) and gynoids, “γυνή’’: gyni (woman); 
One such tradition is Japanese Shinto indigenous 
two, via automatons and toys as per U.S. 
spirituality, (or, Kami-no-michi), often cited as the 
patent developers in the 1800s, and three to 
very reason for Japanese robot and autonomous 
Japan, where both historical and technological 
systems culture, a culture more prevalent in 
foundations for android development have 
Japan than anywhere else in the world. Popular 
dominated the market since the 1970s — 
Japanese AI, robot and video-gaming culture 
Japanese Shinto-influenced technology culture  
can be directly connected to indigenous Shinto 
is perhaps the most authentic representation  
tradition, from the existence of kami (spirits) 
of the human-automaton interface.
to puppets and automata. 
Shinto tradition is an animistic religious  
The relationship between A/IS and a human 
tradition, positing that everything is created  
being is a personal relationship in Japanese 
with, and maintains, its own spirit (kami) and  
culture and, one could argue, a very natural 
is animated by that spirit, an idea that goes  
one. The phenomenon of relationship in Japan 
a long way to defining autonomy in robots from  
between humans and automata stands out as 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 210The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
a Japanese viewpoint. This includes on one hand,  Candidate Recommendation
everything that Western culture might deem 
Where Japanese culture leads the way in  
natural, including rivers, trees, and rocks, and 
the synthesis of traditional value systems and 
on the other hand, everything artificially (read: 
technology, we recommend that efforts in 
artfully) created, including vehicles, homes,  
A/IS ethics explore the Shinto paradigm as 
and automata (i.e., robots). Artifacts are as  
representative, though not necessarily as directly 
much a part of nature in Shinto as are animals, 
applicable, to global efforts in understanding 
and are considered naturally beautiful rather  
and applying traditional and classical ethics 
than falsely artificial. 
methodologies to ethics for A/IS. 
A potential conflict between Western concepts 
of nature and artifact and Japanese concepts  Further Resources
of the same arises when the two traditions 
•  Holland-Minkley, D. F. “God in the Machine: 
are compared and contrasted, especially in 
Perceptions and Portrayals of Mechanical 
the exploration of artificial intelligence. Where 
Kami in Japanese Anime.” PhD Diss. 
in Shinto, the artifact as artificial represents 
University of Pittsburgh, 2010.
creation and authentic being (with implications 
for defining autonomy), the same is designated  •  Jensen, C. B., and A. Blok. “Techno-Animism 
as secondary and oft times unnatural, false,  in Japan: Shinto Cosmograms, Actor-Network 
and counterfeit in Western ethical philosophical  Theory, and the Enabling Powers of Non-
tradition, dating back to Platonic and Christian  Human Agencies.” Theory, Culture & Society 
ideas of separation of form and spirit. In both  30, no. 2 (2013): 84–115.
traditions, culturally presumed biases define our 
•  Tzafestas, S. G. Roboethics: A Navigating 
relationships with technology. While disparate 
Overview. Cham, Switzerland: Springer, 2015.
in origin and foundation, both Western classical 
ethics traditions and Shinto ethical influences  
in modern A/IS have similar goals and outlooks 
for ethics in A/IS, goals that are centered  
in relationship. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 211The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
Section 3 — Classical Ethics for  
a Technical World
How will AI and autonomous systems influence 
human autonomy in ways that may or may not 
Issue: 
be advantageous to the good life, and perhaps 
Maintaining human autonomy. even if advantageous, may be detrimental at the 
same time? How do these systems affect human 
autonomy and decision-making through the use 
Background of algorithms when said algorithms tend to inform 
(“in-form”) via targeted feedback loops? 
Autonomous and intelligent systems present  
the possibility for a digitally networked intellectual  Consider, for example, Google’s autocomplete 
capacity that imitates, matches, and supersedes  tool, where algorithms attempt to determine 
human intellectual capacity, including, among  one’s search parameters via the user’s initial 
other things, general skills, discovery, and  keyword input, offering suggestions based on 
computing function. In addition, A/IS can   several criteria including search patterns. In this 
potentially acquire functionality in areas traditionally   scenario, autocomplete suggestions influence,  
captured under the rubric of what we deem  in real-time, the parameters the user phrases 
unique human and social ability. While the larger  their search by, often reforming the user’s 
question of ethics and AI looks at the implications  perceived notions of what it was they were 
of the influence of autonomous systems in   looking for in the first place, versus what they 
these areas, the pertinent issue is the possibility  might have actually originally intended.
of autonomous systems imitating, influencing, 
Targeted algorithms also inform as per emerging 
and then determining the norms of human 
IoT applications that monitor the user’s routines 
autonomy. This is done through the eventual 
and habits in the analog world. Consider for 
negation of independent human thinking and 
example that our bio-information is, or soon will 
decision-making, where algorithms begin to 
be, available for interpretation by autonomous 
inform through targeted feedback loops what it 
systems. What happens when autonomous 
is we are and what it is we should decide. Thus, 
systems can inform the user in ways the user is 
how can the academic rigor of traditional ethics 
not even aware of, using one’s bio-information  
speak to the question of maintaining human 
in targeted advertising campaigns that seek  
autonomy in light of algorithmic decision-making?
to influence the user in real-time feedback loops 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 212The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
based on the user’s biological reactions (pupil  Candidate Recommendation
dilation, body temperature, emotional reaction), 
•  An ethics by design methodology is the first 
whether positive or negative, to that very same 
step to addressing human autonomy in AI, 
advertising, using information about our being  
where a critically applied ethical design of 
to in-form (and re-form) our being?
autonomous systems preemptively considers 
On the other hand, it becomes important not  how and where autonomous systems may  
to adopt dystopian assumptions concerning  or may not dissolve human autonomy. 
autonomous machines threatening human 
•  The second step is a pointed and  
autonomy. The tendency to think only in negative 
widely applied education curriculum  
terms presupposes a case for interactions 
that encompasses school age through 
between autonomous machines and human 
university, one based on a classical ethics  
beings, a presumption not necessarily based  
foundation that focuses on providing  
in evidence. Ultimately the behavior of algorithms 
choice and accountability toward digital  
rests solely in their design, and that design  
being as a priority in information and 
rests solely in the hands of those who designed 
knowledge societies. 
them. Perhaps more importantly, however,  
is the matter of choice in terms of how the user 
Further Resources
chooses to interact with the algorithm. Users 
often don’t know when an algorithm is interacting  •  van den Berg, B. and J. de Mul. “Remote 
with them directly, or their data which acts as   Control. Human Autonomy in the Age of 
a proxy for their identity. The responsibility for  Computer-Mediated Agency,” in:  Autonomic 
the behavior of algorithms remains with both the  Computing and Transformations of Human 
designer and the user and a set of well-designed  Agency. Philosophers of Law Meeting 
guidelines that guarantee the importance of  Philosophers of Technology, edited by  
human autonomy in any interaction. As machine  Mireille Hildebrandt and Antoinette Rouvroy, 
functions become more autonomous and   46–63. London: Routledge, 2011.
begin to operate in a wider range of situations, 
•  Costa, L. “A World of Ambient Intelligence,” 
any notion of those machines working for  
Chapter 1 in Virtuality and Capabilities  
or against human beings becomes contested. 
in a World of Ambient Intelligence, 15–41. 
Does the machine work for someone in 
Cham, Switzerland: Springer International, 
particular, or for particular groups but not for 
2016. 
others, and who decides on the parameters? 
 
The machine itself? Such questions become key 
 
factors in conversations around ethical standards. 
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 213The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
•  Verbeek, P.-P. “Subject to Technology  it places emphasis on habitual, iterative action 
on Autonomic Computing and Human  focused on achieving excellence in a chosen 
Autonomy,” in The Philosophy of Law Meets  domain or in accord with a guiding purpose.  
the Philosophy of Technology: Autonomic  At points on the goal-directed continuum 
Computing and Transformations of Human  associated with greater sophistication, virtue 
Agency, edited by. M. Hildebrandt and   ethics become even more useful by providing  
A. Rouvroy. New York: Routledge, 2011. a framework for prudent decision-making that 
is in keeping with the autonomous system’s 
purpose, but allows for creativity in how to 
achieve the purpose in a way that still allows  
for a degree of predictability. An ethics that 
Issue: 
does not rely on a decision to refrain from 
Applying goal-directed behavior  transgressing, but instead to prudently pursue 
a sense of purpose informed by one’s identity, 
(virtue ethics) to autonomous 
might provide a greater degree of insight into  
and intelligent systems.
the behavior of the system.
Candidate Recommendation
Background
Program autonomous systems to be able to 
Initial concerns regarding A/IS also include 
recognize user behavior as being those of specific 
questions of function, purpose, identity, and 
types of behavior and to hold expectations as  
agency, a continuum of goal-directed behavior, 
an operator and co-collaborator whereby both 
with function being the most primitive expression. 
user and system mutually recognize the decisions 
How can classical ethics act as a regulating force 
of the autonomous system as virtue ethics based. 
in autonomous technologies as goal-directed 
behavior transitions from being externally set by 
Further Resources
operators to being indigenously set? The question 
is important not just for safety reasons, but for  •  Lennox, J. G. “Aristotle on the Biological 
mutual productivity. If autonomous systems are  Roots of Virtue.” Biology and the Foundations 
to be our trusted, creative partners, then we  of Ethics, edited by J. Maienschein and  
need to be confident that we possess mutual  M. Ruse, 405–438. Cambridge, U.K.: 
anticipation of goal-directed action in a wide  Cambridge University Press, 1999.
variety of circumstances.
•  Boden, M. A., ed. The Philosophy of Artificial 
A virtue ethics approach has merits for  Life. Oxford, U.K.: Oxford University Press, 
accomplishing this even without having to posit   1996.
a “character” in an autonomous technology, since 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 214The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
•  Coleman, K. G.. “Android Arete: Toward   in the case of machine ethics, a set of rules  
a Virtue Ethic for Computational Agents.”  is used to determine which actions are morally 
Ethics and Information Technology 3, no. 4  allowable and which are not. Since it is not 
(2001): 247–265. possible to cover every situation by a rule, an 
inference engine is used to deduce new rules 
from a small set of simple rules (called axioms) 
Issue:  by combining them. The morality of a machine 
comprises the set of rules that are deducible 
A requirement for  
from the axioms.
rule-based ethics  
Formal systems have an advantage since 
in practical programming.
properties such as decidability and consistency  
of a system can be effectively examined.  
If a formal system is decidable, every rule 
Background
is either morally allowable or not, and the 
Research in machine ethics focuses on simple  “unknown” is eliminated. If the formal system  
moral machines. It is deontological ethics   is consistent, one can be sure that no two rules 
and teleological ethics that are best suited   can be deduced that contradict each other.  
to the kind of practical programming needed   In other words, the machine never has moral 
for such machines, as these ethical systems   doubt about an action and never encounters  
are abstractable enough to encompass ideas   a deadlock.
of non-human agency, whereas most modern  
The disadvantage of using formal systems is  
ethics approaches are far too human-centered  
that many of them work only in closed worlds  
to properly accommodate the task.
like computer games. In this case, what is not 
In the deontological model, duty is the point   known is assumed to be false. This is in drastic 
of departure. Duty can be translated into rules.   conflict with real world situations, where rules  
It can be distinguished into rules and meta   can conflict and it is impossible to take into 
rules. For example, a rule might take the form  account the totality of the environment. In other 
“Don’t lie!”, whereas a meta rule would take   words, consistent and decidable formal systems 
the form of Kant’s categorical imperative:   that rely on a closed world assumption can  
“Act only according to that maxim whereby   be used to implement an ideal moral framework 
you can, at the same time, will that it should  for a machine, yet they are not viable for real  
become a universal law.” world tasks.
A machine can follow simple rules. Rule-based  One approach to avoiding a closed world  
systems can be implemented as formal systems  scenario is to utilize self-learning algorithms,  
(also referred to as axiomatic systems), and   such as case-based reasoning approaches.  
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 215The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Classical Ethics in A/IS
Here, the machine uses “experience” in the   Candidate Recommendation
form of similar cases that it has encountered  
By applying the classical methodologies of 
in the past or uses cases which are collected  
deontological and teleological ethics to machine 
in databases.
learning, rules-based programming in A/IS  
In the context of the teleological model,   can be supplemented with established praxis, 
the consequences of an action are assessed.  providing both theory and a practicality toward 
The machine must know the consequences of  consistent and decidable formal systems.
an action and what the action’s consequences 
mean for humans, for animals, for things in the  Further Resources
environment, and, finally, for the machine itself. 
•  Bendel, O. Die Moral in der Maschine: 
It also must be able to assess whether these 
Beiträge zu Roboter-und Maschinenethik. 
consequences are good or bad, or if they are 
Heise Medien, 2016.
acceptable or not, and this assessment is not 
absolute: while a decision may be good for   •  Bendel, O. “LADYBIRD: the Animal-Friendly 
one person, it may be bad for another; while   Robot Vacuum Cleaner.” The 2017 AAAI 
it may be good for a group of people or for   Spring Symposium Series. Palo Alto, CA:  
all of humanity, it may be bad for a minority   AAAI Press, 2017.
of people. An implementation approach  
•  Fisher, M., L. Dennis, and M. Webster. 
that allows for the consideration of potentially 
“Verifying Autonomous Systems.” 
contradictory subjective interests may be  
Communications of the ACM 56, no. 9 
realized by decentralized reasoning approaches 
(2013): 84–93.
such as agent-based systems. In contrast to this, 
centralized approaches may be used to assess 
•  McLaren, B. M. “Computational Models of 
the overall consequences for all involved parties. 
Ethical Reasoning: Challenges, Initial Steps, 
 
and Future Directions.” IEEE Intelligent 
 
Systems 21, no. 4 (2006): 29–37.
 
  •  Perez Alvarez, M. A. “Tecnologías de la 
  Mente y Exocerebro o las Mediaciones del 
Aprendizaje,” 2015.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 216The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications 
Technology Committee
Mixed reality could alter our very notions of identity and reality over the next generation, as 
these technologies infiltrate more and more aspects of our lives, from work to education, 
from socializing to commerce. An autonomous and intelligent systems (A/IS) backbone 
that would enable real-time personalization of this illusory world raises a host of ethical and 
philosophical questions, especially as the technology moves from headsets to much more 
subtle and integrated sensory enhancements. This committee has been working to discover 
the methodologies that could provide this future with an ethical skeleton and the assurance 
that the rights of the individual, including control over one’s increasingly multifaceted 
identity, will be reflected in the encoding of this evolving environment. While augmented, 
virtual, and mixed reality deal primarily with technological environments, A/IS technologies 
utilizing and influencing user data in these environments present unique ethical challenges 
society must face today to avoid negative unintended consequences that could harm 
innovation and greatly decrease human well-being tomorrow. 
Our Committee has created the following sections within mixed reality to help address 
these ethical challenges: 
1. Social Interactions
2. Mental Health
3. Education and Training
4. The Arts
5. Privacy Access and Control
It is our hope that by addressing these challenges today, we can create a more positive, 
ethical, and intentional reality, whatever the environment. 
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 217The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Section 1 — Social Interactions
The nature of mediated reality and the ability  use technology to make their lives easier, more 
for individuals to alter their identity (or for their  comfortable, more controllable, safer, and less 
identity to be altered by other actors) means that  disruptive. These tendencies have always existed, 
social interactions will definitely be affected by  but out of the last decade of digital media 
the widespread adoption of mixed reality.  has emerged a rudimentary version of what 
the coming intelligent mixed-reality world will 
probably look like, in terms of the use of personal 
Issue:  data and A/IS to create an environment in which 
the user has actually become the product.
Within the realm of A/IS-
enhanced mixed reality, how   Eli Pariser’s “filter bubble” is the inevitable result 
of consumers’ desire to get what they want 
can we evolve, harness, and  
enabled by an industry that naturally wants to 
not eradicate the positive  
create products that will sell. This effect, however, 
effects of serendipity?
will become qualitatively different and much 
more profound when the curated content goes 
from a window on a laptop to becoming a full-
Background time part of the physical world.
In the real world, bumping into a stranger when  Is an augmented or virtual world an improvement 
your GPS breaks means you may meet your  over the physical world when it can be controlled 
life partner. However, in the digital and virtual  in ways possible only in an illusion? Or does 
spheres, algorithms that have been programmed  it become a denatured place, a software 
by design may eliminate genuine randomness  concoction more inclined toward order and 
from our human experience. What do we stand  predictability than freedom and invention?  
to lose when we code “frictions” or randomness  What would widespread use of such technology 
out of our lives that may cause discomfort, but  have on individuals, society, and politics over  
can also bring joy and growth? the long term? 
For several years now, we have witnessed how  In a physical city, a great deal of life, good and 
online systems automatically sculpt the reality we  bad, is open to randomness, chance, risk, and 
encounter. Two major forces have come together:  the constant threat of encountering behavior one 
the commercial imperative to give customers  would rather not encounter. At the same time, 
what they want, and the desire of customers to  there are unpredictable and often inspirational 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 218The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
experiences that could not happen elsewhere,  Further Resources
and over time can broaden one’s embrace of 
•  Kefalidou, G., and S. Sharples. “Encouraging 
human diversity along all axes. In a gated suburb, 
Serendipity in Research: Designing 
by contrast, these qualities are markedly reduced. 
Technologies to Support Connection-Making,” 
We trade inspiration for control. Qualities are 
International Journal of Human-Computer 
traded off for other qualities.
Studies 89 (2016): 1–23.
Creating the digital version of the gated community 
•  Harford, T. Messy: The Power of Disorder to 
will happen naturally — they are both designed 
Transform Our Lives, New York: Riverhead 
systems. But how can developers create MR/A/IS 
Books, 2016.
experiences that allow users what might be called 
the city option — the ability to live in, for example,  •  Pariser, E. The Filter Bubble: How the New 
a virtual world that somehow mimics the truly  Personalized Web Is Changing What We 
unpredictable aspects many people love about  Read and How We Think. New York: Penguin 
cities? Can such a simulation have the same effect  Books, 2011.
as the “real thing” if there’s no actual risk of serious 
•  Rabin, S., J. Goldblatt, and F. Silva. “Advanced 
unpleasantness? Could the degree of “serendipity” 
Randomness Techniques for Game AI: 
be dialed in by the user? 
Gaussian Randomness, Filtered Randomness, 
and Perlin Noise” in Game AI Pro: Collected 
Candidate Recommendation
Wisdom of Game AI Professionals, edited 
1.  Upon entering any virtual realm, individuals  by S. Rabin,  29–43. Natick, MA: Taylor & 
should be provided information about the  Francis, 2013. 
nature of algorithmic tracking and mediation   
within any environment. This will allow   
not only for consent regarding the use of   
their personal data, but for improved trust   
between individuals and creators of these   
environments regarding user experience. This   
could also include a “serendipity on or off”   
button allowing a user to express their desire   
for randomness as well.   
 
2.  Work with the MR/A/IS development 
 
community to address this challenge and try 
 
to make it a standard part of the conversation 
 
from the very beginning of MR/A/IS-related 
 
project development.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 219The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
their identity. Is the optimal digital representation 
of a person the externally observable physical 
Issue: 
facade, or an illusion better aligned to the 
What happens to cultural  individual’s self-image and identity?
institutions in a mixed reality,  
While the benefits of spending time in alternate 
AI-enabled world of illusion, 
realities could include increasing empathy toward 
where geography is largely  others or discovering aspects of your individuality 
eliminated, tribe-like entities  that could positively affect your identity (in 
either real or virtual reality), there are multiple 
and identities could spring up 
benefits of human interaction, both physical and 
spontaneously, and the notion 
emotional, that could be affected adversely if too 
of identity morphs from physical 
much time is spent within realities of one’s own 
certainty to virtuality? creation. 
Candidate Recommendation
Background
Provide widespread educational classes on the 
When an increasing amount of our lives is  benefit of positive human connection/touch. 
spent in a photorealistic and responsive world  This could involve fields including emotional 
of software, what will happen to actual human  intelligence or positive psychology. 
contact, which might always remain undigitizable 
in meaningful ways? When an illusory world  Further Resources
is vastly more pleasant and fulfilling than the 
•  Fredrickson, B. L. “Your Phone Versus Your 
physical alternative, will there be a significant 
Heart” (Sunday Review). New York Times, 
population who choose to live exclusively, or 
March 23, 2013. 
who spend at least a majority of their time, in 
a synthetic world of their own making? Opting  •  McGonigal, J., and J. Whelan. Reality Is 
in and out will be central to the coming digital  Broken: Why Games Make Us Better and 
experiences; but what happens with the opposite  How They Can Change the World. New York: 
— when people choose to opt-out of the “real”  Penguin Books, 2011.
world in favor of illusion? 
•  Turkle, S. Alone Together: Why We Expect 
MR/A/IS technology could be especially  More from Technology and Less from Each 
meaningful in allowing people to create a physical  Other. New York: Basic Books, 2011.
appearance that more closely reflects who they 
•  Pasqualini, I., J. Llobera, and O. Blanke. 
are. For example, it could help transgender 
“‘Seeing’ and ‘Feeling’ Architecture: How 
persons reconcile their physical appearance with 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 220The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Bodily Self-Consciousness Alters Architectonic  Background
Experience and Affects the Perception of 
The availability of VR and AR could lead to 
Interiors.” Frontiers in Psychology 4, (2013): 
permanent disengagement from society that can 
354. 
have far-reaching implications on fertility rates, 
•  Hershfield, H., D. W. Goldstein, W. Sharpe,  the economy, and alter existing social fabrics. 
J. Fox, L. Yeykelis, L. Carstensen et al.  People may choose to disengage. 
“Increasing Saving Behavior Through Age-
With mixed reality, our notions of time will be 
Progressed Renderings of the Future Self.” 
multi-modal and as such will have a societal 
Journal of Marketing Research 48, no. SPL, 
impact in terms of culture, relationships, and 
(2011): S23–S37. 
perception of the self. We might be able to 
manipulate our perceptions of time and space so 
as to experience, or re-experience, interactions 
Issue:  that would otherwise be impossible. With 
alternative realities in reach, people may inhabit 
With alternative realities at 
them to avoid facing problems they encounter in 
reach, we will have alternative  real life.
ways of behaving individually 
Candidate Recommendation
and collectively, and perceiving 
Research and potentially consider the 
ourselves and the world around 
reconstruction of our social contract as alternative 
us. These new orientations 
mixed societies, including the concept of present 
regarding reality could enhance 
virtual and physical beings that will potentially 
an already observed tendency  emerge from alternative realities. 
toward social reclusiveness 
Further Resources
that detaches many from our 
•  Petkova, V., and Ehrsson, H. (2008). “If 
common reality. Could such  
I Were You: Perceptual Illusion of Body 
a situation lead to an  
Swapping.” PLoS ONE 3, no. 12 (2008): 1–9.
individual opting out of  
•  Rainie, L., and J. Anderson. “The Evolution 
“societal engagements?”  
of Augmented Reality and Virtual Reality.” 
 
December 14, 2008.
 
•  Peck, T., S. Seinfeld, S. Aglioti, and M. Slater. 
 
“Putting Yourself in the Skin of a Black Avatar 
Reduces Implicit Racial Bias.” Consciousness 
and Cognition 22, no. 3 (2013): 779–787. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 221The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Further Resources
Issue:  •  Madary, M., and T. K. Metzinger. “Real 
Virtuality: A Code of Ethical Conduct. 
The way we experience (and 
Recommendations for Good Scientific 
define) physical reality on a daily 
Practice and the Consumers of VR-
basis will soon change.  Technology.” Frontiers in Robotics and AI 3 
(February 19, 2016). 
Background
VR and AR technologies are very popular in China, 
Issue: 
for example, where dedicated experimental 
We may never have to say 
zones are gaining significant traction. VR cafes 
are changing the way we interact with people  goodbye to those who have 
around us and offer experiences that rival  graduated to a newer  
movie theaters, theme parks, and travel. For 
dimension (i.e., death). 
example, VR applications have been introduced 
to attractions’ sites and are used to provide an 
interactive experience for tourists who can better 
acquaint themselves with new environments  Background
and attractions. This also changes the way we 
Whether we will have the ability to keep our 
experience our physical reality on a daily basis. In 
consciousness alive via software or create an 
addition, augmented-reality enhancement over 
avatar copy of ourselves or loved ones, there is 
the next generation will become ubiquitous in 
the very real possibility we will see a person’s  
the physical environment, from our homes to city 
representation after death as we know it. While 
streets, and will inevitably alter our view of what 
the decision to upload one’s consciousness 
constitutes reality or physical certainty.
or represent oneself as an avatar after death 
is a deeply personal one, there are multiple 
Candidate Recommendation legal, societal, and cultural issues to deal with 
(e.g., identity, next of kin) to avoid confusion or 
Create widespread education about how the 
potential manipulation of “living” family members 
nature of mixed reality will affect our social 
and friends. In the future, if one’s consciousness 
interactions to avoid widespread negative  
is still “alive” in some sense and able to engage in 
societal consequences.  
human activities, is that person still legally alive?
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 222The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Candidate Recommendation to use MR might exclude an individual from a 
working environment or from a new connected 
New forms of societal norms around traditional 
socializing platform.
death will need to be created for governments 
(updating forms of identity such as passports,  MR can also be used to disengage from 
etc.) along with cultural mores (sending family  one’s environment. Individuals can choose to 
and friends cards letting them know a certain  go back in time and relive happy memories 
person’s consciousness has transferred from  recorded by MR technology (whether real or 
carbon-based to silicon).  not), go on vacation to a venue miles and years 
away, or immerse themselves in some virtual 
Further Resource  entertainment — all without leaving their chair 
and without interacting with other people. This 
•  Rothblatt, M. Virtually Human: The Promise—
can lead to the disengagement of individuals 
and the Peril—of Digital Immortality. New 
even when in the company of others, as virtual 
York: St, Martin’s Press, 2014. 
interactions can supplement and surpass human 
interaction in the user experience they offer. 
In this way, individuals can “fulfill” their social 
needs without reciprocating those of others. 
Issue:  This artificial “fulfillment” of basic social needs 
through fully immersive technologies might have 
Mixed reality changes the way we 
unpredicted implications on the very fabric of 
interact with society and can also 
society, especially by changing the way humans 
lead to complete disengagement. interact with each other.
Candidate Recommendations
Background
MR content providers should be well aware 
The increasing popularity of VR and AR dedicated  of the ramifications of offering alternative 
zones and their use in public sites in China, for  social interactions that do not require a human 
example, is changing the way individuals interact  counterpart, or severely limit key social cues. 
with each other. Where friends and colleagues 
would previously emphasize eye contact and  Further Resource
physical proximity as a way of establishing trust 
•  Kim, M. “The Good and the Bad of Escaping 
and a sense of cohesion, MR will change the way 
to Virtual Reality.” The Atlantic, February 18, 
we perceive the people we interact with. They 
2015.
may be judged based on their avatars, their ability 
to navigate this new reality, and their willingness 
to interact via MR. The inability or choice whether 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 223The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Issue:  Issue: 
A/IS, artificial consciousness,   An MR/A/IS environment could 
and augmented/mixed reality  fail to take into account the 
has the potential to create a  neurodiversity of the population.
parallel set of social norms.
Background
Background
Different brains process information differently, 
Mixed reality poses the potential to redefine and 
and MR/A/IS design assumptions could 
reset many human social norms. Traditionally 
potentially limit the value of MR/A/IS experiences 
human norms have been established by 
for many potential users. At the same time, 
influences such as religion, politics, and 
an MR/A/IS environment that accommodated 
economics, to name a few. The interactions 
neurodiversity could be a tool of immense 
between people and augmented/mixed reality 
potential good. Different people learn differently, 
could generate an entirely different set of 
and a neurodiversity-aware MR/A/IS could 
norms created entirely by the designer of the 
adapt itself for each individual’s strengths and 
mixed reality. There is likely to be opportunity to 
preferences. Different brains might well want to 
positively influence and enhance new norms via 
augment the world differently — for example, 
augmented/mixed reality if given a predictable 
augmentation for emotional cueing of autistic 
environment to operate within and potential 
persons. In addition, such an environment would 
positive psychology impacts and overall wellness. 
offer the opportunity to learn from the ways that 
Recommendations others experience the world due to different 
cognitive architectures.
Those who create augmented/mixed reality 
experiences need to clearly define the purpose of 
Candidate Recommendations
the designed reality. Users who interact with this 
reality should specifically “opt in” to agree to their  Work with MR/A/IS developers to build 
immersion in the reality. And during the delivery  neurodiversity sensitivity into the creation of 
of the experience, the reality and reactions of  intelligent experiences and hardware.
those interacting need to be auditable against the 
initial agreed purpose. 
Further Resource
Further Resource •  Metzinger, T., and E. Hildt. Cognitive 
Enhancement. The Oxford Handbook of 
•  Wassom, B. Augmented Reality Law, Privacy, 
Neuroethics. Oxford, U.K.: Oxford University 
and Ethics: Law, Society, and Emerging 
Press, 2011.
AR Technologies. Waltham, MA: Syngress/
Elsevier, 2015.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 224The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Section 2 — Mental Health
While there are proven benefits for creating  of giving over one’s senses to 
empathy in users or treating PTSD for soldiers  software? Moreover, what are 
while utilizing mixed, virtual, or augmented reality, 
the implications for the ethical 
there are also potential negative unintended 
development and use of MR 
consequences via loss of agency, consent, or 
confusion about one’s place in one’s world(s)  applications designed for mental 
depending on how these tools are used in  health assessment and treatment 
regards to a person suffering from mental health 
in view of the potential potency 
issues, or for any individual unused to these 
of this media format compared 
environments. 
to traditional methodologies?
Issue: 
Background
How can AI-enhanced mixed 
reality explore the connections  AI-enhanced MR will generate a range of powerful 
applications in healthcare over the next generation, 
between the physical and the 
from improving medical and surgical outcomes, 
psychological, the body and 
to virtual physicians, to performance visualization 
mind for therapeutic and other  for athletes. Compelling ultra-high-fidelity systems 
purposes? What are the risks for  could exploit the brain’s neuroplasticity for a variety 
of beneficial (and non-beneficial) ends, including 
when an AI-based mixed-reality 
present-day treatment of PTSD and anxiety 
system presents stimuli that 
disorders using VR.
a user can interact with in an 
Being in a completely mediated VR environment 
embodied, experiential activity? 
could, for example, fool the mind into thinking 
Can such MR experiences 
and feeling as it did in an earlier stage of 
influence and/or control the 
one’s life, with measurable physiological 
senses or the mind in a fashion  effects. Psychological conditions often have 
that is detrimental and enduring?  accompanying physical ailments that diminish 
or disappear when the psychological condition 
What are the short- and long-
is treated. While the positive impact of MR for 
term effects and implications 
changing cognition, emotions, and behavior is 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 225The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
often talked about as having therapeutic value. If  Creating awareness over who controls what in 
one accepts that premise, one has to also accept  connected systems is critical. Even calling these 
that such changes can occur that have less- new forms of fiction a series of “realities” blurs 
desirable consequences. the line unnecessarily. The idea that there is 
anything human-authored that is “non-fiction” 
The converse is true as well. Treating physical 
is something that needs to be explored on 
systems often improves mental states. With 
a cultural level, or in these ultra-high-fidelity 
human augmentation, the physiological and 
systems “truth” will be dictated by an increasingly 
psychological can both be automatically 
homogeneous and concentrated few. Even if 
manipulated or adjusted based on either 
these systems are personalized at scale by A/IS, 
human- or machine-mandated and -controlled 
fundamental awareness and control need to be 
parameters. In addition to external sensory input, 
vested with an individual.
we need to consider internal input (implanted 
devices) which deliver information to senses as  Questions still need to be answered regarding 
well as deliver medication (or nutrition) based  the use of MR as a tool for mental health 
upon monitoring emotional or physical states. diagnosis and treatment. Thus far, significant 
literature has emerged indicating positive impact 
How can mixed reality (MR) be used 
on mental health and physical functioning using 
constructively to engage the mind to such 
theoretically-informed MR applications with 
an extent that physiological mechanisms can 
well-designed content delivered within the more 
be controllably affected, and what are the 
controlled (and safe) context of the therapy 
ethical implications? We don’t have a complete 
setting, administered and supervised by a well-
understanding of what a human requires to be 
trained clinician. However, what happens if these 
happy and healthy. Does this require interaction 
types of VR experiences become commodity 
with the physical world? Or can generated 
products that are readily accessible to anyone, 
experiences be an outlet for those that struggle 
who might self-diagnose their clinical condition 
in the real world? Should we always approach 
and use MR treatment content as “self-help” 
a user’s interaction with a system to help them 
therapy? While some might say this is not much 
work on real-world problems, or is it okay to let 
different from purchasing a self-help book and 
them get lost in the generated world? 
following the instructions and recommendations 
therein, MR experiences may have a deeper 
A VR system could radically affect how the mind 
impact on a user than reading a book. Similar to 
processes and synthesizes information, and 
most areas of mental health care, there is a risk 
ultimately it could be a way to teach ourselves 
that this form of self-diagnosis and treatment 
new ways to think and create content. However, 
is based on inaccurate or counterproductive 
the long-term effects of immersion are largely 
information. Another kind of problem may 
unknown at this point, and the exploitability of 
emerge if a clinician decides that MR would be 
a person’s (or a larger group’s) notion of reality 
great for generating a buzz for their practice and 
raises a host of ethical issues.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 226The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
result in more business, but hasn’t had training  documented with some level of research 
in its use and safe application. Thus, there are  before they can be endorsed as evidence-
issues of concern here from both the patient and  based and promoted to a patient in that 
provider side of the equation. Consequently, we  fashion. In an emerging area like MR, where 
need ethical guidelines for the safe and informed  unique and specific guidelines have yet to 
use of clinical MR applications, much like the way  be established, the practitioner must be fully 
that pharmaceutical treatments are managed by a  transparent about the evidence base for the 
well-trained and qualified physician. approach and take precautions to preserve 
the safety and integrity of the patient.
Candidate Recommendation
2.  “2.01 Boundaries of Competence  
Research conducted by qualified mental health  (a) Psychologists provide services, teach 
experts is required in this area to determine how  and conduct research with populations and 
people can best approach immersion in new  in areas only within the boundaries of their 
realities in ways they can control or mediate  competence, based on their education, 
should potential negative or triggering situations  training, supervised experience, consultation, 
take place.  study or professional experience.” 
This one is obvious. MR-delivered mental 
In the area of clinical practice the American 
health assessment and treatment may 
Psychological Association’s ethical code 
require fundamentally different skill sets 
provides a clear and well-endorsed set of 
than what is needed for traditional “talk 
guidelines that can serve as good starting point 
therapy” approaches. Clinicians need to 
for understanding and proactively addressing 
have specialized training, and possibly in the 
some of the issues for the creation and use 
future, some level of certification in the safe 
of MR applications (see: www.apa.org/ethics/
and ethical use of MR for therapy.
code/#201e). Three core areas of concerns and 
recommendations can be derived from these  3.  While not cited as an APA standard, the 
guidelines (two from the APA code and one  issues regarding patient self-diagnosis 
regarding patient self-help decision-making): and self-treatment deserves further 
mention. Mental health conditions can be 
1.  “2.04 Bases for Scientific and 
extremely complex and in some instances 
Professional Judgments  
the self-awareness of the patient may be 
Psychologists’ work is based upon 
compromised. This can oftentimes lead to a 
established scientific and professional 
faulty self-diagnosis as well as the problems 
knowledge of the discipline.” 
that arise when the patient searches for 
MR applications that are developed for 
information via the Internet, where reliable 
clinical assessment and treatment must be 
and valid content can be questionable. 
based on some theoretical framework and 
The same issues come into play with self-
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 227The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
treatment. The problems that can ensue   serve to create the general impression that MR 
are two-fold. is a “snake oil” approach and lead to people not 
seeking (or benefiting from) an otherwise well-
•  The patient makes errors in either or 
validated MR approach.
both areas and achieves no clinical 
benefit, or worse, aggravates the  An example of a “grey area” in this domain 
existing condition with an ineffective or  concerns one of the most common fears that 
inappropriate MR approach that actually  people report — public speaking. Technically, in 
does more harm than good. an extreme form where it significantly impairs 
social and occupational functioning, public 
•  By pursuing a “seductive” MR self-
speaking anxiety would qualify as a phobia and 
help approach that is misaligned with 
be diagnosed as an anxiety disorder. However, 
their actual needs or has no evidence 
since people have some level of sub-clinical fear 
for its efficacy, the patient could miss 
of public speaking that they eventually get over 
the opportunity to actually receive 
with practice, this has been one of the first areas 
quality evidence-based care that is 
where widespread consumer access to public 
designed and delivered based on the 
speaking VR exposure therapy software has 
informed judgment of a trained expert 
occurred . Users can practice their presentation 
diagnostician or clinical care provider.
“skills” on a low-cost mobile phone driven VR 
HMD (cardboard, Gear VR, Daydream, etc.) in 
These two negative impacts could occur if a 
front of various types of audiences and settings. 
company produces an MR approach without 
In this case, most clinicians would not show 
sufficient validation and over-promotes or 
much concern for this type of self-help approach, 
markets it to the public as a test or a cure. This 
and the potential for damaging effects to a 
has been seen over the years with many forms of 
user appears to be fairly minimal. But, from this 
pseudo medicine, and there needs to be some 
example, can we now expect that applications 
principle about the promotion of a MR application 
will be made readily available for other and 
that has the consumers’ protection in mind. 
perhaps more complex anxiety-disorder-based 
This issue is particularly important at the current 
phobias (fear of flying, social phobia, driving, 
time, in view of all the public exposure, hype, 
spiders, intimacy, etc.), or even for PTSD 
and genuine excitement surrounding AR/VR/
treatment?
MR. One can observe new companies emerging 
in the healthcare space without any credible 
From this, general guidelines for the creation, 
expert clinical and/or research guidance. Such 
distribution, practice methods, and training 
companies could not only do harm to users, but 
requirements should be established for the 
the uninformed development and over-hype of 
clinical application of MR for persons with mental 
the benefits to be derived from a MR clinical 
health conditions.
application leading to negative effects could 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 228The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Further Resources Background
•  Rizzo, A., M. Schultheis, and B. Rothbaum.  We do not have a complete understanding of 
“Ethical Issues for the Use of Virtual Reality in  what a human requires to be happy and healthy. 
the Psychological Sciences” in Ethical Issues  Do we require interaction with the physical 
in Clinical Neuropsychology, edited by S. S.  world? Or can generated experiences be an 
Bush, and M. L. Drexler. Lisse, NL: Swets &  outlet for those who struggle in the real world? 
Zeitlinger Publishers, 2002.  Should we always approach a user’s interaction 
with a system to help them work on real-world 
•  Wiederhold, B. K., and M. D. Wiederhold. 
problems, or is it okay to let them get lost in the 
Virtual Reality Therapy for Anxiety Disorders: 
generated world? Some negative examples to 
Advances in Evaluation and Treatment. 
consider along these lines: 
Washington, DC: American Psychological 
Association, 2005.  1.  Immersion and escapism could become a 
problem for people who tend to withdraw 
•  Botella, C., B. Serrano, R. Baños, and A. 
into themselves, become antisocial, and want 
Garcia-Palacios. “Virtual Reality Exposure-
to avoid the real world. This might have to 
Based Therapy for the Treatment of 
be dealt with differently depending on what 
Post-Traumatic Stress Disorder: A Review 
the withdrawal is based on — anxiety, abuse, 
of Its Efficacy, the Adequacy of the 
depression, etc. 
Treatment Protocol, and Its Acceptability.” 
Neuropsychiatric Disease and Treatment 11,  2.  There will more than likely be issues similar 
(2015): 2533–2545.  to the kind of video-game addictions we see 
now. 
Some positive examples to consider along these 
Issue: 
lines: 
Mixed reality creates 
1.  AR/VR environments could be used as 
opportunities for generated 
outlets for people who may damage 
experiences and high levels of 
themselves, others, or objects in the physical 
user control that may lead certain  world. 
individuals to choose virtual life 
2.  AR/VR environments could offer a soothing 
over the physical world. What  
atmosphere for disabled children and adults. 
are the clinical implications?  For example, they could offer experiences 
  similar to “stimming” and have relaxing 
music, noises, etc. 
3.  There could be an increase of AR/VR 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 229The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
therapists and counselors. AR/VR-based  Candidate Recommendation
meditations and mindfulness may also begin 
While being conscious to help people avoid 
to proliferate. This could take the form of 
withdrawal from society where the lack of human 
projecting therapists and patients who are 
interaction could increase negative mental health, 
far apart into the same VR space, projecting 
it is important for widespread testing of these 
multiple people into the same VR space for 
systems to let these new realities (MR/AR/VR) 
meetings, such as Alcoholics Anonymous, 
be a tool for exploring interactions to increase 
etc. These methods could be used to help 
positive mental health and well-being. 
people who may not be able to leave the 
home. (For example, therapists have held 
Further Resource
autism group-counseling sessions inside of 
Second Life, reporting that group members  •  O’Brolcháin, F., T. Jacquemard, D. Monaghan, 
did better expressing themselves when they  N. O’Connor, P. Novitzky, and B. Gordijn. “The 
had an avatar with which to participate.)   Convergence of Virtual Reality and Social 
Networks: Threats to Privacy and Autonomy.” 
Science Engineering Ethics 22, no. 1 (2016): 
1–29. 
 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 230The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Section 3 — Education and Training
There is value in using immersive technologies in  AR/VR/MR will play a large part in these 
education and training. That which is experiential  solutions, but the art of good immersive 
can provide sustainable training in the long-term.  interfaces and experiences remains largely 
Will all senses be stimulated within an immersive  elusive. We currently are in a state where adding 
learning environment? AR/VR could be valuable  more data and more sensors is often seen as the 
in K-12 classrooms for immersion and interactivity  solution, and yet this does not address the core 
with subject material at all different age levels. In  issues of how to increase human performance 
addition, mixed reality could be one key element  given these information increases. 
to lifelong learning and the ability to adapt to 
changing job markets. Candidate Recommendation
Two areas need to be considered. First is 
development of the technological capabilities. 
Issue: 
Human factors need to be front-and-center 
How can we protect worker  throughout the design and testing process, 
rights and mental well-being  particularly with regard not only to efficacy of 
the task execution, but also possible deleterious 
with the onset of automation-
effects on the human, both physical and 
oriented, immersive systems? 
psychological. The second area is implementation 
and deep consideration of the user base. Age, 
psychological state, and other demographic data 
Background should be considered for use cases, backed by 
research rather than ad hoc determinations.
In many workplace environments, humans are 
sharing spaces and tasks with automated systems 
(e.g., robots and/or A/IS algorithms). As these  Further Resource 
relationships increase, there will be increased 
•  Madary, M., and T. K. Metzinger. “Real 
pressure on humans to effectively “team” with 
Virtuality: A Code of Ethical Conduct. 
these systems. There are myriad issues entangled 
Recommendations for Good Scientific 
in human-machine teaming including A/IS design 
Practice and the Consumers of VR-
(how do you enable trust?), human-system 
Technology.” Frontiers in Robotics  
interface (command and control), and enabling 
and AI 3 (February 19, 2016). 
better situational awareness (sensing and 
understanding). 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 231The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
will track emerging technology implementations 
around telepresence and remote collaboration, 
Issue: 
and create test-bed integrations of emerging 
AR/VR/MR in training/operations  tech, prototyping the “art of the possible,” and 
can be an effective learning  enabling user studies such that a technologist can 
evaluate, assess, and provide insight into promise 
tool, but will alter workplace 
and pitfalls over the near horizon.
relationships and the nature  
of work in general. 
Further Resource
•  Pellerin, C. “Work: Human-Machine Teaming 
Represents Defense Technology Future.” DoD 
Background
News, Defense Media Activity, Washington, 
AR/VR/MR is already having an impact in training,  DC: Department of Defense, 2015.  
operations, and production. The capabilities of 
just-in-time knowledge, coaching, and monitoring 
suggests the promise of increased safety and 
productivity. But how will these technologies 
Issue: 
change the workplace, alter career trajectories, 
and impact and influence what, how, and why we  How can we keep the safety and 
educate people? development of children and 
minors in mind? 
In addition, the definition of “workplace” 
will radically change. Remote operation and 
increased telepresence capabilities, combined 
with interactive A/IS enabling “always available”  Background
expertise, make the likelihood high of 
AR/VR may be valuable in K-12 classrooms for 
collaborative workspaces that are entirely virtual 
immersion and interactivity with subject material 
and not necessarily synchronous. While there 
at all different age levels. AR can be used to 
are potential advantages (decreased traffic and 
interact with shapes, objects, artifacts, models 
energy consumption), there will no doubt be 
of molecules, etc. in a space, while VR can be 
second- and third-order effects that lead to 
used to explore historical environments, role-
negative outcomes.
play in a story or time period, or create a virtual 
whiteboard space for students to collaborate 
Candidate Recommendation and interact in. How can being immersed in a 
Create a task force and living laboratory that  different reality interfere with development and 
focuses on the “workplace of the future.” This lab  perception of reality by younger students who 
may not be able to completely differentiate 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 232The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
between reality and virtual reality? Would 
escapism and immersion be a problem, for 
Issue: 
example, in mentally ill or unstable teenagers 
who want an escape? How can we protect the  Mixed reality will usher  
identity and information of minors, especially if  in a new phase of specialized  
virtual experiences might be connected to the 
job automation.
Internet? 
Candidate Recommendation
Background
Augment the Consumer Products Safety 
VR and AR also give rise to a new level of 
Commission (or equivalent) to include policy/
automation, where specialized content and 
governance over mixed reality products. 
services, like piano lessons, personalized 
Determine appropriate age restrictions and 
assistance and support, or even tourism guidance 
guidelines based on proper research protocols 
could be consumed at any given time and place. 
and results.
This will bring better customized services into our 
lives at a lower cost and higher availability. It is 
Further Resource
also, however, likely to negatively impact a broad 
•  Steinicke, F., and G. Bruder. “A Self- class of jobs.
Experimentation Report About Long-Term 
Use of Fully-Immersive Technology,”  Candidate Recommendation
Proceedings of the 2nd ACM Symposium on 
Governments are advised to keep close watch 
Spatial User Interaction, (2014): 66–69. 
over the automation of personalized services 
through mixed-reality technology and offer 
alternative education and training to professionals 
in fields that are expected to be affected. 
Further Resource
•  Stanford University. “Artificial Intelligence and 
Life in 2030: One Hundred Year Study on 
Artificial Intelligence.” Stanford, CA: Stanford 
University, 2016.      
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 233The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
human labor, and no doubt policy will need to be 
crafted to enable agility in the workforce along 
Issue: 
with models for how humans work and thrive in 
A combination of mixed reality  increasingly virtual environments populated by 
and A/IS will inevitably replace  artificial agents.
many current jobs. How will 
Candidate Recommendation
governments adapt policy, and 
how will society change both  Create a working group to look at industries and 
job areas most likely to be replaced or heavily 
expectations and the nature  
augmented by a combination of mixed reality and 
of education and training?
AI/IoT. Similarly, the group would work to predict 
near-term and longer-term job needs and growth 
areas. Look to leverage the existing community 
Background college system as a platform for “21st century 
trades,” enabling rapid acquisition of necessary 
It is clear that many current tasks in society 
skills along with ongoing training.
will move from human-actuated to being 
accomplished by machine and/or algorithm. The 
Industrial Revolution gives an historical taste of  Further Resources
this type of change, but given the depth and 
•  Nutting, R. “No, ‘Truck Driver’ Isn’t the Most 
breadth of digital penetration into human life, it 
Common Job in Your State.” MarketWatch, 
will be an even more profound sea change. There 
February 12, 2015.  
are two main areas of immediate concern. First 
is for the population — essentially, “what will I do  •  Stanford University. “Artificial Intelligence and 
for a living?” Educational and training missions  Life in 2030: One Hundred Year Study on 
will need rethinking, and infrastructure will need  Artificial Intelligence.” Stanford, CA: Stanford 
to be created or leveraged to enable rapid career  University, 2016. 
changes and skill acquisition.
•  Stern, A. Raising the Floor: How a Universal 
Second, government will need to consider the  Basic Income Can Renew Our Economy and 
societal ramifications of automation replacing  Rebuild the American Dream. New York: 
PublicAffairs 2016.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 234The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Section 4 — The Arts
Throughout history, the arts have been a  With specific regard to AR, how will the digital 
means for human expression and often healthy  public landscape not simply be absorbed 
escapism, as well as for social and political  by private commercial interests, but allow 
commentary. The imminent arrival of culturally  virtual space for citizens and artists to freely 
pervasive mixed-reality technologies has the  participate? Will artistic content be algorithmically 
potential to dramatically impact and permanently  subordinated to commercial content? 
alter the methods and tools by which artists earn 
their living. With this in mind, how can humanity  Candidate Recommendation
best approach the interdisciplinary and cross-
Provide users/citizens the option to always “opt 
cultural impacts that the new AR/VR artistic 
out” of any immersive environment to which 
paradigms will offer?
they may be exposed and provide transparency 
and consent options to make this possible. 
This transparency could include not only the 
constituent algorithms, but also information about 
Issue: 
the identity of private actors behind the data.
There is the possibility of 
commercial actors to create 
pervasive AR/VR environments  Issue: 
that will be prioritized in user’s 
There is the possibility that AR/
eyes/vision/experience. 
VR realities could copy/emulate/
hijack creative authorship and 
intellectual and creative property 
Background
with regard to both human  
In the near future, users will filter their digital 
and/or AI-created works.
landscapes by opting in or opting out of mixed-
reality information-delivery mechanisms driven 
by A/IS frameworks that will both structure and,  Background
in many cases, alter or curate the data for private, 
There exists the possibility for certain types of art 
opaque ends.  
forms or certain creative ideas when expressed 
in this new modality to be algorithmically 
suppressed. How can we make sure there is even 
distribution and access to ideas?
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 235The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Mixed reality presents unique opportunities for  virtual environments that reflect original rights or 
developers, artists, and story-tellers to both build  ownership to validate, recognize, and remunerate 
upon and challenge existing modes of content  artists for original work. In addition to research, 
creation, while helping to forge original tools  new forms of copyright will surely need to be 
and methodologies in the realization of new  conceived and codified that are more appropriate 
artistic media. Virtual reality (VR) and 360 video  for the highly collaborative, inter-media, and 
borrow narrative and artistic techniques from  virtual environments within which many of these 
their gaming, theater, cinema and architecture  mixed reality works will be created.
antecedents; however, these media also present 
new occasions for developers to fashion novel  Further Resources
modes of editing, point of view (POV), and sound 
•  Cartiere C., and M. Zebracki, eds., The 
(for example). 
Everyday Practice of Public Art: Art, Space, 
Using many of the same creative tools, AR  and Social Inclusion. New York: Routledge, 
provides a way to use public spaces as a canvas  2016.
for meaningful cultural exchange and, in doing 
•  Geroimenko, V. Augmented Reality Art: From 
so, affords the user a fresh way of seeing such 
an Emerging Technology to a Novel Creative 
spaces as a more open and democratic media 
Medium. Cham, Switzerland: Springer, 2014.
environment. The creative community writ large 
can leverage AR as an instrument of new media 
•  Foucault, M. “Space, Knowledge and Power,” 
content creation, public media production, and 
in The Foucault Reader edited by P. Rabinow. 
artistic expression, which could result in a freer, 
Harmondsworth, U.K.: Penguin, 1984.
more effective use of public space, as well as 
a more imaginative exchange of ideas between  •  Baudrillard, J. Simulacra et Simulation. 
citizens. Finally, A/IS frameworks used to  Translated by P. Foss, P. Patton, and P. 
generate artworks are becoming more accessible,  Beitchman. New York: Semiotext(e), 1983.
which raises questions of the role of the human 
•  Morey, S., and J. Tinnell, eds. Augmented 
artist and ethical issues of authorship and creative 
Reality: Innovative Perspectives across Art, 
rights. The philosophical debate around the 
Industry, and Academia. Anderson, SC: Parlor 
concepts “author” and “artist” with regard to 
Press, 2016.
created works is not a new one in the humanities 
or the legal world. However, these concepts take  •  Lanier, J. Dawn of the New Everything: 
on entirely new dimensions when infusing the  Encounters with Reality and Virtual Reality, 
discussion with the role of a non-human actor in  New York: Henry Holt, and Co., 2017.
the creative process.
•  Grau, O. Virtual Art: From Illusion to 
Immersion, Cambridge, MA: The MIT Press, 
Candidate Recommendation
2003.
Research methods to allow new forms of creative 
copyright to be embedded within physical and 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 236The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Section 5 — Privacy Access and Control 
While concerns over personal data access abound  Ubiquitous recording will challenge expectations 
within existing Internet or IoT environments, the  of privacy both in public and private spaces. 
nature of the imminent pervasive and immersive  Excessive storage and data logging will inevitably 
landscapes of mixed reality provides unique new  create a target for law enforcement (think the 
challenges regarding the nature of user identity  Alexa case). The personalized consumption of 
and control.  controversial immersive content could pose 
challenges for effective public oversight and 
erode the distinction between what is real 
Issue:  and what is permissible. The ability of A/IS 
paired with AR to match disparate data sets will 
Data collection and control issues 
challenge a bystander’s ability to control her/his 
within mixed realities combined 
public image. 
with A/IS present multiple ethical 
This also prompts the question of data 
and legal challenges that ought 
ownership, access, and control in VR and AR.  
to be addressed before these 
If users divulge personal or identifying data, we 
realities pervade society.  should have clear assurances that their virtual 
and physical identities can and will be protected 
within such virtual worlds. This also applies to 
accidental collection of data by VR systems to 
Background
better customize the technology. It is important 
AR’s and VR’s potential for persistent, ubiquitous 
to question the level of control we have over our 
recording could undermine the reasonable 
data and privacy when integrating these pervasive 
expectation of privacy that undergirds privacy-
technologies into our lives.
law doctrine as expressed in constitutional law, 
tort, and statute (Roesner et al., 2014). Like other  Further, mixed-reality applications must be 
emerging technologies, it may force society to  secured against tampering. As technology 
rethink notions of privacy in public. Furthermore,  mediates the way users view their surroundings, 
the mobility of AR devices in particular  cybersecurity is vital to ensure that only they can 
exacerbates challenges to privacy in private  see the information on their displays. Unsecured 
spaces, such as the home, that have traditionally  applications not only leave data vulnerable,  
been subject to the strongest privacy protections.  but create the possibility of digital assault  
or false light.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 237The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
Also, as AR platforms become the gateway to  Further Resource
certain pieces of information, developers should 
•  Stanford University. “Artificial Intelligence and 
consider the discriminatory effects of placing 
Life in 2030: One Hundred Year Study on 
information behind that gateway — especially 
Artificial Intelligence.” Stanford, CA: Stanford 
since the display of incomplete information is a 
University, 2016.
form of misuse that can lead to discrimination. If 
some vital piece of information is only available 
via AR, or only available to a particular AR 
Issue: 
sandbox, some people will inevitably be locked 
out of that information (of course, this criticism  Like other emerging 
could apply to any communications technology,  technologies, AR/VR will force 
so the solution may be opportunities for public 
society to rethink notions of 
access [e.g., libraries] rather than design).
privacy in public and may 
Consider a mixed-reality scenario in which a user  require new laws or regulations 
“sees” a photorealistic avatar commit a crime 
regarding data ownership in 
(a real crime, whether in simulation or not) but 
these environments. 
the avatar depicts (is cloaked) as an altogether 
different person (or persons) than the person 
who is “seen” by third-party witnesses. In that 
case, only an identity-management system  Background
will know who the true perpetrator was. What 
If a user has a specific interaction with mixed-
will happen under such circumstances to the 
reality avatars, can and should this particular 
1) perpetrators of the crime (what constitutes 
storyline development become proprietary? If 
probable cause and reasonable search?) and 
users divulge personal or identifying data, we 
2) what happens to the person whose identity 
should have clear assurances that their virtual 
was “falsely used” within mixed reality? What if 
and physical identities can and will be protected 
a person is falsely accused because immersed 
within such virtual worlds. This also applies to 
witnesses have “seen” them commit a crime? 
accidental collection of data by VR systems to 
What access to identity-management software 
better customize the technology. It is important 
does each of these constituencies have?
to question the level of control we have over our 
data and privacy when integrating these pervasive 
Candidate Recommendation technologies into our lives.
Further research is required in assessing the 
Facial recognition and other machine learning 
implications of data collection, A/IS, and mixed 
applications that can match disparate data sets 
reality to include benefits and definition of 
will hamper people’s ability to control their own 
boundaries.
image. For example, an AR application that 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 238The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Mixed Reality in Information and Communications Technology Committee
matches publicly available information with facial 
recognition will strip bystanders of anonymity 
Issue: 
without their consent (Denning, Dehlawi, and 
Kohno 2014). Users of AI-informed mixed-
reality systems need to 
The development of specialized content for VR 
understand the known effects 
— e.g., violent shooting games, highly sexualized 
or illicit content — limits public oversight of  and consequences of using those 
controversial content consumption. Considering  systems in order to trust them.
AR provides a high level of immersion, mixed 
reality will challenge established policy and social 
Background
norms around privacy and data control. 
Trust will be essential to the widespread adoption 
of A/IS that pervades our lives and helps make 
Candidate Recommendation
increasingly crucial decisions. With black boxes 
Further research is needed on data-control 
playing influential roles, trust will be difficult to 
issues and an A/IS or mixed-reality “guardian” or 
earn. Openness and transparency could be ideal 
“agent” will be required to identify any potentially 
principles to guide the development of intelligent 
negative environments or issues within those 
mixed reality in a way that would alleviate much 
environments based on an individual’s preset 
understandable wariness. Trust is a factor in 
requirements regarding data and identity issues. 
not only the corporate use of personal data, 
Including the potential role of blockchain may  
but also in A/IS algorithms and the increasingly 
be part of this study. Further, it is incumbent 
compelling mixed-reality illusions superimposed 
upon technologists to educate the public on  
on the physical world. In a world where one’s 
the benefits and potential for abuse of A/IS  
very perception has been delegated to software, 
and mixed reality. 
unprecedented levels of trust in systems  
and data — and openness and transparency —  
Further Resources will be needed to ensure the technology’s 
responsible progress.
•  IEEE P7006™, Standard for Personal Data 
Artificial Intelligence (AI) Agent. 
Candidate Recommendations
•  Stanford University. “Artificial Intelligence and 
Establish a new kind of user guide for MR/A/
Life in 2030: One Hundred Year Study on 
IS focused on transparency and end-user 
Artificial Intelligence.” Stanford, CA: Stanford 
understanding of the constituent components. 
University, 2016.
Users should be able to understand the systems 
and their logic if they are going to opt-in in an 
informed manner. Perhaps there is a place for 
a neutral, trusted, and independent third party 
to evaluate MR/A/IS products and experiences 
along these lines.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 239The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Prioritizing ethical and responsible artificial intelligence has become a widespread goal for 
society. Important issues of transparency, accountability, algorithmic bias, and others are 
being directly addressed in the design and implementation of autonomous and intelligent 
systems (A/IS). While this is an encouraging trend, a key question still facing technologists, 
manufacturers, and policy makers alike is, what should be the specific metrics of societal 
success for “ethical AI” once it’s being used? 
For A/IS to demonstrably advance the well-being of humanity, there needs to be concise 
and useful indicators to measure those advancements. However, there is not a common 
understanding of what well-being indicators are, or which ones are available. Technologists 
will use best-practice metrics available even if, unbeknownst to them, said metrics are 
inappropriate or, worse, potentially harmful. To avoid unintended negative consequences 
and to increase value for users and society, clear guidance on what well-being is and how  
it should be measured is needed.
Common metrics of success include profit, gross domestic product (GDP), consumption 
levels, occupational safety, and economic growth. While important, these metrics fail to 
encompass the full spectrum of well-being for individuals or society. Psychological, social, 
and environmental factors matter. Where these factors are not given equal priority to fiscal 
metrics of success, technologists risk causing or contributing to negative and irreversible 
harms to our planet and population. 
This document identifies examples of existing well-being metrics that capture such  
factors, allowing the benefits of A/IS to be more comprehensively evaluated. While these 
indicators vary in their scope and use, they expand the focus of impact to aspects of  
human well-being that are not currently measured in the realms of A/IS. 
When properly utilized, these metrics could provide an opportunity to test and monitor  
A/IS for unintended negative consequences that could diminish human well-being. 
Conversely, these metrics could help identify where A/IS would increase human well-being, 
providing new routes to societal and technological innovation. By corollary, A/IS can also 
increase the measurement and efficiency of well-being indicators. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 240The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
This Committee, along with the IEEE P7010™ Standard Working Group, Well-being Metrics 
Standard for Ethical Artificial Intelligence and Autonomous Systems, was created with the 
belief that A/IS should prioritize human well-being as an outcome in all system designs, 
using the best available and widely accepted well-being metrics as their reference point. 
This document is divided into the following sections:
•  An Introduction to Well-being Metrics (What you need to know) 
•  The Value of Well-being Metrics for A/IS (Why you should care) 
•  Adaptation of Well-being Metrics for A/IS (What you can do) 
Appendix:
The following sections are included in the Appendix as separate documents to provide 
readers with an introduction to existing individual and societal level well-being metrics 
currently in use: 
•  The State of Well-being Metrics. This section identifies well-being metrics being used 
today by social scientists, international institutions, and governments to provide an 
overall introduction to well-being. 
•  The Happiness Screening Tool for Business Product Decisions. This tool is provided  
as an example of how well-being indicators can inform decisions. 
Disclaimer: While we have provided recommendations in this document, it should be understood these do not represent a 
position or the views of IEEE but the informed opinions of Committee members providing insights designed to provide expert 
directional guidance regarding A/IS. In no event shall IEEE or IEEE-SA Industry Connections Activity Members be liable for any 
errors or omissions, direct or otherwise, however caused, arising in any way out of the use of this work, regardless of whether 
such damage was foreseeable. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 241The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Section 1 — An Introduction  
to Well-being Metrics 
This section provides a brief overview of what  and Development (OECD) Guidelines on 
well-being metrics are outside of the context of  Measuring Subjective Well-being (p. 12). This 
A/IS to provide a background for readers who  holistic definition of well-being encompasses 
may not be familiar with these areas. individual, social, economic, and governmental 
circumstances as well as human rights, 
capabilities, environmental protection, and fair 
Issue:  labor, as these circumstances and many others 
form the basis for human well-being.
There is ample and robust science 
behind well-being metrics and  Well-being metrics fall into four categories: 
use by international and national 
1.  Subjective or survey-based indicators
institutions, yet many people 
•  Survey-based or subjective well-being (SWB) 
in the A/IS field and corporate 
indicators are being used by international 
communities are unaware that 
institutions and countries to understand 
well-being metrics exist, or what  levels of reported well-being within a country 
entities are using them.  and for aspects of citizen demographics. 
Examples include the European Social Survey, 
Bhutan’s Gross National Happiness Indicators, 
and well-being surveys created by The UK 
Background
Office for National Statistics. Survey-based 
The concept of well-being refers to an evaluation  or subjective metrics are also employed in 
of the general goodness of a state or event  the field of positive psychology and in the 
to the individual or community as a distinct  World Happiness Report, and the data are 
moral or legal evaluation. The term itself has  employed by researchers to understand the 
been used and defined in various ways across  causes, consequences, and correlates of 
different contexts and fields. For the purposes  well-being as subjects see it. The findings 
of this committee, well-being is defined as  of these researchers provide crucial and 
encompassing human satisfaction with life and  necessary guidance to policy makers, leaders, 
the conditions of life, flourishing (eudaimonia),  and others in making decisions regarding 
and positive and negative affect, following  people’s subjective sense of well-being. 
the Organization for Economic Cooperation 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 242The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
2.  Objective indicators Candidate Recommendation
A/IS policy makers and manufacturers 
•  Objective well-being indicators have been 
(including academics, designers, engineers, 
used to understand conditions enabling 
and corporate employees) should prioritize 
well-being of countries and to measure the 
having all their stakeholders learn about well-
impact of companies. They are in used by 
being metrics as potential determinants for how 
organizations like the OECD with their Better 
they create, deploy, market, and monitor their 
Life Index (which also includes subjective 
technologies. This process can be expedited 
indicators), and United Nations with their 
by having organizations including the Global 
Millennium Development Goal Indicators.  
Reporting Initiative (GRI), B-Corp, and Standards 
For business, the Global Reporting Initiative, 
Development Organizations (SDO) create 
SDG Compass, and B-Corp provide broad 
certifications, guidelines, and standards that 
indicator sets.
demonstrate the value of holistic, well-being-
3.  Composite indicators (indices that  centric reporting guidelines for the A/IS public 
aggregate multiple metrics) and private sectors. 
•  Aggregate metrics combine subjective and/
Further Resources
or objective metrics to produce one measure. 
Examples of this are the UN’s Human  •  The IEEE P7010™ Standards Working Group, 
Development Index, the Social Progress  Wellbeing Metrics Standard for Ethical 
Index, and the United Kingdom’s Office   Artificial Intelligence and Autonomous 
of National Statistics Measures of National  Systems has been formed with the aim of 
Well-being. identifying well-being metrics for applicability 
to A/IS today and in the future. All are 
4.  Social media sourced data 
welcome to join the working group. 
•  Social media is source used to measure 
•  On 11 April 2017, IEEE hosted a dinner 
the well-being of a geographic region or 
debate at the European Parliament in 
demographics, based on sentiment analysis 
Brussels to discuss how the world’s top 
of publicly available data. Examples include 
metric of value (gross domestic product) 
the Hedonometer and the World Well-being 
must move Beyond GDP to holistically 
Project.
measure how intelligent and autonomous 
The appendix The State of Well-being Metrics  systems can hinder or improve human  
provides a broad primer on the state of well- well-being: 
being metrics.
•  Prioritizing Human Well-being in the Age 
of Artificial Intelligence (Report)
•  Prioritizing Human Well-being in the Age 
of Artificial Intelligence (Video)
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 243The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Section 2 — The Value of Well-being 
Metrics for A/IS
Well-being metrics, in the form of triple-bottom  Background
line benefits (“people, planet, and profit”) for 
While many organizations are aware of the need 
the corporate world, and in the form of tools 
to incorporate sustainability measures as part of 
to measure a population’s well-being for policy 
their efforts, the reality of bottom line, quarterly 
makers, can provide value to A/IS technologists. 
driven shareholder growth is a traditional 
Where technologists may be unaware of how 
metric prioritized within society at large. Where 
systems could negatively impact human well-
organizations exist in a larger societal ecosystem 
being, by increasing awareness of common 
equating exponential growth with success, as 
indicators and their designed intent, they can 
mirrored by GDP or similar financial metrics, 
avoid harm while increasing benefit. 
these companies will remain under pressure 
to deliver results that do not fully incorporate 
In addition, a key value for the use of well-being 
societal and environmental measures and goals 
metrics for A/IS technologists comes in the  
along with existing financial imperatives.
form of predictive modeling (forecasting 
outcomes based on data analysis and 
Along with an increased awareness of how 
probabilities), either for unintended 
incorporating sustainability measures beyond 
consequences, or as a unique means  
compliance can benefit the positive association 
of innovation regarding metrics or areas  
with an organization’s brand in the public sphere, 
of consideration not currently being  
by prioritizing the increase of holistic well-being, 
measured today. 
companies are also recognizing where they can 
save or make money and increase innovation  
in the process. 
Issue: 
For instance, where a companion robot outfitted 
Many people in the A/IS field 
to measure the emotion of seniors in assisted 
and corporate communities are 
living situations might be launched with a typical 
not aware of the value well-being  “move fast and break things” technological 
metrics offer.   manufacturing model, prioritizing largely fiscal 
metrics of success, these devices might fail in  
 
the market because of limited adoption. However, 
where they also factor in data aligning with 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 244The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
uniform metrics measuring emotion, depression,  of a total impact approach. There’s an 
or other factors (including life satisfaction, affect,  overwhelming consensus (85% CEOs) that 
and purpose), the device might score very high  results from a total impact approach would 
on a well-being scale comparable to the Net  be more insightful than financial analysis 
Promoter Score widely used today. If the device  alone. Business leaders saw the more holistic 
could significantly lower depression according  perspective useful in not only managing 
to metrics from a trusted source like the World  their business, but also in communicating 
Health Organization, academic institutions testing  with certain stakeholders. But less than 25% 
early versions of systems would be more able to  of CEOs measure their total impact with 
attain needed funding to advance an A/IS well- the lack of availability of data or a robust 
being study overall. While these are hypothetical  framework holding them back.
scenarios, they are designed to demonstrate 
This report, along with more recent work being 
the value of linking A/IS design to well-being 
done by other thought-leading organizations in 
indicators where possible.
the public sector like the OECD in their February, 
This is a key point regarding the work of this  2017 Workshop, Measuring Business Impacts 
Committee — rather than focus on the negative  on People’s Well-Being, demonstrates the desire 
aspects of how A/IS could harm humans, the  for business leaders to incorporate metrics of 
implementation of uniform well-being metrics  success beyond fiscal indicators for their efforts. 
will help provably demonstrate how these  The B-Corporation movement has even created a 
technologies can have a positive influence on  new legal status for “a new type of company that 
society.  uses the power of business to solve social and 
environmental problems.” Focusing on increasing 
The good news in regards to this subject is 
“stakeholder” value versus shareholder returns 
that thought leaders in the corporate arena 
alone, forward-thinking B-Corps are building trust 
have recognized this multifaceted need to 
and defining their brands by provably aligning 
utilize metrics beyond fiscal indicators. In 2013, 
their efforts to holistic metrics of well-being.
PricewaterhouseCoopers released a report called 
Total Impact Approach: What CEOs Think from  From a mental health perspective, well-being is 
PricewaterhouseCoopers: (where total impact  also important to business. Happy workers are 
refers to a “holistic view of social, environmental,  more productive than employees who are not 
fiscal and economic dimensions”) where they  engaged in their careers. There are also fewer 
noted: issues with absenteeism: people miss work less 
and have fewer health claims.  
187 CEOs across the globe shared their 
 
views on the value of measuring total 
 
impact. From all industries, they explored 
the benefits, opportunities and challenges 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 245The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Candidate Recommendation
A/IS and well-being experts should work directly  Issue: 
with the business community to identify existing 
By leveraging existing work in 
metrics or combinations of indicators that would 
computational sustainability or 
bring the greatest value to businesses focused on 
the “triple bottom line” (accounting for economic,  using existing indicators to model 
social, and environmental impacts) increase of  unintended consequences of 
human well-being. (Noting, however that well-
specific systems or applications, 
being metrics should only be used with consent, 
well-being could be better 
respect for privacy, and with strict standards for 
understood and increased  
collection and use of these data). 
by the A/IS community and 
In addition, any stakeholders creating A/IS in 
society at large. 
the business or academic, engineering, or policy 
arenas are advised to review the Appendix listing 
well-being metrics to familiarize themselves with 
existing indicators already relevant to their work.  Background
To date, there does not exist a definitive well-
Further Resources being metric that encompasses every aspect of 
individual and societal well-being that could serve 
•  PwC. Total Impact Approach: What CEOs 
as a common metric like the GDP for all A/IS 
Think.
manufacturers. Moreover, data may or may not 
•  World Economic Forum. The Inclusive Growth  exist within the context one wishes to measure  
and Development Report. January 16, 2017.  or improve. 
Geneva, Switzerland: World Economic Forum.  
Modeling for Unintended Consequences
 
  There is a potential for synergy when adapting 
  well-being indicators for the use of A/
  IS. This potential is in avoiding unintended 
  consequences. Two challenges to face when 
  exploring this potential are: (1) Identifying which 
  indicators to select to model potential unintended 
  consequences; and, (2) Understanding how to 
predict unintended consequences when data are 
lacking or are incomplete.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 246The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Machine-learning and other tools have the ability  A crucial distinction between well-being metrics 
to map out potential consequences with greater  and potential interventions in their use is 
specificity and efficiency than humans. In this  that a well-being metric does not dictate an 
way, A/IS could be utilized to map out potential  intervention, but points the way for developing 
consequences regarding how products, services,  an intervention that will push a metric in a 
or systems might affect end users or stakeholders  positive direction. For example, a team seeking 
in regards to specific well-being indicators. In  to increase the well-being of people using 
this way, models could be run during the design  wheelchairs found that when provided the 
phase of a system, product, or service to predict  opportunity to use a smart wheelchair, some 
how it could improve or potentially harm end  users were delighted with the opportunity 
users, analogous to human rights assessments  for more mobility, while others felt it would 
provided by the United Nations Guiding Principles  decrease their opportunities for social contact 
Reporting Framework.  and lead to an overall decrease in their well-
being. The point being that even increased 
As the exchange of A/IS related data regarding 
well-being due to a smart wheelchair does not 
an individual (via personalized algorithms, in 
mean that this wheelchair should automatically 
conjunction with affective sensors measuring 
be adopted. Well-being is only one value in the 
and influencing emotion, etc.) and society (large 
mix for adoption, where other values to consider 
data sets representing aggregate individual 
would be human rights, respect, privacy, justice, 
subjective and objective data) is widely available 
freedom, culture, etc.
via establishing tracking methodologies, this data 
should be classified to match existing well-being  Computational Sustainability
indicators so devices or systems can be provably 
Computational sustainability is an area of study 
aligned to the increase of human well-being 
within the A/IS community that demonstrates 
(satisfaction with life and the conditions of life, 
that the A/IS community is already showing 
positive affect, and eudaimonic well-being). 
interest in well-being even when not using 
this term, as the concept of sustainability 
As an example, today popular robots like Pepper 
encompasses aspects of well-being. 
are equipped to share data regarding their usage 
and interaction with humans to the cloud. This 
Computational sustainability directly relates to the 
allows almost instantaneous innovation, as 
use of these technologies to increase social good 
once an action is validated as useful for one 
in ways that could be uniquely tied to existing 
Pepper robot, all other units (and ostensibly their 
well-being metrics. As defined by The Institute 
owners) benefit as well. As long as this data 
of Computational Sustainability, the field is 
exchange happens via pre-determined consent 
designed to provide “computational models for a 
with their owners, this “innovation in real-time” 
sustainable environment, economy, and society” 
model can be emulated for the large-scale 
and their project summary notes that:  
aggregation of information relating to existing 
well-being metrics. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 247The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Humanity’s use of Earth’s resources is threatening  and others. Sustainability domains include 
our planet and the livelihood of future  natural resources, climate, and the 
generations. Computing and information science  environment (for example, climate change, 
can — and should — play a key role in increasing  atmosphere, water, oceans, forest, land, 
the efficiency and effectiveness in the way we  soil, biodiversity, species), economics and 
manage and allocate our natural resources.  human behavior (for example, human well-
We propose an expedition in Computational  being, poverty, infectious diseases, over-
Sustainability, encompassing computational  population, resource harvesting), energy 
and mathematical methods for a sustainable  (for example, renewable energy, smart grid, 
environment, economy, and society. material discovery for fuel cell technology) 
and human-built systems (for example, 
AAAI, (the Association for the Advancement of 
transportation systems, cities, buildings,  
Artificial Intelligence) the world’s largest global 
data centers, food systems, agriculture).
body dedicated to the advancement of artificial 
intelligence had a special track on computational 
sustainability at their 2017 conference. The  Candidate Recommendations
description of the track provides helpful specifics 
•  Work with influencers and decision-makers 
demonstrating the direct alignment between the 
in the computational sustainability field to 
work of this Committee and the A/IS community 
cross-pollinate efforts of computational 
at large: 
sustainability in the A/IS field and the 
This special track invites research papers  well-being communities to expedite efforts 
on novel concepts, models, algorithms,  to identify, align, and advance robust and 
and systems that address problems in  uniform indicators into current models that 
computational sustainability. We are looking  prioritize and increase human well-being. 
for a broad range of papers ranging  Develop cross-pollination between the 
from formal analysis to applied research.  computational sustainability and well-being 
Examples include papers explaining how the  professionals to ensure integration of well-
research addresses specific computational  being into computational sustainability, and 
problems, opportunities, or issues underlying  vice-versa. 
sustainability challenges and papers 
•  Explore successful programs like LEED 
describing a sustainability challenge or 
Building Design Standards, ISO 2600 
application that can be tackled using 
Corporate Responsibility, ISO 37101 
AI methods. Papers proposing general 
Sustainable Development Standards, and 
challenges and data sets for computational 
others to determine what new standards 
sustainability are also welcome. All AI topics 
or certification models along these 
that can address computational sustainability 
lines approach would be valuable and 
issues are appropriate, including machine 
operationalizable for A/IS. 
learning, optimization, vision, and robotics, 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 248The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Further Resources
•  Gomes, C. P. “Computational Sustainability:  Issue: 
Computational Methods for a Sustainable 
Well-being indicators provide 
Environment, Economy, and Society” in The 
an opportunity for modeling 
Bridge: Linking Engineering and Society. 
Washington, DC: National Academy of  scenarios and impacts that could 
Engineering of the National Academies,  improve the ability of A/IS to 
2009. 
frame specific societal benefits 
•  Meadows, D. H., D. L. Meadows, J. Randers,  for their use. 
and W. W. Behrens, III. The Limits to Growth. 
New York: Universe Books, 1972. Reissued 
in 2004 by Chelsea Green Publishing & 
Background: 
Earthscan.
There is a lack of easily available or widely 
•  LEED Building Design Standards program. recognized scenarios along these lines. 
•  ISO 2600, Guidance on Social Responsibility. 
Candidate Recommendation
•  ISO 37101, Sustainable Development in 
Rigorously created well-being assessments could 
Communities 
be utilized as a public “scoreboard,” or statement 
 
of intent, that would provide innovation 
opportunities for technologists as well as a form 
of public accountability for human sustainability.
Further Resources
The following schema and well-being assessment 
tool provide an initial attempt to visualize how 
A/IS technologists can utilize well-being metrics 
in their work. By modeling the potential positive 
or negative impacts of technologies across a full 
spectrum of financial, environmental, and social 
impacts (e.g., a “triple bottom line” well-being 
indicator model) A/IS technologists can better 
avoid negative unintended consequences for 
human well-being, while increasing innovation 
and positive human well-being for their work. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 249The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Schema of A/IS and the Stakeholders Involved in Their Development
The schema represents a model of the world where the stakeholders (designers, engineers, 
technologists, researchers, managers, users, etc.) involved in A/IS development adapt and operationalize 
well-being metrics for ethical A/IS. Stakeholders can visualize important entities in the world as agents 
with different goals that receive observations and possible rewards from the environment and make 
actions that could have positive and negative impacts to the well-being of different agents. 
This schema could help to assess, in different cases, the well-being metrics that the A/IS should take 
into account and the well-being metrics of the impacts that A/IS actions could and can cause, related to 
important elements in the world like: people, products, organizations, climate, countries, etc. An applied 
case of this schema could be seen in the following well-being impact assessment.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 250The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Well-being Impact Assessment
Here is a concept for simple A/IS well-being impact assessment, based on Maslow’s Hierarchy of Need 
(where the Hierarchy would be considered an accredited and contextually appropriate metric of use). 
Given that a working definition of well-being including both individual and societal key performance 
indicators (KPIs) is still being developed, this metric is general and used for illustrative purposes only.
Please also note that this is a purely conceptual framework used as a directional teaching tool for 
readers. It doesn’t yet include an evaluative component or reflect the holistic nature of well-being at this 
time like The Happiness Screening Tool (based on the government of Bhutan’s Policy Screening Tool) 
provided in the Appendix. It should be noted that any impact assessment created by A/IS and well-
being experts working together identify best-in-class (existing) metrics within specific contexts of use. 
Individual Individual Environment Individual Social Social
Direct Indirect Direct Indirect Direct Indirect
Basic Needs
Safety
Belonging
Esteem
Self-Actualization
Overall Impact
Indicators: 
nil impact = 0        negative impact = −        positive impact = +        unknown impact = ?
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 251The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
The following examples are provided to demonstrate specific A/IS applications within this framework 
and include: a retail kiosk robot, a small factory arm, a mental health chatbot, and a companion robot. 
The goal of these diagrams is to provide a sample of how the work of matching established well-being 
metrics to A/IS work could progress. 
Retail Kiosk Robot Individual Individual Environment Individual Social Social
Direct Indirect Direct Indirect Direct Indirect
Basic Needs 0 0 0 − + ?
Safety ? ? ? − + ?
Belonging + ? + ? + ?
Esteem + ? 0 0 + ?
Self-Actualization ? ? 0 0 ? ?
Overall Impact Mild + Unknown Very Mild + Mild − Strong + Unknown
Using this tool, the retail kiosk robot scores are mildly beneficial in the category of Individual Direct (i.e., 
reduced barriers to goal attainment) and Environmental Direct (i.e., use of resources), while strongly 
beneficial in Social Direct (i.e., better access to mental health support), but mildly unbeneficial in 
Environment Indirect (i.e., carbon footprint), and unknown in Social Indirect (i.e., job loss) categories. 
The robot is “helpful and kind,” but of limited utility or interaction value. Another example of a negative 
impact on well-being is gendering, racial identification, or physical attributes of kiosk robots (such as a 
slim, youthful appearing, Caucasian, female), leading to harmful stereotyping. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 252The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Small Factory Arm Individual Individual Environment Individual Social Social
Direct Indirect Direct Indirect Direct Indirect
Basic Needs + + 0 − + +
Safety ? ? ? − ? +
Belonging − − 0 0 0 0
Esteem − − 0 0 0 0
Self-Actualization 0 0 0 0 0 0
Overall Impact Mild −  Mild − Nil Mild − Mild + Mild +
The tool indicates that robots need to be assessed more thoroughly on their safe operations to better 
answer impact assessment, and that this is also a robot with very limited interaction with people. But the 
diagram shows how the arm could have a potentially negative impact on self-worth and belonging, but a 
positive impact on basic needs both for individuals and society.
Mental Health  Individual Individual Environment Individual Social Social
Chatbot Direct Indirect Direct Indirect Direct Indirect
Basic Needs 0 0 0 0 0 0
Safety + 0 0 0 ? +
Belonging + ? 0 0 ? −
Esteem + ? 0 0 ? −
Self-Actualization ? 0 0 0 0 0
Overall Impact Strong + Unknown Nil Nil Unknown Mild −
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 253The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
There is evidence that a mental health aide chatbot could improve individual self esteem and ultimately 
reduce self harm, but there is little evidence supporting claims that this would improve society directly 
or indirectly. The reliance on artificial support may have a net negative impact on society. However, 
this would need to be determined by the A/IS and well-being experts applying this methodology once 
created in a robust and rigorous manner. 
Companion Robot  Individual Individual Environment Individual Social Social
like Paro Direct Indirect Direct Indirect Direct Indirect
Basic Needs 0 0 0 - 0 0
Safety + ? 0 0 0 0
Belonging + ? 0 0 ? -
Esteem + ? 0 0 ? -
Self-Actualization ? 0 0 0 0 0
Overall Impact
For a small resource cost, a companion robot can provide significant psychological assistance. On the 
one hand, this makes society more caring, but on the other hand reliance on artificial companionship 
shows a lack of social resources in this area. A potential negative impact is development of reliance on 
companionship and negative impact on people who lose access to companion robot.
The Happiness Project Screening Tool for Business provided in the Appendix could also augment this if 
a product shows a low or negative score in the areas of well-being. Another set of metrics that could be 
used in a more detailed schema are the Kingdom of Bhutan’s nine domains of well-being: psychological 
well-being, health, community vitality, living standards, governance, environment diversity, culture, 
education, and time use.
Whatever established well-being metrics that may be utilized for such a methodology, it is critical  
for A/IS technologists and well-being experts to work in unison to create assessment tools using best  
in class data, indicators, and practices in their potential analysis and use.
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 254The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Section 3 — Adaptation of Well-being 
Metrics for A/IS
This section focuses on areas of immediate  objectives? How will these measures be adapted 
attention for A/IS technologists to be aware  as we learn more? 
of regarding well-being metrics in an effort to 
Existing metrics of well-being could be formulated 
aid their work and avoid negative unintended 
into a sub-objective of the A/IS. In order to 
consequences.
operate with respect to such sub-objectives, it 
is instrumental to evaluate the consequences 
of the A/IS’s actions. As practical systems are 
Issue: 
bounded and can predict over only limited 
How can creators of A/IS  horizons, it may be necessary to supplement 
incorporate measures of   these evaluations with both biases toward virtues 
and deontological guidelines or soft constraints 
well-being into their systems?
as lesser supplemental components, informed  
by the well-being metrics and their precursors  
Background
or constituents. 
Just as undirected A/IS can lead to negative 
As these well-being sub-objectives will be only 
outcomes, A/IS directed only to specific ends 
a subset of the intended goals of the system, 
without considering human well-being can lead 
the architecture will need to balance multiple 
to negative side effects. Without practical ways 
objectives. Each of these sub-objectives may  
of incorporating widely shared ways of measuring 
be expressed as a goal, or as a set of rules, or as 
and promoting well-being metrics and expected 
a set of values, or as a set of preferences, and 
well-being outcomes available to designers, A/IS 
those can be combined as well, using  
will likely lack beneficence.
established methodologies from intelligent 
Once well-being metrics are widely recognized  systems engineering. 
as a directional requirement for society, 
For example, people, organizations, and  
conceptually, one would like such measures 
A/IS, collaborating together, could understand the 
to be supported by the engines of change and 
well-being impacts and objectives of products, 
leverage within society. A/IS will be an increasing 
services, organizations, and A/IS within the 
portion of such engines. How might designers 
context of the well-being of communities, cities, 
architect systems to include such measures as 
countries, and the planet using the SDG Index 
considerations while executing their primary 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 255The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
and Dashboards, the SDG Compass Inventory  End users would have the opportunity to layer 
of Business Indicators and other metrics. This  on their own preferences in these systems, and 
collaboration of people, organizations and   would also be able to get an explanation and 
A/IS could make decisions and take actions with  inventory of the types of objectives or value 
high expected utility to well-being objectives and  systems the A/IS holds relating to established 
goals such as those stated in the Sustainable  well-being metrics, including what permissioning 
Development Goals and similar institutions. This  is required for modifying or removing them.
collaboration could lead to a more humane, 
organizational, and computational sustainability  Candidate Recommendation
for individuals, all of society, and the planet.
Formation of a working group to develop a 
International organizations, lawmakers, and  blueprint for the fluid and evolving (institutional 
policy experts can specify core values and/or  learning) operationalization of A/IS well-being 
sub-objectives as rules for the benefit of society  indicators for the various stakeholders (e.g., 
utilizing well-being metrics as a starting point  technicians, coders, and system designers), 
and these can be pluggable and hierarchical by  international well-being oriented organizations, 
jurisdiction. Similarly, industry organizations would  lawmakers, and policy experts, industry 
be able to specialize norms and industry self- organizations, retailers, resellers, service 
regulation (e.g., any automated flight attendants  organizations and owners, and end users. 
should prevent onboard smoking and sit down 
during takeoff) as a layer. Candidate Recommendation
System designers should ensure situational  Creation of technical standards for representing 
awareness as well as prediction of the  dimensions, metrics, and evaluation guidelines 
consequences of their actions based on   for well-being metrics and their precursors and 
some world model. They could also layer in  constituents within A/IS. This would include 
their own sub-objectives and make the system’s  ontologies for representing requirements as well 
values explicit. as a testing framework for validating adherence 
to well-being metrics and ethical principles. 
Resellers, service organizations, or owners that 
(For more information, please see IEEE P7010™ 
have particular primary goals for their systems 
Standards Working Group mentioned above). 
would still be able to specify primary goals for the 
 
system (e.g., mowing lawns, doing taxes, etc.), 
 
and those would be alongside the other deeper-
 
down subgoals and values as well for societal 
benefit, public safety, etc., directly relating  
to established well-being metrics. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 256The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Further Resources
•  Calvo, R. A., and D. Peters. Positive  Issue: 
Computing: Technology for Well-Being and 
A/IS technologies designed to 
Human Potential. Cambridge MA: MIT Press, 
replicate human tasks, behavior, 
2014
or emotion have the potential  
•  Collette Y., and P. Slarry. Multiobjective 
to either increase or decrease 
Optimization: Principles and Case Studies 
well-being.
(Decision Engineering Series). Berlin, 
Germany: Springer, 2004. doi: 10.1007/978-
3-662-08883-8. 
Background
•  Greene, J. et al. “Embedding Ethical Principles 
A/IS are already being executed in ways that 
in Collective Decision Support Systems,” in: 
could dramatically increase human well-being 
Proceedings of the Thirtieth AAAI Conference 
or, possibly, have an undue coercive effect on 
on Artificial Intelligence, 4147–4151. Palo 
humans. 
Alto, CA: AAAI Press, 2016.
A/IS technologies present great opportunity 
•  Li, L. et al. “An Ontology of Preference-Based 
for positive change in every aspect of 
Multiobjective Evolutionary Algorithms,” 2016.
society. However, sophisticated manipulative 
CoRR abs/1609.08082. 
technologies utilizing A/IS can also restrict the 
•  A. FT Winfield, C. Blum, and W. Liu.  fundamental freedom of human choice, and 
“Towards an Ethical Robot: Internal Models,  are able to manipulate humans who consume 
Consequences and Ethical Action Selection,”  customized content without recognizing the 
in Advances in Autonomous Robotics  extent of manipulation. Software platforms are 
Systems. Springer, 2014, pp. 85–96.  moving from targeting content to much more 
powerful and potentially harmful “persuasive 
•  Gershman, S. J., E. J. Horvitz, and J. B. 
computing.” A/IS with sophisticated manipulation 
Tenenbaum. “Computational rationality: A 
technologies (so-called “big nudging”) will 
converging paradigm for intelligence in brains, 
be able to guide individuals through entire 
minds, and machines.” Science 349, no. 
courses of action, whether it be a complex work 
6245 (2015): 273–278. 
process, consumption of free content, or political 
•  PositiveSocialImpact: Empowering people,  persuasion. 
organizations and planet with information 
There is also a related concern that big nudging 
and knowledge to make a positive impact  
can be done without anyone realizing harm 
to sustainable development. 
is occurring. With deep learning methods, 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 257The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
technologies may not be understood, much less  Candidate Recommendation
contemplated. This begs the age-old question: 
To avoid potential negative unintended 
just because one can do something, does that 
consequences, A/IS manufacturers, and society 
mean one should? Hence, there is a need to 
in general, should prioritize the analysis and 
understand A/IS well-being related processes  
implementation of practices and policy that 
and impacts further, and to devise ways to 
secures or increases human well-being, including: 
protect people from harm and secure  
well-being in the furtherance of A/IS.  •  Well-being metrics to guide the development 
and implementation of A/IS should increase 
A/IS may also deceive and harm humans 
human well-being, defined subjectively in 
by posing as humans. With the increased 
terms of cognitive, affective, and eudaimonic 
ability of artificial systems to meet the Turing 
domains, and objectively in terms of 
test (an intelligence test for a computer that 
conditions enabling well-being.
allows a human to distinguish human from 
artificial intelligence), there is a significant risk  •  While individuals may enjoy the ability of A/IS 
that unscrupulous operators will abuse the  to simulate humans in situations where they 
technology for unethical commercial, or outright  are pure entertainment, explicit permission 
criminal, purposes. The widespread manipulation  and consent by users in the use of these 
of humans by A/IS and loss of human free  systems is recommended, and the well-
agency, autonomy, and other aspects of human  being impacts on users should be monitored, 
flourishing, is by definition a reduction in   researched, and considered by the A/IS 
human well-being. Without taking action to  community in an effort to provide services 
prevent it, it is highly conceivable that A/IS will  and goods that improve well-being. As part 
be used to deceive humans by pretending to be  of this, it is important to include multiple 
another human being in a plethora of situations  stakeholders, including minorities, the 
or via multiple mediums.  marginalized, and those often without  
power or a voice.
Without laws preventing A/IS from simulating 
humans for purposes like deception and  •  The implications of A/IS on human well-
coercion, and enforcing A/IS to clearly identify   being are important issues to research and 
as such, mistaken identity could also reasonably  understand. A literature review to determine 
be expected.   the status of academic research on the 
  issue of A/IS impacts on human well-being 
needs to be conducted and aggregated 
in a centralized repository for the A/IS 
community. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 258The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
Further Resources Background
•  Helbing, D. et al. “Will Democracy Survive  International human rights law has been firmly 
Big Data and Artificial Intelligence?” Scientific  established for decades and the protection of 
American, February 25, 2017.  human rights must be an end result in itself. 
Some countries or regimes have highlighted 
•  Schenker, J. L. “Can We Balance Human 
the use or increase of certain “well-being” 
Ethics with Artificial Intelligence?” 
measures as justification to violate human rights, 
Techonomy, January 23, 2017.
as happens in countries that conduct ethnic 
cleansing or mistreat refugees or immigrants  
•  Bulman, M. “EU to Vote on Declaring Robots 
who are portrayed as threatening a nation’s 
To Be ‘Electronic Persons.” Independent, 
culture or economic structure. 
January 14, 2017.
While the use of well-being metrics to justify 
•  Nevejan, N. for the European Parliament. 
human rights violations is an unconscionable 
“European Civil Law Rules in Robotics.” 
perversion of the nature of any well-being 
October 2016.
metric, these same practices happen today in 
•  “The AI That Pretends To Be Human,”  relation to the GDP. For instance, today, according 
LessWrong blog post, February 2, 2016. to the International Labor Organization (ILO) 
approximately 21 million people are victims of 
•  Chan, C. “Monkeys Grieve When Their Robot 
forced labor (slavery) representing between 9% 
Friend Dies.” Gizmodo, January 11, 2017.
to 56% of various countries current GDP income. 
These clear human rights violations, from sex 
trafficking and child armies, to indentured farming 
or manufacturing labor, increase a country’s GDP.
Issue: 
Well-being metrics and mechanisms should 
Human rights law is sometimes 
also take into consideration, and happen in 
conflated with human well-being,  conjunction with, independent assessments on 
leading to a concern that a focus  respect and international obligations to promote, 
protect, and fulfill a full spectrum of human 
on human well-being will lead 
rights. For example, the use of the goal of well-
to a situation that minimizes the 
being in the context of repairing and enhancing 
protection of inalienable human 
humans, predictive policing, or autonomous 
rights, or lowers the standard  weapons systems to protect the public may have 
of existing legal human rights  negative impacts on the rights of individuals or 
groups. Moreover, the development and delivery 
guidelines for non-state actors. 
of A/IS should adopt a human rights approach  
to technology, including, but not limited to, the 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 259The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
UN Guiding Principles on Human Rights (also  •  OpenDiversityOrg initiative from Double 
known as the Ruggie principles). Union and Project Include have an action 
document with a lot of recommendations. 
To avoid issues of conflation and confusion, it 
is critical to note the following: human rights  •  “The Diversity Debt” by Susan Wu at Project 
involves adhering to the firmly established  Include is a compelling example of converting 
application of international human rights law.  a problem into innovation language.
Well-being metrics are designed to measure  
the efficacy of the implementation of 
methodologies and policy related to  
individual and societal flourishing. 
Issue: 
Well-being as a value is also distinct from  
A/IS represents opportunities 
justice, responsibility, and freedom. But A/IS 
for stewardship and restoration 
technologies can be narrowly conceived from  
an ethical standpoint and still be legal and safe  of natural systems and securing 
in their usage following existing practices, but not  access to nature for humans, but 
contribute to human well-being. In this regard, 
could be used instead to distract 
well-being considerations do not displace other 
attention and divert innovation 
issues of human rights or ethical methodologies, 
until the planetary ecological 
but rather complement them.
condition is beyond repair. 
Candidate Recommendation
Human rights and human well-being should not 
Background
be held as trade-offs, with one to be prioritized 
over the other. In this regard, well-being metrics  Human well-being, the existence of many other 
can be complementary to the goals of human  species, as well as economic and social systems, 
rights, but cannot and should not be used as   draw from and depend upon healthy ecological 
a proxy for human rights or any existing law. systems and a healthy local and planetary 
environment. Research using geo-data finds that 
Further Resources human well-being is enhanced through access 
to nature. Many bank on technology to answer 
•  Project Include - The site features an open 
the threats of climate change, water scarcity, soil 
source manual for creating diversity in tech 
degradation, species extinction, deforestation, 
and highlights three key points for creating 
deterioration of biodiversity, and destruction  
change: inclusion, comprehensiveness, and 
of ecosystems that threaten humankind and 
accountability.
other life forms. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 260The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
While technology may be the answer for some  Further Resources
of these threats, it is unclear whether benefits 
•  Newton, J. “Well-being and the Natural 
extend beyond those from high socio-economic 
Environment: An Overview of the Evidence.” 
class to the majority of people, particularly the 
August 20, 2007.
middle class and working poor, as well as those 
suffering from abject poverty, fleeing disaster  •  Dasgupta, P. Human Well-Being and the 
zones or otherwise lacking the resources to  Natural Environment. Oxford, U.K.: Oxford 
meet their needs. For example, in cities in China  University Press, 2001.
where air pollution is so prevalent that the air is 
•  Haines-Young, R., and M. Potschin. “The 
unhealthy, a few schools have covered “outdoor” 
Links Between Biodiversity, Ecosystem 
fields with domes full of purified air while most 
Services and Human Well-Being,” in 
children must risk their lungs when playing 
Ecosystem Ecology: A New Synthesis, edited 
outside, or play indoors. Moreover, it is well-
by D. Raffaelli, and C. Frid. Cambridge, U.K.: 
understood that ecological crises, such as sea 
Cambridge University Press, 2010.
level rise and fisheries depletion, will not only 
negatively impact business interests, but it will 
•  Hart, S. Capitalism at the Crossroads: Next 
have a significantly more devastating impact on 
Generation Business Strategies for a Post-
the poor and developing nations than the wealthy 
Crisis World. Upper Saddle River, NJ: Pearson 
and developed nations.
Education, 2010.
Candidate Recommendation •  United Nations Department of Economic 
and Social Affairs. “Call for New Technologies 
Well-being metrics employed for A/IS should 
to Avoid Ecological Destruction.” Geneva, 
include measures for ecological/environmental 
Switzerland, July 5, 2011. 
sustainability that point the direction toward 
stewardship and restoration of natural systems  •  Pope Francis. Encyclical Letter Laudato Si,  
and ensure equitable environmental justice.  On the Care of Our Common Home.  
May 24, 2015.
Candidate Recommendation
Convene a committee to issue findings on the 
modalities and potentials already identified in 
which A/IS makes progress toward stewardship 
and restoration of natural systems; trends in 
the A/IS field that represent threats to and 
opportunities for ecological sustainability and 
environmental justice; and areas for suggested 
future innovation and implementation. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 261The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
increasing ability to understand and engineer our 
genomes: How do in-depth and personalized 
Issue: 
understanding of how our genomes function 
The well-being impacts of A/IS  and evolve relate to the notion of well-being 
applied to human genomes are  as measured traditionally and/or according to 
well-being measures? When does a reductionist 
not well understood. 
interpretation of the health significance of our 
genomics data threaten our well-being?
Background
Other significant questions include: 
As A/IS are increasingly used to interpret the 
•  How accurate will the predictive health 
health significance of our genomics data (“deep 
data coming from the convergence of  
genomics”) and to contribute to the subsequent 
A/IS and genomics be? 
engineering and editing of our genomes, 
important ethical and governance questions   •  How will these health predictions be used, 
are in the background that provide an opportunity  and who will have access to them? 
to utilize well-being metrics to ensure the 
beneficial development of genomic research   •  Do pharmaceutical and insurance 
as it relates to A/IS. companies have the right to use and profit 
from your health data predictions/modeling 
without giving you any benefits back in 
Imagine this scenario: 
return? 
6 A.M., Washington, DC — Erika wakes 
up and quickly checks her “digital DNA  •  Would it threaten your self-worth if those 
avatar,” a digital version of her genetic  handling your health data know a lot  
blueprint as it evolves day by day.  of biological details about your body? 
The avatar knows a lot about her as 
•  Is it ethical for a prospective employer to 
it constantly monitors the interactions 
ask how your health will look like in the 
between her genes, analyzes her bodily 
next decade? 
fluids and diet, as well as integrates data 
about the air quality around her. Her  Answers to these questions are not easy to 
avatar proposes a few advices about  capture, but their impact on well-being within 
food choices and exercise patterns.  society is profound.
Everything seems in check, nothing  
The convergence of genomics technologies and 
to be worried about. For now.
A/IS creates new opportunities to define our 
A first overarching reflection concerns the  identity and well-being within a simple narrative 
relationship between well-being and an  in which our genes have the power to tell us who 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 262The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
Well-being
and how well we are. As A/IS are increasingly  Candidate Recommendation
used to interpret the health significance of 
A working committee should be convened 
our genomics data (“deep genomics”) and to 
gathering those at the sharp end of genomics,  
contribute to the subsequent engineering/editing 
A/IS, ethics, and governance to start a 
of our genomes, we should consider important 
conversation with different communities to  
ethical and governance questions. 
better understand the impact on well-being 
There is an urgent need to concurrently discuss  of the use of A/IS to interpret (and engineer) 
how the convergence of A/IS and genomic  genomics data.
data interpretation will challenge the purpose 
and content of relevant legislation that preserve  Candidate Recommendation
well-being, such as, for the United States, the 
Relevant expert and legislative committees 
Health Insurance Portability and Accountability 
should commission a study on the impact on 
Act (HIPAA) and the Genetic Information Non-
well-being of deep genomics, meaning at the 
Discrimination Act (GINA). Finding the right 
convergence of genomics and A/IS. Such a study 
balance of protection and regulation in using  
is recommended to encompass diverse fields 
A/IS to interpret the health significance of 
of expertise in philosophy, sociology, ethics, 
genomics data will be important. Too much 
biosafety, biosecurity, and genomics governance. 
regulation could endanger precision medicine 
Recommendations from the study should draft 
initiatives in some countries, while others would 
proposals to frame debates in legislatures and 
be leading the bio-race. Too little regulation could 
help lawmakers start developing appropriate 
leave citizens vulnerable to different forms of 
legislation to govern A/IS applied to genomes  
threats to their well-being. 
for the well-being of society. 
This work is licensed under a Creative Commons Attribution-NonCommercial 3.0 United States License. 263