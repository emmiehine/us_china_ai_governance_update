成果文件：
人工智能伦理问题建议书草案初稿
根据教科文组织大会第四十届会议的决定（第40 C/37号决议），总干事于2020年3月设立了负责拟定人工智能伦理问题建议书草案文本的特设专家组（AHEG）。
为适应2019冠状病毒病（COVID-19）大流行带来的挑战性形势，特设专家组从2020年3月底至5月初采用线上工作方式，编写了人工智能伦理问题建议书草案文本初稿。
2020年6月至8月就这份初稿进行了广泛的多利益攸关方磋商。磋商分为三部分：(i) 公众在线磋商（收到800多条反馈）；(ii) 与教科文组织所有地区的东道国/机构联合举办的地区和分地区在线磋商（超过500人参加）；(iii) 合作伙伴举办的多利益攸关方和公民公开审议讨论会（约有500人参加）。在磋商过程中就文本提出了50 000多条意见。
2020年8月至9月初，特设专家组结合在此次磋商过程中收到的反馈意见，修订了草案文本初稿，形成了本文件所载的建议书草案初稿，并将于2020年9月送交会员国征求书面意见。
社会科学及人文科学部门助理总干事以及生物伦理和科学伦理科对特设专家组的工作给予了支持。
本文件并非详尽无遗，也未必代表教科文组织会员国的观点。
人工智能伦理问题建议书草案初稿
序言
联合国教育、科学及文化组织（教科文组织）大会于X年X月X日至X月X日在巴黎召开第XX届会议，
认识到人工智能（AI）对社会、生态系统和人类生活包括人类思想具有深刻而动态的影响，部分原因在于人工智能以新的方式影响着人类的思维、互动和决策，并且波及到教育、人文科学、社会科学和自然科学、文化、传播和信息，
忆及教科文组织根据《组织法》，力求通过教育、科学、文化以及传播和信息促进各国间之合作，对和平与安全作出贡献，以增进对正义、法治及所确认之世界人民均享人权与基本自由之普遍尊重，
深信这部以国际法为依据、采用全球规范方法且注重人的尊严和人权以及性别平等、社会和经济正义、身心健康、多样性、互联性、包容性、环境和生态系统保护的规范性文书，可以引导人工智能技术向着负责任的方向发展，
考虑到人工智能技术可以对人类大有助益，但也会引发重大的伦理关切，例如人工智能技术可能内嵌并加剧偏见，可能导致不平等和排斥，并对文化、社会和生态多样性构成威胁，造成社会或经济鸿沟；算法的工作方式和算法训练数据应具有透明性和可理解性；算法对于人的尊严、人权、性别平等、隐私、表达自由、信息获取、社会、经济、政治和文化进程、科学和工程实践、动物福利、环境和生态系统的潜在影响，
认识到人工智能技术会加深世界各地国家内部和国家之间现有的鸿沟和不平等，必须维护正义、信任和公平，以便在享受人工智能技术的惠益和避免受其负面影响方面不让任何人掉队，同时认识到各国国情不同以及一部分人没有参与所有技术发展的意愿，
意识到所有国家都正值信息和通信技术及人工智能技术加速使用的时期，对于媒体和信息素养的需求日益增长，且数字经济带来了重大的社会、经济和环境挑战以及惠益共享的机会，对于中低收入国家——包括但不限于最不发达国家（LDC）、内陆发展中国家（LLDC）和小岛屿发展中国家（SIDS）而言尤为如此，需要承认、保护和促进本土文化、价值观和知识，以发展可持续的数字经济，
认识到人工智能技术具备有利于环境和生态系统的潜力惠益，要实现这些惠益，需要公平获取技术，同时不能忽视而且更要去应对其对环境和生态系统的潜在危害和影响，
注意到应对风险和伦理关切不应妨碍创新，而是应提供新的机会，激励新的和负责任的研究和创新实践，使人工智能技术立足于人权、价值观、原则以及关于道义和伦理的思考， 
忆及教科文组织大会在2019年11月第四十届会议上通过了第40 C/37号决议，授权总干事“以建议书的形式编制一份关于人工智能伦理问题的国际准则性文书”，提交2021年大会第四十一届会议，
认识到人工智能技术的发展导致信息量增加，需要相应提高媒体和信息素养，并增加获取重要信息来源的机会，
认为关于人工智能技术及其社会影响的规范框架应建立在共识和共同目标的基础上，以伦理、人权、基本自由、数据、信息和知识的获取、国际和国家法律框架、研究和创新自由、人类福祉、环境和生态系统福祉为依据，将伦理价值观和原则与同人工智能技术有关的挑战和机遇联系起来，
认识到在规范范围不明确的情况下，或是在由于技术发展迅速而政策反应相对较慢、尚未制定相关规范的情况下，伦理价值观和原则可以提供指导，从而有力地影响基于权利的政策措施和法律规范的制定和实施，
深信全球公认的人工智能技术伦理标准和国际法特别是人权法、原则和标准，可以在统一世界各地的人工智能相关法律规范方面起到重要作用，
承认《世界人权宣言》（1948年），包括强调有权分享科学进步及其产生的福利的第27条；国际人权框架文书，包括《消除一切形式种族歧视国际公约》（1965年）、《公民及政治权利国际公约》（1966年）、《经济、社会、文化权利国际公约》（1966 年）、联合国《消除对妇女一切形式歧视公约》（1979年）、联合国《儿童权利公约》（1989年）和联合国《残疾人权利公约》（2006年）；教科文组织《保护和促进文化表现形式多样性公约》（2005年），
注意到教科文组织《当代人对后代人的责任宣言》（1997年）；《联合国土著人民权利宣言》（2007年）；联合国秘书长2011年关于第二次老龄问题世界大会的后续行动的报告（A/66/173），其中着重关注老年人的人权状况；人权与跨国公司和其他工商企业问题秘书长特别代表2011年的报告（A/HRC/17/31），其中概述《工商企业与人权：实施联合国“保护、尊重和补救”框架指导原则》；联合国大会关于审查信息社会世界首脑会议的决议（A/RES/68/302）；人权理事会2019年9月26日通过的关于“数字时代的隐私权”的决议（A/HRC/RES/42/15）；促进和保护意见和表达自由权问题特别报告员的报告（A/73/348）；教科文组织《关于科学和科学研究人员的建议书》（2017年）；教科文组织互联网普遍性指标（2019年获得教科文组织国际传播发展计划认可），包括R.O.A.M.原则（2015年获得教科文组织大会认可）；教科文组织《关于保存和获取包括数字遗产在内的文献遗产的建议书》（2015年）；联合国秘书长数字合作高级别小组关于“相互依存的数字时代”的报告（2019年）和联合国秘书长数字合作路线图（2020年）；《世界生物伦理与人权宣言》（2005年）；教科文组织《与气候变化有关的伦理原则宣言》（2017年）；联合国“全球脉搏”举措；国际电信联盟人工智能造福人类全球峰会的成果和报告。
又注意到其他政府间组织与人工智能伦理问题有关的现有框架，例如欧洲委员会通过的相关人权文书和其他法律文书及其人工智能特设委员会（CAHAI）的工作；欧洲联盟与人工智能有关的工作，欧洲联盟委员会人工智能问题高级别专家组的工作，包括《可信人工智能伦理准则》；经合组织首个专家组（AIGO）及其继任者经合组织人工智能专家网络（ONE AI）的工作、经合组织人工智能问题理事会的建议以及经合组织人工智能政策观察站（OECD.AI）；《二十国集团贸易和数字经济部长声明》总结并概述的二十国集团人工智能原则；七国集团《关于未来人工智能的沙勒瓦共同愿景》；非洲联盟人工智能问题工作组的工作；阿拉伯国家联盟人工智能问题工作组的工作，
强调必须特别关注中低收入国家，包括但不限于最不发达国家、内陆发展中国家和小岛屿发展中国家，这些国家具备能力，但在人工智能伦理问题辩论中的代表性不足，由此引发了对于地方知识、文化和伦理多元化、价值体系以及应对人工智能技术的正负两方面影响需要实现全球公平的要求受到忽视的关切，
意识到目前存在许多与人工智能技术的伦理和监管问题有关的国家政策和其他框架，
又意识到私营部门、专业组织和非政府组织已制定出许多与人工智能伦理问题有关的倡议和框架，例如电气电子工程师学会发起的“自主和智能系统伦理问题全球倡议”及其在“合乎伦理的设计”方面的工作；世界经济论坛“全球技术治理：多利益攸关方办法”；全球工会联盟“合乎伦理的人工智能十大原则”；《关于负责任地发展人工智能的蒙特利尔宣言》；《多伦多宣言：在机器学习系统中保护平等和非歧视的权利》；和谐人工智能原则（HAIP）；人工智能伙伴关系原则，
深信人工智能技术可以带来重大惠益，但实现这些惠益也会加剧创新债务、知识获取不对称、信息权障碍、开发周期中的创造能力差距、人员和机构能力差距、获取技术创新的障碍、在数据方面缺乏适当的实体和数字基础设施以及规范框架等问题，
强调需要开展全球合作并实现全球团结，应对人工智能技术给文化和伦理体系的多样性和互联性带来的挑战，减少可能的滥用，确保人工智能战略和监管框架不以国家利益、商业利益和经济竞争作为唯一的导向，
充分考虑到世界各国的伦理取向和文化具有多样性，与技术和知识社会有关的法律缺乏灵活性，人工智能技术可能破坏地方和地区伦理标准和价值观，因此人工智能技术的快速发展对于合乎伦理的应用和治理提出了挑战，
1.       通过这份《人工智能伦理问题建议书》；
2.       建议会员国根据本国的宪法规定和治理结构，采取适当步骤，包括必要的立法或其他措施，适用本建议书的各项条款，以便根据国际法和宪法规定，使建议书的原则和规范在本国司法管辖区内生效； 
3.       又建议会员国确保所有利益攸关方，包括人工智能技术领域的私营公司，承担起责任，并提请公共、私营和民间社会部门从事人工智能技术工作的管理部门、实体、研究和学术组织、机构和组织注意到本建议书，保证人工智能技术的开发和应用以健全的科学研究以及伦理分析和评估作为指导。
I.       适用范围
1.      本建议书涉及与人工智能有关的伦理问题。建议书将人工智能伦理作为一种系统性规范考量，以相互依存的价值观、原则和行动构成的不断发展的全面性框架为基础，旨在指导社会以负责任的方式应对人工智能技术对人类、社会、环境和生态系统产生的已知和未知影响，为社会接受或拒绝人工智能技术提供依据。建议书没有将伦理等同于法律、人权或技术的规范性补充，而是将伦理问题视为对人工智能技术进行规范性评估和指导的动态基础，以人的尊严、福祉和防止损害为导向，并立足于科技伦理。
2.      本建议书无意对人工智能作出唯一的定义，这种定义需随着时间的推移和技术的发展而变化。建议书旨在探讨人工智能系统中具有核心伦理意义并且在国际上已形成广泛共识的特征。因此，本建议书将人工智能系统视为有能力以类似于智能行为的方式处理信息的技术系统，通常包括推理、学习、感知、预测、规划或控制等方面。这一方法有三个重要因素：
(a)        人工智能系统是包含模型和算法的信息处理技术，这些模型和算法能够生成学习和执行认知任务的能力，从而在现实和虚拟环境中实现预测和决策等结果。在设计上，人工智能系统借助知识建模和知识表达，通过对数据的利用和对关联性的计算，在某些方面可以实现自主运行。人工智能系统可以包含若干种方法，包括但不限于：
(i)         机器学习，包括深度学习和强化学习，
(ii)       机器推理，包括规划、调度、知识表达和推理、搜索和优化，以及
(iii)     信息物理系统，包括物联网、机器人系统、社交机器人和涉及控制、感知及处理传感器所收集信息的人机交互以及人工智能系统工作环境中执行器的操作。
(b)        与人工智能系统有关的伦理问题涉及人工智能系统生命周期的各个阶段，此处系指从研究、设计、开发到配置和使用等各阶段，包括维护、运行、交易、融资、监测和评估、验证、使用终止、拆卸和终结。此外，人工智能行为者可以定义为在人工智能生命周期内至少参与一个阶段的任何行为者，可指自然人和法人，例如研究人员、程序员、工程师、数据科学家、终端用户、大型科技公司、中小企业、初创企业、大学、公共实体等。
(c)        人工智能系统引发了新型伦理问题，包括但不限于人工智能对决策、就业和劳动、社交、卫生保健、教育、媒体、表达自由、信息获取、隐私、民主、歧视和军事化的影响。此外，人工智能算法可能复制偏见，例如性别、种族和年龄偏见，从而加剧已有的各种形式的歧视、身份偏见和成见，由此产生了新的伦理挑战。其中一些问题与人工智能系统能够完成此前只有生物才能完成、甚至在有些情况下只有人类才能完成的任务有关。这些特点使得人工智能系统在人类实践和社会中以及在与环境和生态系统的关系中，可以起到影响深远的新的作用，为儿童和青年的成长、培养对于世界和自身的认识、批判性地认识媒体和信息以及学会作出决定创造了新的环境。从长远看，人工智能系统可能挑战人类特有的对于经验和能动作用的感知，在人类的自我认知、社会、文化和环境的互动、自主性、能动性、价值和尊严方面引发更多关切。
3.      秉承教科文组织世界科学知识与技术伦理委员会（COMEST）在《2019年人工智能伦理问题初步研究》中的分析，本建议书特别关注人工智能系统与教育、科学、文化、传播和信息等教科文组织核心领域有关的广泛伦理影响：
(a)        教育，这是因为生活在数字化社会需要新的教育实践，需要伦理反思、批判性思维、负责任的设计实践和新的技能，因为这对劳动力市场和就业能力都有影响。
(b)        最广泛意义上的科学，包括从自然科学、医学到社会科学和人文科学等所有学术领域，这是由于人工智能技术带来了新的研究能力，影响到我们关于科学认识和解释的观念，为决策开辟了新的基础。
(c)        文化特性和多样性，这是由于人工智能技术可以丰富文化和创意产业，但也会导致文化内容的供应、数据、市场和收入更多地集中在少数行为者手中，可能对语言、媒体、文化表现形式、参与和平等的多样性和多元化产生负面影响。
(d)        传播和信息，这是由于人工智能技术在处理、组织和提供信息方面起到日益重要的作用，很多现象引发了与信息获取、虚假信息、错误信息、误解、新型社会叙事兴起、歧视、表达自由、隐私、媒体和信息素养等有关的问题，自动化新闻、通过算法提供新闻、对社交媒体和搜索引擎上的内容进行审查和管理只是其中几个实例。
4.      本建议书的对象是既作为人工智能行为者、又负责针对人工智能系统的整个生命周期制定法律和监管框架并促进商业经营责任的国家。此外，建议书为贯穿人工智能系统生命周期的伦理影响评估奠定了基础，从而为包括私营部门在内的所有人工智能行为者提供伦理指南。
II.     宗旨和目标
5.      本建议书旨在提供基础，让人工智能系统可以造福人类、个人、社会、环境和生态系统，同时防止危害。
6.      全球已有多个组织制定了人工智能伦理框架，本建议书旨在额外提供一部全球公认的规范性文书，不仅注重阐明价值观和原则，而且着力于通过具体的政策建议切实落实这些价值观和原则，并且着重强调性别平等以及环境和生态系统保护等问题。
7.      由于与人工智能有关的伦理问题十分复杂，需要国际、地区和国家各个层面和各个部门的众多利益攸关方开展合作，故而本建议书的宗旨是让利益攸关方能够在全球和文化间对话的基础上共同承担责任。
8.      本建议书的目标如下：
(a)        提供关于价值观、原则和行动的普遍框架，指导各国制定与人工智能有关的立法、政策或其他文书；
(b)        指导个人、团体、社群、机构和私营公司的行动，确保将伦理规范嵌入人工智能系统生命周期的各个阶段；
(c)        在人工智能系统生命周期的各个阶段促进尊重人的尊严和性别平等，保障当代和后代的利益，保护人权、基本自由、环境和生态系统；
(d)        推动多利益攸关方、多学科和多元化对话，讨论与人工智能系统有关的伦理问题；以及
(e)        促进对人工智能领域进步和知识的公平获取以及惠益共享，特别关注包括最不发达国家、内陆发展中国家和小岛屿发展中国家在内的中低收入国家的需求和贡献。
III.    价值观和原则
9.      首先，人工智能系统生命周期的所有行为者都应尊重下文所载的价值观和原则，并通过修订现行和制定新的法律法规和业务准则来促进这些价值观和原则。这必须遵守国际法以及国际人权法、原则和标准，并应符合社会、政治、环境、教育、科学和经济可持续性目标。
10.    价值观作为催人奋进的理想，在制定政策措施和法律规范方面起到强有力的作用。下文概述的一系列价值观可以激发良好的行为，是确立原则的基础；原则更为具体地阐述了作为其根本的价值观，以便更易于在政策声明和行动中落实这些价值观。
11.    下文概述的所有价值观和原则本身都是可取的，但在任何实际情况下都会不可避免地对这些价值观和原则进行权衡取舍，需要根据具体情况作出复杂的优先排序，同时又不损害其他原则和价值观。在权衡时应考虑到与相称性及合法目的有关的关切。要审慎处理这些情况，通常需要在国际人权法、标准和原则的指导下，与广泛的相关利益攸关方合作，发挥社会对话以及伦理审议、尽职调查和影响评估的作用。
12.    人工智能系统生命周期的可信度和完整性（如能实现）可以造福人类、个人、社会、环境和生态系统，并且可以体现出本建议书提出的价值观和原则。人们应有充分的理由相信人工智能系统可以实现共同惠益，同时采取充分的措施来降低风险。实现可信度的一项基本要求是，人工智能系统在整个生命周期内都受到政府、私营公司、独立的民间社会和其他利益攸关方的监测。由于可信度是本文件所载各项原则得到落实的结果，本建议书提出的政策行动建议均旨在提升人工智能生命周期各个阶段的可信度。
III.1.      价值观
尊重、保护和促进人的尊严、人权和基本自由
13.    每个人的尊严构成了人权和基本自由这一不可分割的体系的基础，在人工智能系统的整个生命周期内都至关重要。人的尊严系指承认每个人的内在价值，因此，尊严无关性别、语言、宗教、政治或其他见解、民族、族裔、土著或社会出身、性取向和性别认同、财产、出生、残疾、年龄或其他状况。
14.    在人工智能系统生命周期的任何阶段，任何人都不应受到身体、经济、社会、政治或精神方面的损害。在人工智能系统的整个生命周期内，每个人的生活质量都应得到改善，而“生活质量”的定义只要不侵犯或践踏人权或人的尊严，应由个人或群体来决定。
15.    在人工智能系统的整个生命周期内，人会与人工智能系统展开互动，接受这些系统提供的帮助，例如照顾弱势者，包括但不限于儿童、老年人、残疾人或病人。在这一互动过程中绝不应将人物化，不应损害人的尊严，也不应侵犯或践踏人权。
16.    在人工智能系统的整个生命周期内，必须尊重、保护和促进人权和基本自由。各国政府、私营部门、民间社会、国际组织、技术界和学术界在介入与人工智能系统生命周期有关的进程时，必须尊重人权文书和框架。新技术应提供新手段倡导、捍卫和行使人权，而不是侵犯人权。
环境和生态系统的蓬勃发展
17.    在人工智能系统生命周期内，应认识到并促进环境和生态系统的蓬勃发展。此外，环境和生态系统事关人类和其他生物能否享受人工智能进步带来的惠益。
18.    参与人工智能系统生命周期的所有行为者都必须遵守相关国际法和国内立法、标准和做法，例如旨在保护和恢复环境和生态系统以及促进可持续发展的预防措施。这些行为者应减少人工智能系统对环境的影响，包括但不限于碳足迹，确保将气候变化和环境风险因素降到最低，防止会加剧环境恶化和生态系统退化的对自然资源的不可持续开采、使用和改造。
确保多样性和包容性
19.    在人工智能系统的整个生命周期内，应确保尊重、保护和促进多样性和包容性，至少要符合国际人权法、标准和原则以及人口、文化、性别和社会多样性和包容性。要做到这一点，可以促进所有个人或按性别、语言、宗教、政治或其他见解、民族、族裔、土著或社会出身、性取向和性别认同、财产、出生、残疾、年龄或其他状况划分的群体积极参与人工智能系统生命周期。应监测和处理任何同质化倾向。
20.    对于生活方式、信仰、观点、表达形式或个人经验的多重选择，包括对于人工智能系统的选择使用以及这些架构的共同设计，在人工智能系统生命周期的任何阶段都不应受到任何限制。
21.    此外，针对一些社区缺乏必要的技术基础设施、教育和技能以及法律框架的情况，特别是在中低收入国家、最不发达国家、内陆发展中国家和小岛屿发展中国家，应努力找到解决办法，绝不能加以利用。
和谐与和平共处
22.    人工智能行为者应为实现和谐与和平的生活起到促进作用，确保建设人人必将受益的相互关联的未来。和谐与和平共处的价值观表明，人工智能系统在整个生命周期内都有可能为所有生物之间及其与自然环境之间的相互关联作出贡献。
23.    人与人之间相互联系的概念是基于这样一种认识，每个人都属于一个更大的整体，当其他人以任何方式受到削弱时，这个整体就会被削弱。要实现和谐与和平共处，需要一种有机、直接、出自本能的团结纽带，其特点是不懈地寻求非冲突的和平关系，倾向于在最广泛的意义上与他人达成共识以及与自然环境和谐共处。 
24.    这一价值观要求在人工智能系统的整个生命周期内促进和平，人工智能系统生命周期的各个程序不得隔离或物化人，不得危害人类安全，不得分裂个人和群体或使之相互对立，也不得威胁人类、非人类和自然环境之间的和谐共存，因为这将对人类整体产生负面影响。 
III.2.      原则
相称性和不损害
25.    应该认识到，人工智能技术本身并不能确保人类、环境和生态系统的繁荣。况且，与人工智能系统生命周期有关的任何进程都不得超出实现合法目的或目标所需的范围，并应切合具体情况。假如对人类、环境或生态系统可能造成任何损害，应确保落实风险评估程序，并采取措施以防止发生此类损害。
26.    应从以下方面证明选择人工智能方法的合理性：(a) 为实现特定合法目标而选取的人工智能方法应是可取和相称的；(b) 选取的人工智能方法不得对本文件提出的基本价值观产生负面影响；(c) 人工智能方法应切合具体情况，并应建立在严谨的科学基础上。在涉及生死抉择的情况下，应由人类作出最终决定。
安全和安保
27.    在人工智能系统的整个生命周期内，应避免意外伤害（安全风险）和易受攻击的脆弱性（安保风险），确保人类、环境和生态系统的安全和安保。开发可持续和保护隐私的数据获取框架，促进利用优质数据更好地训练人工智能模型，可以实现有安全和安保保障的人工智能。
公平和非歧视
28.    人工智能行为者应尊重公平，从而促进社会正义。公平意味着在地方、国家和国际层面共享人工智能技术的惠益，同时又考虑到不同年龄组、文化体系、不同语言群体、残疾人、女童和妇女以及处境不利、边缘化和弱势群体的具体需求。在地方层面，要努力让社区能够用其选择的语言获取人工智能系统，并应尊重不同文化。在国家层面，政府有义务在获取和参与人工智能系统生命周期的问题上在城乡之间以及在所有人当中表现出公平性，无论性别、语言、宗教、政治或其他见解、民族、族裔、土著或社会出身、性取向和性别认同、财产、出生、残疾、年龄或其他状况如何。在国际层面，技术最先进的国家有义务团结最落后的国家，确保共享人工智能技术的惠益，使得后者通过获取和参与人工智能系统生命周期促进在信息、传播、文化、教育、研究、社会经济和政治稳定方面建立更加公平的世界秩序。
29.    人工智能行为者应尽一切努力，在人工智能系统的整个生命周期内尽量减少和避免强化或固化基于身份偏见的不适当的社会—技术偏见，确保人工智能系统的公平。对于不公平的算法决定和歧视应可以作出补救。
30.    此外，在人工智能系统的整个生命周期内，需要应对歧视、数字和知识鸿沟及全球不平等（包括在技术、数据、连接性、知识和技能的获取方面）以及受影响社区的参与（作为设计阶段的一部分）问题，以便让每个人都得到公平对待。
可持续性
31.    可持续社会的发展，有赖于实现一系列复杂的社会、文化、经济和环境目标。人工智能技术的出现可能有利于可持续性目标，但也可能阻碍这些目标的实现，这取决于处在不同发展水平的国家如何应用人工智能技术。因此，对人工智能技术的社会、文化、经济和环境影响所进行的持续评估，应充分考虑到人工智能技术对于可持续性这个目前由联合国可持续发展目标所确定的涉及多个方面且不断变化的系列目标的影响。
隐私
32.    隐私权对于保护人的尊严、自主权和能动性不可或缺，在人工智能系统的整个生命周期内必须在个人和集体两个层面尊重、保护和促进隐私权。重要的是，人工智能所用数据的收集、使用、共享、归档和删除方式，必须符合本建议书提出的价值观和原则。
33.    监管机构应在国家或超国家层面建立适当的数据保护框架和治理机制，这些框架和机制受到司法系统的保护，并在人工智能系统的整个生命周期内得到保障。此类保护框架和机制涉及数据的收集、控制和使用、数据主体行使权利以及个人要求删除个人数据的权利，确保个人数据的处理以及数据的个人化、去个人化和再个人化拥有合法的目的和有效的法律依据，并确保数据的透明度、对敏感数据的适当保护和有效的独立监督。
34.    需要对算法系统开展深入的隐私影响评估，其中包括使用算法系统的社会和伦理考量以及通过设计方法对于隐私的创新使用。
人类的监督和决定
35. 应始终可以将人工智能系统生命周期的任何阶段的伦理和法律责任赋予自然人或现有法人实体。因此，人类监督不仅指个人监督，在适当情况下也指公共监督。
36.    在某些情况下，出于效率性的考虑，人类有时不得不依赖人工智能系统，但依然要由人类来决定是否在有限情形下出让控制权，这是由于人类在决策和行动上可以借助人工智能系统，但人工智能系统永远无法取代人类的最终责任和问责。
透明度和可解释性
37.    人工智能系统的透明度往往是确保基本人权和伦理原则得到尊重、保护和促进的重要先决条件。透明度是切实落实相关国家和国际责任立法的必要因素。
38.    在人工智能系统的整个生命周期内都需要努力提高人工智能系统的透明度和可解释性，以支持民主治理，但透明度和可解释性的程度应始终切合具体情况，在透明度和可解释性与安全和安保等其他原则之间会存在某些权衡取舍。在根据人工智能算法作出决定时，人们有权知道，并且在这些情况下有权要求或请求私营公司或公共机构提供解释性信息。
39.    从社会—技术角度来看，提高透明度有助于建设更加和平、公正和包容的社会。提高透明度有利于开展公众监督，这可以减少腐败和歧视，还有助于发现和防止对人权产生的负面影响。透明度有助于人类信任人工智能系统。具体到人工智能系统，透明度可以帮助人们了解人工智能系统各个阶段是如何按照该系统的具体环境和敏感度设定的。透明度还包括深入了解可以影响特定预测或决定的因素，以及了解是否具备适当的保证（例如安全或公平措施）。在预计会对人权产生严重不利影响的情况下，透明度还可能要求共享特定代码或数据集。
40.    可解释性是指让人工智能系统的结果可以理解，并提供阐释说明。人工智能系统的可解释性也指各个算法模块的输入、输出和行为的可解释性及其如何促成系统结果。因此，可解释性与透明度密切相关，结果和导致结果的子过程应是可理解和可追溯的，并且应切合使用环境。
41.    透明度和可解释性与适当的责任和问责措施以及人工智能系统的可信度密切相关。
责任和问责
42.    在人工智能系统的整个生命周期内，人工智能行为者应根据现行国家法律和国际法，特别是国际人权法、原则和标准以及伦理准则，承担伦理和法律责任，尊重、保护和促进人权，并促进保护环境和生态系统。以任何方式基于人工智能系统作出的决定和行动，其伦理责任和义务最终都应由人工智能行为者承担。
43.    应建立适当的监督、影响评估和尽职调查机制，确保在人工智能系统的整个生命周期内对人工智能系统及其影响实施问责。技术和体制方面的设计都应确保人工智能系统（的运行）可审计和可追溯，特别是要应对与人权之间的冲突以及对环境和生态系统福祉的威胁。
认识和素养
44.    应通过政府、政府间组织、民间社会、学术界、媒体、社区领袖和私营部门共同领导的开放且可获取的教育、公民参与、数字技能和人工智能伦理问题培训、媒体和信息素养及培训，同时兼顾现有的语言、社会和文化多样性，促进公众对于人工智能技术和数据价值的认识和理解，确保公众的有效参与，让所有社会成员都能够就使用人工智能系统作出知情决定，避免受到不当影响。
45.    了解人工智能系统的影响，应包括了解人权、借助人权以及促进人权。这意味着在接触和理解人工智能系统之前，应首先了解人工智能对于人权和获取权利产生的影响。
多利益攸关方以及适应性治理和协作
46.    对于数据的使用应尊重国际法和主权。数据主权是指各国根据国际法，对于在境内生成或入境的数据进行监管，并采取措施，力争在尊重隐私权和其他人权的基础上对数据进行有效监管。
47.    多方利益攸关方参与人工智能系统的整个生命周期，是实现包容的人工智能治理、共享人工智能的惠益、公平的技术进步及其为发展目标所作贡献的必要因素。利益攸关方包括但不限于政府、政府间组织、技术界、民间社会、研究人员和学术界、媒体、教育、决策者、私营公司、人权机构和平等机构、反歧视监测机构以及儿童和青年团体。必须采用开放标准和互可操作性原则，以促进协作。必须采取措施，兼顾技术的变化和新利益攸关方群体的出现，便于边缘化群体、社区和个人进行实际干预。
IV.    政策行动领域
48.    以下政策领域所述的政策行动是对本建议书提出的价值观和原则的具体落实。主要行动是会员国建立政策框架或机制，并通过开展多种行动，例如协助所有利益攸关方制定伦理影响评估和尽职调查工具，确保私营公司、学术和研究机构以及民间社会等其他利益攸关方遵守这些框架或机制。此类政策或机制的制定过程应向所有利益攸关方开放，并应考虑到各会员国的具体情况和优先事项。教科文组织可以作为合作伙伴，支持会员国制定、监测和评估政策机制。
49.    教科文组织认识到，会员国在科学、技术、经济、教育、法律、规范、基础设施、社会、文化和其他方面，处于实施本建议书的不同准备阶段。需要指出的是，这里的“准备”是一种动态。因此，为切实落实本建议书，教科文组织将：(1) 制定准备状态评估方法，协助会员国确定其准备进程各个方面在特定时刻的所处状态；(2) 确保支持会员国制定全球公认的人工智能技术伦理影响评估（EIA）方法，分享最佳做法、评估准则、其他机制和分析工作。
政策领域1：伦理影响评估
50.    会员国应开展影响评估，确定并评估人工智能系统的惠益、关切和风险以及预防、减轻和监测风险的措施。伦理影响评估应根据本建议书提出的原则，确定对人权（特别是但不限于弱势群体的权利）、劳工权利、环境和生态系统产生的影响以及伦理和社会影响。
51.    会员国和私营公司应建立尽职调查和监督机制，确定、防止并减轻人工智能系统对人权、法治和包容性社会产生的影响，并说明如何处理这些影响。会员国还应能够评估人工智能系统对贫困问题产生的社会经济影响，确保人工智能技术在目前和未来的大规模应用不会加剧各国之间以及国内的贫富差距和数字鸿沟。为做到这一点，针对获取信息的权利，包括私营实体掌握的涉及公共利益的信息，应实行有执行力的透明度协议。
52.    会员国和私营公司应采取适当措施，监测人工智能系统生命周期的各个阶段，包括用于决策的算法的性能、数据以及参与这一过程的人工智能行为者，特别是在公共服务领域和需要与终端用户直接互动的领域。
53.    各国政府应采用监管框架，其中特别针对公共管理部门提出人工智能系统伦理影响评估程序，以预测后果、减少风险、避免有害后果、促进公民参与并应对社会挑战。评估还应确立适当的监督机制，包括确定可审计性、可追溯性和可解释性，从而能够评估算法、数据和设计流程，并且包括对人工智能系统的外部审查。公共管理部门开展的伦理影响评估应透明，并向公众开放。此类评估还应具备多学科、多利益攸关方、多文化、多元化和包容等特性。鼓励会员国制定机制和工具，例如监管沙箱或测试中心，以便能够采用多学科和多利益攸关方的方式监测并评估影响。应要求公共管理部门引入适当的机制和工具，监测这些部门实施和/或部署的人工智能系统。
54.    会员国应为与人工智能伦理问题有关的举措和政策建立监测和评估机制。可行的机制包括：记录符合人权与合乎伦理的人工智能系统发展情况的资料库；经验教训分享机制，会员国可以借此就其政策和举措向其他会员国征求反馈意见；面向所有人工智能行为者的指南，用以评估其对本文件所载政策建议的遵守情况；以及，后续工具。应以国际人权法、标准和原则作为人工智能系统伦理评估的一部分。
政策领域2：伦理治理和管理
55.    会员国应确保所有人工智能治理机制均具备包容性、透明性、多学科、多边（包括可以跨界减轻损害和作出补救）和多利益攸关方等特性。治理应包括预测、保护、监测影响、执行和补救等方面。
56.    会员国应实施有力的执行机制和补救行动，确保调查并补救人工智能系统给用户造成的损害，确保人权和法治在数字世界与现实世界中同样得到尊重。此类机制和行动应包括私营公司提供的补救机制。为此，应提升人工智能系统的可审计性和可追溯性。此外，会员国应加强履行这项关照义务的机构能力，并应与研究人员和其他利益攸关方合作调查、防止并减少对于人工智能系统的潜在恶意使用。
57.    鼓励会员国根据应用领域的敏感程度、对人类生命、环境和生态系统的预期影响以及本建议书提出的其他伦理考量，考虑多种形式的柔性治理，例如人工智能系统认证机制和此类认证的相互承认。此类机制可以包括针对系统、数据和伦理准则遵守情况的不同层面的审计，并应由各国获得授权的部门进行验证。另一方面，此类机制不得因要求开展大量文书工作而妨碍创新或是让中小企业或初创企业处于不利地位。此类机制还包括定期监测，在人工智能系统的整个生命周期内确保系统的稳健性、持续完整性和遵守伦理准则，必要时可要求重新认证。
58.    应要求政府和公共管理部门对现有和拟议的人工智能系统进行自我评估，其中特别应包括对采用人工智能是否适当进行评估，如果适当则应开展进一步评估，确定适当的方法，并评估采用这种方法是否有违任何人权法、标准和原则。
59.    会员国应鼓励公共实体、私营公司和民间组织吸收多方利益攸关方参与其人工智能治理工作，并考虑增设独立的人工智能伦理问题干事岗位或某种其他机制，负责监督伦理影响评估、审计和持续监测工作，确保对于人工智能系统的伦理指导。鼓励会员国、私营公司和民间组织在教科文组织的支持下，创设独立的人工智能伦理问题干事网络，在国家、地区和国际层面支持这一进程。
60.    会员国应促进数字生态系统的发展和获取，以便在国家层面发展合乎伦理的人工智能系统，同时鼓励国际合作。此类生态系统特别包括数字技术和基础设施，在适当情况下还包括人工智能知识共享机制。在这方面，会员国应考虑审查其政策和监管框架，包括关于信息获取和政务公开的政策和监管框架，以反映出人工智能方面的具体要求和促进机制，例如公共资金资助或公有数据和源代码开放式存储库以及数据信托机制，以支持安全、公平、合法及合乎伦理的数据共享。
61.    会员国应与国际组织、跨国公司、学术机构和民间社会合作建立机制，确保所有会员国积极参与关于人工智能治理的国际讨论，特别是中低收入国家，尤其是最不发达国家、内陆发展中国家和小岛屿发展中国家。可以通过提供资金、确保平等的地区参与或任何其他机制来实现这一目标。此外，为确保人工智能论坛的包容性，会员国应为人工智能行为者的出入境提供便利，特别是中低收入国家，尤其是最不发达国家、内陆发展中国家和小岛屿发展中国家的行为者，以便其参加此类论坛。
62.    修订关于人工智能系统的现行国家法律或制定新的法律，必须遵守国际人权法，并在人工智能系统的整个生命周期内促进人权和基本自由。随着人工智能技术的发展，还应采取以下形式促进人权和基本自由：治理举措；关于人工智能系统的合作实践的良好范例；国家及国际技术和方法准则。包括私营部门在内的多个部门在其关于人工智能系统的实践中必须利用现行和新的文书以及本建议书，尊重、保护和促进人权和基本自由。
63.    会员国应提供人权机制、人工智能的社会及经济影响监测和监督机制以及其他治理机制，例如独立的数据保护机关、部门监督、负责监督购置人工智能系统用于人权敏感用途（例如刑事司法、执法、福利、就业、卫生保健等）的公共机构，以及独立的司法系统。
64.    会员国应确保政府和多边组织在保障人工智能系统的安全和安保方面起到主导作用。具体而言，会员国、国际组织和其他相关机构应制定国际标准，列出可衡量和可检测的安全和透明度等级，以便能够客观评估人工智能系统并确定合规水平。此外，会员国应对人工智能技术潜在安全和安保风险的战略研究提供持续支持，并应鼓励透明度和可解释性研究，在不同方面和不同层面（例如技术语言和自然语言）为这些领域投入更多资金。
65.    会员国应实施政策，在人工智能系统的整个生命周期内确保人工智能行为者的行动符合国际人权法、标准和原则，同时对于当前的文化和社会多样性，包括地方习俗和宗教传统，表现出认识和尊重。
66.    会员国应建立机制，要求人工智能行为者披露并打击人工智能系统结果和数据中任何类型的陈规定型观念，无论是设计使然还是出于疏忽，确保人工智能系统的训练数据集不会助长文化、经济或社会不平等、偏见，不会散播不可靠的信息，也不会传播反民主思想。应特别关注缺少数据的地区。
67.    会员国应实施政策，促进并提高人工智能开发团队和训练数据集的多样性，确保人工智能技术及其惠益的平等获取，特别是针对农村和城市地区的边缘化群体。
68.    会员国应酌情制定、审查并调整监管和法律框架，在人工智能系统生命周期的不同阶段对其内容和结果实施问责制和责任制。会员国应建立责任框架或澄清对现有框架的解释，确保为人工智能系统的结果和行为确定责任归属。此外，会员国在制定监管框架时，应特别考虑到最终责任和问责必须始终落实到自然人或法人身上，人工智能系统本身不应被赋予法人资格。为确保这一点，此类监管框架应符合人类监督原则，并确立着眼于人工智能系统生命周期不同阶段的行为者和技术流程的综合性方法。
69.    会员国应增强司法机构根据法治和国际标准作出与人工智能系统有关决定、包括在其审议中使用人工智能系统的决定的能力，同时确保坚持人类监督原则。
70.    为在空白领域确立规范或调整现有的法律框架，会员国应让所有人工智能行为者（包括但不限于研究人员、民间社会和执法部门的代表、保险公司、投资者、制造商、工程师、律师和用户）参与其中。这些规范可以发展成为最佳做法、法律和法规。进一步鼓励会员国采用样板政策和监管沙箱等机制，加快制定与新技术的飞速发展相适应的法律、法规和政策，确保法律法规在正式通过之前能够在安全环境下进行测试。会员国应支持地方政府制定符合国家和国际法律框架的地方政策、法规和法律。
71.    会员国应对人工智能系统的透明度和可解释性提出明确要求，以便确保人工智能系统整个生命周期的可信度。此类要求应包括影响机制的设计和实施，其中要考虑到每个特定人工智能系统的应用领域的性质（是否为高风险领域，例如执法、安全、教育、招聘和卫生保健？）、预期用途（在破坏安全和侵犯人权方面存在哪些风险？）、目标受众（谁需要信息？）和可行性（算法是否可以解释，在准确性和可解释性之间作出了哪些权衡取舍？）。
政策领域3：数据政策
72.    会员国应努力制定数据治理战略，确保持续评估人工智能系统训练数据的质量，包括数据收集和选择过程的充分性、适当的安全和数据保护措施以及从错误中学习和在所有人工智能行为者之间分享最佳做法的反馈机制。在收集元数据和用户隐私之间保持平衡，应是此类战略的一项首要目标。
73.    会员国应采取适当的保障措施，承认并保护个人的基本隐私权，包括通过或执行可以提供适当保护且符合国际法的法律框架。会员国应大力鼓励包括私营公司在内的所有人工智能行为者遵守现行国际标准，特别是要开展隐私影响评估，作为伦理影响评估的一部分，其中要考虑到预期数据处理产生的更广泛的社会经济影响，并在其系统中采用从设计入手保护隐私的做法。在人工智能系统的整个生命周期内应尊重、保护和促进隐私。
74.    会员国应确保个人可以保留对于其个人数据的权利，并确保保护框架特别预见到以下问题：透明度；关于处理敏感数据的适当保障；最高程度的数据安全；有效和实际的问责方案和机制；数据主体充分享有权利，特别是人工智能系统中其个人数据的访问权和删除权；数据用于商业目的（例如精准定向广告）或跨境转移时提供适当程度的保护；作为数据治理机制一部分的有效独立监督，此类机制尊重数据主权，并且在数据主权与国际信息自由流通（包括数据获取）的惠益之间保持平衡。
75.    会员国应制定数据政策或等效框架，或是加强现有政策或框架，确保强化个人数据和敏感数据的安全，这些数据一旦泄露，可能会给个人造成特殊损害、伤害或困难。相关实例包括：与犯罪、刑事诉讼、定罪以及相关安全措施有关的数据；生物识别和基因数据；与族裔或社会出身、政见、工会会籍、宗教和其他信仰、健康和性生活有关的个人数据。
76.    会员国应利用人工智能系统改善信息和知识的获取，包括数据存放，消除在获取人工智能系统生命周期方面的差距。这可以包括支持研究人员和开发人员强化表达自由和信息获取，更多地主动披露官方数据和信息。会员国还应促进开放数据，包括为公共资金资助或公有数据和源代码建立开放式存储库。
77.    会员国应确保人工智能数据集的总体质量和稳健程度，并在监督数据集的收集和使用方面保持警惕。这包括在可能和可行的情况下投资建立黄金标准数据集，包括开放、可信、多样化、建立在有效的法律基础上并且按法律要求征得数据主体同意的数据集。应鼓励制定数据集标注标准，以便于确定数据集的收集方式及其特性。
78.    按照联合国秘书长数字合作高级别小组报告的建议，会员国应在联合国和教科文组织的支持下，酌情采用“数字共享”方式处理数据，提高工具、数据集和数据托管系统接口的互可操作性，鼓励私营公司酌情共享其收集的适用于研究或符合公共利益的数据。会员国还应促进公共和私营部门建立协作平台，在可信和安全的数据空间内共享优质数据。
政策领域4：发展与国际合作
79.    会员国和跨国公司应优先考虑人工智能伦理问题，在相关国际、政府间和多利益攸关方论坛上讨论与人工智能有关的伦理问题。
80.       会员国应确保人工智能在卫生保健、农业/食品供应、教育、媒体、文化、环境、水管理、基础设施管理、经济规划和增长及其他发展领域的应用符合本建议书提出的价值观和原则。
81.    会员国应通过国际组织，努力为人工智能促进发展提供国际合作平台，包括提供专业知识、资金、数据、领域知识和基础设施，以及促进技术专家和商业专家之间的合作，以应对挑战性发展问题，特别是针对中低收入国家，尤其是最不发达国家、内陆发展中国家和小岛屿发展中国家。
82.    会员国应努力促进人工智能研究和创新方面的国际合作，包括可以促进中低收入国家和其他地区（包括最不发达国家、内陆发展中国家和小岛屿发展中国家）的研究人员更多参与和领导的研究和创新中心及网络。
83.    会员国应促进国际组织、研究机构和跨国公司开展人工智能伦理问题研究，可以将这些研究作为公共和私营实体以合乎伦理的方式使用人工智能系统的基础，包括研究特定伦理框架在特定文化和背景下的适用性，以及将这些框架匹配技术上可行的解决方案的可能性。
84.    会员国应鼓励在人工智能领域开展国际合作与协作，以弥合地缘技术差距。在会员国与其民众之间、公共和私营部门之间以及全球北方和全球南方的会员国之间，应开展技术交流/磋商。
85.    会员国应制定并实施国际法律框架，鼓励各国和其他利益攸关方之间开展国际合作，并特别关注中低收入国家，尤其是最不发达国家、内陆发展中国家和小岛屿发展中国家的情况。
政策领域5：环境和生态系统
86.    在人工智能系统的整个生命周期内，会员国应评估对环境产生的直接和间接影响，包括但不限于其碳足迹、能源消耗以及为支持制造人工智能技术开采原材料对环境造成的影响。会员国应确保所有人工智能行为者遵守环境法律、政策和惯例。
87.    会员国应在必要和适当时采取激励措施，确保开发并采用基于权利、合乎伦理、由人工智能驱动的解决方案抵御灾害风险；监测并保护环境与生态系统，并促进其再生；保护地球。这些人工智能系统应在整个生命周期内吸收地方和土著社区的参与，并应支持循环经济做法以及可持续的消费和生产模式。例如，在必要和适当时可将人工智能系统用于以下方面：
(a)        支持自然资源的保护、监测和管理。
(b)        支持与气候有关问题的预防、控制和管理。
(c)        支持更加高效和可持续的粮食生态系统。
(d)        支持可持续能源的加速获取和大规模采用。
(e)        促成并推动旨在促进可持续发展的可持续基础设施、可持续商业模式和可持续金融主流化。
(f)         检测污染物或预测污染程度，协助相关利益攸关方确定、规划并实施有针对性的干预措施，防止并减少污染及曝露风险。 
88.    会员国在选择人工智能方法时，鉴于其中一些方法具有数据密集型或资源密集型特点以及对环境产生的不同影响，应确保人工智能行为者能够根据相称性原则，倾向于使用节约数据、能源和资源的人工智能方法。应制定要求，确保有适当证据表明人工智能应用将产生预期效果，或人工智能应用的附加保障措施可以支持其合理性。
政策领域6：性别
89.    会员国应确保数字技术和人工智能可以全面促进性别平等的实现；确保在人工智能系统生命周期的任何阶段，女童和妇女的权利和基本自由包括其安全和人格不受侵犯。此外，伦理影响评估应包含横向性别平等视角。
90.    会员国应从公共预算中划拨专项资金，用于资助与性别平等有关的计划，确保国家数字政策包含性别行动计划，制定旨在支持女童和妇女的具体政策，例如劳动力教育政策，确保女童和妇女不会被排除在人工智能驱动的数字经济之外。应考虑并落实专项投资，提供有针对性的计划和有性别针对性的语言，为女童和妇女参与科学、技术、工程和数学（STEM）领域提供更多机会，包括信息和通信技术（信通技术）学科，为女童和妇女的就业准备、就业能力、职业发展和专业成长提供更多机会。
91.    会员国应确保实现人工智能系统促进性别平等的潜力。会员国应保证这些技术不会加剧模拟世界中多个领域已经存在的巨大性别差距，这其中包括：性别工资差距；某些职业和活动的代表性差距；人工智能领域高级管理职位、董事会或研究团队的代表性差距；教育差距；数字/人工智能的获取、采用、使用和负担能力方面的差距；无偿工作和照料责任在社会中的不平等分配。
92.    会员国应确保性别陈规定型观念和歧视性偏见不会移置于人工智能系统。必须努力避免技术鸿沟对于实现性别平等、避免暴力侵害女童和妇女以及所有其他类型的性别认同产生复杂的负面影响。
93.    会员国应鼓励女性创业、参与并介入人工智能系统生命周期的各个阶段，提供并促进经济和监管方面的激励措施以及其他激励措施和支持计划，并制定政策，力争在学术界的人工智能研究方面实现性别均衡的参与，在数字/人工智能公司高级管理职位、董事会或研究团队中实现性别均衡的代表性。政府应确保创新、研究和技术方面的公共资金流向具有包容性和明确的性别代表性的计划和公司，并通过平权行动原则鼓励私人资金。此外，应制定并执行关于无骚扰环境的政策，同时鼓励传播关于如何在人工智能系统的整个生命周期内促进多样性的最佳做法。
94.    教科文组织可以协助建立最佳做法资料库，鼓励妇女和代表性不足的群体参与人工智能系统生命周期的各个阶段。
政策领域7：文化
95.    鼓励会员国酌情将人工智能系统纳入物质、文献和非物质文化遗产（包括濒危语言以及土著语言和知识）的保护、丰富、理解、推广和获取工作，例如酌情制定或更新与在这些领域应用人工智能系统有关的教育计划，确保采用针对机构和公众的参与式方法。
96.    鼓励会员国审查并应对人工智能系统产生的文化影响，特别是自动翻译和语音助手等自然语言处理应用程序给人类语言和表达的细微差别带来的影响。此类评估应有助于促进设计和实施相关战略，通过弥合文化差距和增进人类理解，最大限度地发挥人工智能系统的惠益，同时也应有助于了解减少自然语言使用等所带来的负面影响，这可能导致濒危语言、地方方言以及与人类语言和表达形式有关的语音和文化差异的消失。
97.    随着人工智能技术被用于创造、生产、推广和传播多种文化产品和服务，会员国应促进针对艺术家和创意专业人员的人工智能教育和数字培训，以评估人工智能技术在其专业领域的适用性，同时铭记保护文化遗产、多样性和艺术自由的重要性。
98.    会员国应促进当地文化产业和文化领域的中小企业对于人工智能工具的认识和评价，避免文化市场集中化的风险。
99.    会员国应吸引大型技术公司和其他利益攸关方参与进来，促进文化表现形式的多样化供应和多元化获取，特别要确保算法建议可以提高本地内容的知名度和可见性。
100. 会员国应促进在人工智能和知识产权的交汇点上开展新的研究，例如确定在人工智能系统整个生命周期内的众多利益攸关方当中，谁才是通过人工智能技术创作的作品的权利持有者。
101.  会员国应鼓励国家级博物馆、美术馆、图书馆和档案馆开发并使用人工智能系统，以突出其藏品价值，强化其数据库，并允许用户访问这些数据库。
政策领域8：教育和研究
102.  会员国应与国际组织、私营实体和非政府实体合作，向所有国家的公众提供充分的人工智能素养教育，以增强人们的权能，减少因广泛采用人工智能系统而造成的数字鸿沟和数字获取方面的不平等。
103.  会员国应促进人工智能教育“必备技能”的掌握，例如基本读写、计算、编码和数字技能、媒体和信息素养、批判性思维、团队合作、沟通、社会情感技能和人工智能伦理技能，特别是在相关技能教育存在明显差距的国家。
104.  会员国应促进关于人工智能发展的一般性宣传计划，其中包括人工智能技术带来的机会和挑战。这些计划对于非技术群体和技术群体来说都应简明易懂。
105.  会员国应鼓励开展关于以负责任的方式将人工智能技术应用于教学、教师培训和电子学习等课题的研究活动，以增加机会，减轻这一领域的挑战和风险。在开展这些研究活动的同时，应充分评估教育质量以及人工智能技术的应用对于学生和教师的影响。会员国还应确保人工智能技术可以增强师生的权能和体验，同时铭记情感和社会方面以及传统教育形式对于师生关系以及学生之间的关系至关重要，在讨论将人工智能技术应用于教育时应考虑到这一点。
106.  会员国应促进女童和妇女、不同族裔和文化以及残疾人参与各级人工智能教育计划，监测并与其他国家分享这方面的最佳做法。
107.  会员国应根据本国教育计划和传统，为各级教育开发人工智能伦理课程，促进人工智能技术技能教育与人工智能教育的人文、伦理和社会方面的交叉协作。应以当地语言开发人工智能伦理教育的在线课程和数字资源，特别是供残疾人使用的无障碍格式。
108.  会员国应通过投资发展此类研究，或提供激励措施，推动公共和私营部门投资这一领域，从而促进人工智能伦理问题研究。
109.  会员国应确保人工智能研究人员接受过伦理研究方面的培训，并要求他们将伦理考量纳入设计、产品和出版物中，特别是在分析其使用的数据集、数据集的标注方法以及结果的质量和范围方面。
110.  会员国应鼓励私营公司为科学界获取其数据用于研究提供便利，特别是在中低收入国家，尤其是最不发达国家、内陆发展中国家和小岛屿发展中国家。这种获取不得以牺牲隐私为代价。
111.  会员国应促进学术界和产业界人工智能研究领域的性别多样性，为女童和妇女进入该领域提供激励措施，建立机制消除人工智能研究界的性别陈规定型观念和骚扰行为，并鼓励学术界和私营实体分享关于如何提高性别多样性的最佳做法。
112.  为确保对人工智能研究进行批判性评估并适当监测可能出现的滥用或负面影响，会员国应确保人工智能技术今后的任何发展都应建立在严谨的科学研究基础上，并吸收除科学、技术、工程和数学（STEM）之外的其他学科，例如文化研究、教育、伦理学、国际关系、法律、语言学、哲学和政治学等，促进开展跨学科的人工智能研究。
113.  认识到人工智能技术为推进科学知识和实践提供了大好机会，特别是在以往采用模型驱动方法的学科中，会员国应鼓励科学界认识到使用人工智能的惠益、不足和风险；这包括努力确保通过数据驱动方法得出的结论完善且可靠。此外，会员国应欢迎并支持科学界在推动政策和促进人们认识到人工智能技术优缺点方面发挥作用。
政策领域9：经济和劳动
114.  会员国应评估并处理人工智能系统对所有国家劳动力市场的冲击及其对教育要求的影响，同时特别关注经济属于劳动密集型的国家。这可以包括在各级教育中引入更广泛的跨学科“核心”技能，为当前的劳动者和年轻世代提供可以在飞速变化的市场中找到工作的公平机会，并确保他们对于人工智能系统的伦理问题有所认识。除了传授专业技术技能和标记数据集等低技能任务知识之外，还应教授“学会如何学习”、沟通、批判性思维、团队合作、同理心以及在不同领域之间灵活运用知识的能力等技能。关键是要在有高需求的技能方面保持透明度，并围绕这些技能更新学校课程。
115.  会员国应支持政府、学术机构、产业界、劳工组织和民间社会之间的合作协议，以弥合技能要求方面的差距，让培训计划和战略与未来工作的影响和产业界的需求保持一致。应促进以项目为基础的人工智能教学和学习方法，使得私营公司、大学和研究中心可以建立伙伴关系。
116.  会员国应与私营公司、民间组织和其他利益攸关方（包括劳动者和工会）合作，确保高风险员工可以实现公平转型。这包括制定技能提升计划和再培训计划，建立在过渡期内保留员工的有效机制，以及为无法再培训的员工探索尝试“安全网”计划。会员国应制定并实施计划，研究并应对已确定的各项挑战，其中可能包括提升技能和再培训、加强社会保障、主动的行业政策和干预措施、税收优惠、新的税收形式等。应审慎审查并在必要时修改税制和其他相关条例，消解基于人工智能的自动化造成的失业后果。
117.  会员国应鼓励并支持研究人员分析人工智能系统对于当地劳动环境的影响，以预测未来的趋势和挑战。这些研究应调查人工智能系统对经济、社会和地域因素、人机互动和人际关系产生的影响，以便就提升技能和重新部署的最佳做法提出建议。
118.  会员国应制定机制，防止在人工智能系统的整个生命周期内出现垄断以及由此导致的不平等现象，无论是数据、研究、技术、市场或其他方面的垄断。会员国应评估相关市场，如存在垄断则应进行监管和干预，同时考虑到由于缺乏基础设施、人员能力和规章制度，中低收入国家，尤其是最不发达国家、内陆发展中国家和小岛屿发展中国家更多地面临着大型技术公司的剥削，并且更容易受到这种剥削。
政策领域10：健康和社会福祉
119. 会员国应努力利用有效的人工智能系统来改善人类健康并保护生命权，同时建立并维护国际团结，以应对全球健康风险和不确定性，并确保在卫生保健领域采用人工智能系统的做法符合国际法以及国际人权法、标准和原则。会员国应确保参与卫生保健人工智能系统的行为者会考虑到患者与家属的关系以及患者与医护人员关系的重要性。
120.  会员国应规范与广义的健康、特别是精神健康有关的人工智能系统的开发和部署，确保这些系统安全、有效、高效且具有科学和医学可靠性。此外，在数字健康干预等相关领域，大力鼓励会员国让患者及其代表积极参与系统开发的所有相关步骤。
121.  会员国应特别注重通过以下方式，规范人工智能应用于卫生保健领域的预测、检测和治疗方案：
(a)        确保监督，以尽可能减少偏见；
(b)        在开发算法时，确保将专业人员、患者、护理人员或服务用户作为“领域专家”纳入团队；
(c)        由于可能需要不间断监测，应适当注重隐私问题；
(d)        确保被分析的数据主体了解其数据的跟踪和分析情况，并给与知情同意；以及
(e)        确保人工护理以及最终的诊断和治疗决定由人类做出，同时肯定人工智能系统也可以协助人类工作。
122. 会员国应研究人工智能系统对于心理健康的潜在危害所产生的影响及如何加以调控的问题，例如深度抑郁、焦虑、社会隔离、成瘾、贩运、激进化、错误信息等。
123. 会员国应在研究的基础上，针对机器人的未来发展，制定关于人机互动及其对人际关系产生影响的准则，特别关注人类身心健康，尤其是应用于卫生保健领域的机器人、老年人和残疾人的护理机器人、教育机器人、玩具机器人、聊天机器人以及儿童和成人的陪伴机器人。此外，应利用人工智能技术的协助来提高机器人的安全性及其人体工程学使用，包括在人机工作环境中。
124.  会员国应确保人机互动遵守适用于任何其他人工智能系统的相同的价值观和原则，包括人权、在相互关系中促进多样性以及对弱势群体的保护。
125.  会员国应保护用户的权利，使其有权轻松识别与自己互动的对象是生物，还是模仿人类或动物特征的人工智能系统。
126.  会员国应实施政策，提高人们对于人工智能技术拟人化的认识，包括在提及人工智能技术时所使用的语言，并评估这种拟人化的表现形式、伦理影响和可能存在的局限性，特别是在人机互动的情况下和涉及到儿童时。
127.  会员国应鼓励并促进关于人与人工智能系统长期互动所产生影响的合作研究，特别注意这些系统对儿童和青年的心理和认知可能产生的影响。在开展此类研究时，应采用多种规范、原则、协议、学科方法，评估行为和习惯的改变，并审慎评估下游的文化和社会影响。
128.  会员国和所有利益攸关方应建立机制，让儿童和青年切实参与到关于人工智能系统对其生活和未来产生影响的对话、辩论和决策中。
129.  会员国应促进以负责任的方式使用人工智能系统，打击线上领域的仇恨言论和虚假信息，确保人工智能系统不会被用于制作和传播此类内容，特别是在选举期间。
130.  会员国应为媒体创造有利的环境，使媒体有权利和资源有效地报道人工智能系统的利弊，并在报道中利用人工智能系统。
V.          监测和评估
131.  会员国应根据具体国情、治理结构和宪法规定，采用定量和定性相结合的方法，以可信和透明的方式监测和评估与人工智能伦理问题有关的政策、计划和机制。为支持会员国，教科文组织可以从以下方面作出贡献：
(a)        在严谨的科学研究基础上，为人工智能技术的伦理影响评估制定全球公认的方法，包括在人工智能系统生命周期各个阶段的实施指南；
(b)        制定准备状态评估方法，协助会员国确定其准备进程各个方面在特定时刻的所处状态；
(c)        制定全球公认的方法，在事先和事后对照既定目标评估人工智能伦理政策和激励政策的效力和效率；
(d)        加强关于人工智能伦理政策的基于研究和证据的分析和报道，包括公布比较指数；以及
(e)        收集和传播关于人工智能伦理政策的进展、创新、研究报告、科学出版物、数据和统计资料，支持最佳做法分享和相互学习，推动实施本建议书。
132.  监测和评估过程应确保相关利益攸关方的广泛参与，包括但不限于不同年龄段的人、女童和妇女、残疾人、处境不利者、边缘化群体和弱势群体、土著社区以及来自不同社会经济背景的人。必须确保社会、文化和性别多样性，以期改善学习过程，加强调查结果、决策、透明度和成果问责制之间的联系。
133.     为促进与人工智能伦理问题有关的最佳政策和做法，应制定适当的工具和指标，以便根据商定的标准、优先事项和目标，包括关于处境不利、边缘化和弱势群体的具体目标，评估此类政策和做法的效力和效率，以及人工智能系统在个人和社会层面产生的影响。应通过系统方式持续监测和评估人工智能系统的影响以及相关的人工智能伦理政策和做法。这项工作应以国际商定的框架为基础，涉及对于私营和公共机构、提供方和计划的评估，包括自我评价，以及开展跟踪研究和制定一系列指标。数据收集和处理工作应遵守关于数据保护和数据隐私的国家立法。
134. 可行的监测和评估机制包括：人工智能伦理问题观察站，亦或在教科文组织各职能领域通过恪守伦理原则为现有举措作出的贡献；经验分享机制，供会员国就彼此的举措提供反馈意见；人工智能监管沙箱；面向所有人工智能行为者的评估指南，用以评估其对于本文件所述政策建议的遵守情况。
VI.         本建议书的使用和推广
135.  会员国和本建议书确定的所有其他利益攸关方必须尊重、促进和保护本建议书提出的人工智能伦理原则和标准，并应采取一切可行步骤，落实本建议书的政策建议。
136.  会员国应与在本建议书的范围和目标范畴内开展活动的所有国家和国际政府组织、非政府组织、跨国公司和科学组织合作，努力扩大并充实围绕本建议书采取的行动。制订全球公认的伦理影响评估方法和建立国家技术伦理委员会，可以作为这方面的重要工具。
VII.       本建议书的宣传
137.  教科文组织是负责宣传和传播本建议书的主要联合国机构，因此应与其他联合国实体合作开展工作，包括但不限于联合国秘书长数字合作高级别小组、世界科学知识与技术伦理委员会（COMEST）、国际生物伦理委员会（IBC）、政府间生物伦理委员会（IGBC）、国际电信联盟（ITU）、国际劳工组织（ILO）、世界知识产权组织（WIPO）、联合国儿童基金会（UNICEF）、联合国妇女署、联合国工业发展组织（UNIDO）、世界贸易组织（WTO）以及与人工智能伦理问题有关的其他相关联合国实体。
138.  教科文组织还应与其他国际和地区组织合作开展工作，包括但不限于非洲联盟（AU）、太平洋联盟、非洲大学协会（AAU）、东南亚国家联盟（ASEAN）、加勒比共同体（CARICOM）、加勒比电信联盟、加勒比公共服务协会、东部和南部非洲共同市场（COMESA）、拉丁美洲和加勒比国家共同体（CELAC）、欧洲委员会（CoE）、西非国家经济共同体（ECOWAS）、欧亚经济联盟（EAEU）、欧洲联盟（EU）、国际大学协会（IAU）、经济合作与发展组织（OECD）、欧洲安全与合作组织（OSCE）、南亚区域合作联盟（SAARC）、南部非洲发展共同体（SADC）、南方共同市场（MERCOSUR）、电气电子工程师学会（IEEE）、国际标准化组织（ISO）以及世界银行、美洲开发银行和非洲开发银行等国际融资机构。
139. 在教科文组织内部，促进和保护的任务属于各国政府和政府间机构的职权范围，但民间社会将是倡导公共部门利益的重要行为者，因此教科文组织需要确保和促进其合法性。
VIII.      最后条款
140.  应将本建议书作为整体加以理解，各项基本价值观和原则应视为相互补充且相互关联。
141.  本建议书的任何内容均不得解释为允许任何国家、其他社会行为者、群体或个人参与或从事任何有悖人权、基本自由、人类尊严以及对地球和生态系统的关怀的活动或行为。
