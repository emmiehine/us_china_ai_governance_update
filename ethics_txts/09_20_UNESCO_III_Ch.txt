III.    价值观和原则
9.      首先，人工智能系统生命周期的所有行为者都应尊重下文所载的价值观和原则，并通过修订现行和制定新的法律法规和业务准则来促进这些价值观和原则。这必须遵守国际法以及国际人权法、原则和标准，并应符合社会、政治、环境、教育、科学和经济可持续性目标。
10.    价值观作为催人奋进的理想，在制定政策措施和法律规范方面起到强有力的作用。下文概述的一系列价值观可以激发良好的行为，是确立原则的基础；原则更为具体地阐述了作为其根本的价值观，以便更易于在政策声明和行动中落实这些价值观。
11.    下文概述的所有价值观和原则本身都是可取的，但在任何实际情况下都会不可避免地对这些价值观和原则进行权衡取舍，需要根据具体情况作出复杂的优先排序，同时又不损害其他原则和价值观。在权衡时应考虑到与相称性及合法目的有关的关切。要审慎处理这些情况，通常需要在国际人权法、标准和原则的指导下，与广泛的相关利益攸关方合作，发挥社会对话以及伦理审议、尽职调查和影响评估的作用。
12.    人工智能系统生命周期的可信度和完整性（如能实现）可以造福人类、个人、社会、环境和生态系统，并且可以体现出本建议书提出的价值观和原则。人们应有充分的理由相信人工智能系统可以实现共同惠益，同时采取充分的措施来降低风险。实现可信度的一项基本要求是，人工智能系统在整个生命周期内都受到政府、私营公司、独立的民间社会和其他利益攸关方的监测。由于可信度是本文件所载各项原则得到落实的结果，本建议书提出的政策行动建议均旨在提升人工智能生命周期各个阶段的可信度。
III.1.      价值观
尊重、保护和促进人的尊严、人权和基本自由
13.    每个人的尊严构成了人权和基本自由这一不可分割的体系的基础，在人工智能系统的整个生命周期内都至关重要。人的尊严系指承认每个人的内在价值，因此，尊严无关性别、语言、宗教、政治或其他见解、民族、族裔、土著或社会出身、性取向和性别认同、财产、出生、残疾、年龄或其他状况。
14.    在人工智能系统生命周期的任何阶段，任何人都不应受到身体、经济、社会、政治或精神方面的损害。在人工智能系统的整个生命周期内，每个人的生活质量都应得到改善，而“生活质量”的定义只要不侵犯或践踏人权或人的尊严，应由个人或群体来决定。
15.    在人工智能系统的整个生命周期内，人会与人工智能系统展开互动，接受这些系统提供的帮助，例如照顾弱势者，包括但不限于儿童、老年人、残疾人或病人。在这一互动过程中绝不应将人物化，不应损害人的尊严，也不应侵犯或践踏人权。
16.    在人工智能系统的整个生命周期内，必须尊重、保护和促进人权和基本自由。各国政府、私营部门、民间社会、国际组织、技术界和学术界在介入与人工智能系统生命周期有关的进程时，必须尊重人权文书和框架。新技术应提供新手段倡导、捍卫和行使人权，而不是侵犯人权。
环境和生态系统的蓬勃发展
17.    在人工智能系统生命周期内，应认识到并促进环境和生态系统的蓬勃发展。此外，环境和生态系统事关人类和其他生物能否享受人工智能进步带来的惠益。
18.    参与人工智能系统生命周期的所有行为者都必须遵守相关国际法和国内立法、标准和做法，例如旨在保护和恢复环境和生态系统以及促进可持续发展的预防措施。这些行为者应减少人工智能系统对环境的影响，包括但不限于碳足迹，确保将气候变化和环境风险因素降到最低，防止会加剧环境恶化和生态系统退化的对自然资源的不可持续开采、使用和改造。
确保多样性和包容性
19.    在人工智能系统的整个生命周期内，应确保尊重、保护和促进多样性和包容性，至少要符合国际人权法、标准和原则以及人口、文化、性别和社会多样性和包容性。要做到这一点，可以促进所有个人或按性别、语言、宗教、政治或其他见解、民族、族裔、土著或社会出身、性取向和性别认同、财产、出生、残疾、年龄或其他状况划分的群体积极参与人工智能系统生命周期。应监测和处理任何同质化倾向。
20.    对于生活方式、信仰、观点、表达形式或个人经验的多重选择，包括对于人工智能系统的选择使用以及这些架构的共同设计，在人工智能系统生命周期的任何阶段都不应受到任何限制。
21.    此外，针对一些社区缺乏必要的技术基础设施、教育和技能以及法律框架的情况，特别是在中低收入国家、最不发达国家、内陆发展中国家和小岛屿发展中国家，应努力找到解决办法，绝不能加以利用。
和谐与和平共处
22.    人工智能行为者应为实现和谐与和平的生活起到促进作用，确保建设人人必将受益的相互关联的未来。和谐与和平共处的价值观表明，人工智能系统在整个生命周期内都有可能为所有生物之间及其与自然环境之间的相互关联作出贡献。
23.    人与人之间相互联系的概念是基于这样一种认识，每个人都属于一个更大的整体，当其他人以任何方式受到削弱时，这个整体就会被削弱。要实现和谐与和平共处，需要一种有机、直接、出自本能的团结纽带，其特点是不懈地寻求非冲突的和平关系，倾向于在最广泛的意义上与他人达成共识以及与自然环境和谐共处。 
24.    这一价值观要求在人工智能系统的整个生命周期内促进和平，人工智能系统生命周期的各个程序不得隔离或物化人，不得危害人类安全，不得分裂个人和群体或使之相互对立，也不得威胁人类、非人类和自然环境之间的和谐共存，因为这将对人类整体产生负面影响。 
III.2.      原则
相称性和不损害
25.    应该认识到，人工智能技术本身并不能确保人类、环境和生态系统的繁荣。况且，与人工智能系统生命周期有关的任何进程都不得超出实现合法目的或目标所需的范围，并应切合具体情况。假如对人类、环境或生态系统可能造成任何损害，应确保落实风险评估程序，并采取措施以防止发生此类损害。
26.    应从以下方面证明选择人工智能方法的合理性：(a) 为实现特定合法目标而选取的人工智能方法应是可取和相称的；(b) 选取的人工智能方法不得对本文件提出的基本价值观产生负面影响；(c) 人工智能方法应切合具体情况，并应建立在严谨的科学基础上。在涉及生死抉择的情况下，应由人类作出最终决定。
安全和安保
27.    在人工智能系统的整个生命周期内，应避免意外伤害（安全风险）和易受攻击的脆弱性（安保风险），确保人类、环境和生态系统的安全和安保。开发可持续和保护隐私的数据获取框架，促进利用优质数据更好地训练人工智能模型，可以实现有安全和安保保障的人工智能。
公平和非歧视
28.    人工智能行为者应尊重公平，从而促进社会正义。公平意味着在地方、国家和国际层面共享人工智能技术的惠益，同时又考虑到不同年龄组、文化体系、不同语言群体、残疾人、女童和妇女以及处境不利、边缘化和弱势群体的具体需求。在地方层面，要努力让社区能够用其选择的语言获取人工智能系统，并应尊重不同文化。在国家层面，政府有义务在获取和参与人工智能系统生命周期的问题上在城乡之间以及在所有人当中表现出公平性，无论性别、语言、宗教、政治或其他见解、民族、族裔、土著或社会出身、性取向和性别认同、财产、出生、残疾、年龄或其他状况如何。在国际层面，技术最先进的国家有义务团结最落后的国家，确保共享人工智能技术的惠益，使得后者通过获取和参与人工智能系统生命周期促进在信息、传播、文化、教育、研究、社会经济和政治稳定方面建立更加公平的世界秩序。
29.    人工智能行为者应尽一切努力，在人工智能系统的整个生命周期内尽量减少和避免强化或固化基于身份偏见的不适当的社会—技术偏见，确保人工智能系统的公平。对于不公平的算法决定和歧视应可以作出补救。
30.    此外，在人工智能系统的整个生命周期内，需要应对歧视、数字和知识鸿沟及全球不平等（包括在技术、数据、连接性、知识和技能的获取方面）以及受影响社区的参与（作为设计阶段的一部分）问题，以便让每个人都得到公平对待。
可持续性
31.    可持续社会的发展，有赖于实现一系列复杂的社会、文化、经济和环境目标。人工智能技术的出现可能有利于可持续性目标，但也可能阻碍这些目标的实现，这取决于处在不同发展水平的国家如何应用人工智能技术。因此，对人工智能技术的社会、文化、经济和环境影响所进行的持续评估，应充分考虑到人工智能技术对于可持续性这个目前由联合国可持续发展目标所确定的涉及多个方面且不断变化的系列目标的影响。
隐私
32.    隐私权对于保护人的尊严、自主权和能动性不可或缺，在人工智能系统的整个生命周期内必须在个人和集体两个层面尊重、保护和促进隐私权。重要的是，人工智能所用数据的收集、使用、共享、归档和删除方式，必须符合本建议书提出的价值观和原则。
33.    监管机构应在国家或超国家层面建立适当的数据保护框架和治理机制，这些框架和机制受到司法系统的保护，并在人工智能系统的整个生命周期内得到保障。此类保护框架和机制涉及数据的收集、控制和使用、数据主体行使权利以及个人要求删除个人数据的权利，确保个人数据的处理以及数据的个人化、去个人化和再个人化拥有合法的目的和有效的法律依据，并确保数据的透明度、对敏感数据的适当保护和有效的独立监督。
34.    需要对算法系统开展深入的隐私影响评估，其中包括使用算法系统的社会和伦理考量以及通过设计方法对于隐私的创新使用。
人类的监督和决定
35. 应始终可以将人工智能系统生命周期的任何阶段的伦理和法律责任赋予自然人或现有法人实体。因此，人类监督不仅指个人监督，在适当情况下也指公共监督。
36.    在某些情况下，出于效率性的考虑，人类有时不得不依赖人工智能系统，但依然要由人类来决定是否在有限情形下出让控制权，这是由于人类在决策和行动上可以借助人工智能系统，但人工智能系统永远无法取代人类的最终责任和问责。
透明度和可解释性
37.    人工智能系统的透明度往往是确保基本人权和伦理原则得到尊重、保护和促进的重要先决条件。透明度是切实落实相关国家和国际责任立法的必要因素。
38.    在人工智能系统的整个生命周期内都需要努力提高人工智能系统的透明度和可解释性，以支持民主治理，但透明度和可解释性的程度应始终切合具体情况，在透明度和可解释性与安全和安保等其他原则之间会存在某些权衡取舍。在根据人工智能算法作出决定时，人们有权知道，并且在这些情况下有权要求或请求私营公司或公共机构提供解释性信息。
39.    从社会—技术角度来看，提高透明度有助于建设更加和平、公正和包容的社会。提高透明度有利于开展公众监督，这可以减少腐败和歧视，还有助于发现和防止对人权产生的负面影响。透明度有助于人类信任人工智能系统。具体到人工智能系统，透明度可以帮助人们了解人工智能系统各个阶段是如何按照该系统的具体环境和敏感度设定的。透明度还包括深入了解可以影响特定预测或决定的因素，以及了解是否具备适当的保证（例如安全或公平措施）。在预计会对人权产生严重不利影响的情况下，透明度还可能要求共享特定代码或数据集。
40.    可解释性是指让人工智能系统的结果可以理解，并提供阐释说明。人工智能系统的可解释性也指各个算法模块的输入、输出和行为的可解释性及其如何促成系统结果。因此，可解释性与透明度密切相关，结果和导致结果的子过程应是可理解和可追溯的，并且应切合使用环境。
41.    透明度和可解释性与适当的责任和问责措施以及人工智能系统的可信度密切相关。
责任和问责
42.    在人工智能系统的整个生命周期内，人工智能行为者应根据现行国家法律和国际法，特别是国际人权法、原则和标准以及伦理准则，承担伦理和法律责任，尊重、保护和促进人权，并促进保护环境和生态系统。以任何方式基于人工智能系统作出的决定和行动，其伦理责任和义务最终都应由人工智能行为者承担。
43.    应建立适当的监督、影响评估和尽职调查机制，确保在人工智能系统的整个生命周期内对人工智能系统及其影响实施问责。技术和体制方面的设计都应确保人工智能系统（的运行）可审计和可追溯，特别是要应对与人权之间的冲突以及对环境和生态系统福祉的威胁。
认识和素养
44.    应通过政府、政府间组织、民间社会、学术界、媒体、社区领袖和私营部门共同领导的开放且可获取的教育、公民参与、数字技能和人工智能伦理问题培训、媒体和信息素养及培训，同时兼顾现有的语言、社会和文化多样性，促进公众对于人工智能技术和数据价值的认识和理解，确保公众的有效参与，让所有社会成员都能够就使用人工智能系统作出知情决定，避免受到不当影响。
45.    了解人工智能系统的影响，应包括了解人权、借助人权以及促进人权。这意味着在接触和理解人工智能系统之前，应首先了解人工智能对于人权和获取权利产生的影响。
多利益攸关方以及适应性治理和协作
46.    对于数据的使用应尊重国际法和主权。数据主权是指各国根据国际法，对于在境内生成或入境的数据进行监管，并采取措施，力争在尊重隐私权和其他人权的基础上对数据进行有效监管。
47.    多方利益攸关方参与人工智能系统的整个生命周期，是实现包容的人工智能治理、共享人工智能的惠益、公平的技术进步及其为发展目标所作贡献的必要因素。利益攸关方包括但不限于政府、政府间组织、技术界、民间社会、研究人员和学术界、媒体、教育、决策者、私营公司、人权机构和平等机构、反歧视监测机构以及儿童和青年团体。必须采用开放标准和互可操作性原则，以促进协作。必须采取措施，兼顾技术的变化和新利益攸关方群体的出现，便于边缘化群体、社区和个人进行实际干预。
IV.    政策行动领域
48.    以下政策领域所述的政策行动是对本建议书提出的价值观和原则的具体落实。主要行动是会员国建立政策框架或机制，并通过开展多种行动，例如协助所有利益攸关方制定伦理影响评估和尽职调查工具，确保私营公司、学术和研究机构以及民间社会等其他利益攸关方遵守这些框架或机制。此类政策或机制的制定过程应向所有利益攸关方开放，并应考虑到各会员国的具体情况和优先事项。教科文组织可以作为合作伙伴，支持会员国制定、监测和评估政策机制。
49.    教科文组织认识到，会员国在科学、技术、经济、教育、法律、规范、基础设施、社会、文化和其他方面，处于实施本建议书的不同准备阶段。需要指出的是，这里的“准备”是一种动态。因此，为切实落实本建议书，教科文组织将：(1) 制定准备状态评估方法，协助会员国确定其准备进程各个方面在特定时刻的所处状态；(2) 确保支持会员国制定全球公认的人工智能技术伦理影响评估（EIA）方法，分享最佳做法、评估准则、其他机制和分析工作。