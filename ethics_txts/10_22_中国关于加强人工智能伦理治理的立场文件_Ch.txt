中国关于加强人工智能伦理治理的立场文件
中国关于加强人工智能伦理治理的立场文件
（最近更新时间：2022年10月）
 
一、人工智能作为最具代表性的颠覆性技术，在给人类社会带来潜在巨大发展红利的同时，其不确定性可能带来许多全球性挑战，甚至引发根本性的伦理关切。在伦理层面，国际社会普遍担心如不加以规范，人工智能技术的误用滥用恐将损害人的尊严和平等、侵犯人权和基本自由、加剧歧视和偏见、冲击现有法律体系等，并对各国政府管理、国防建设、社会稳定其至全球治理产生深远影响。
中国始终致力于在人工智能领域构建人类命运共同体，积极倡导“以人为本”和“智能向善”理念，主张增进各国对人工智能伦理问题的理解，确保人工智能安全、可靠、可控，更好赋能全球可持续发展，增进全人类共同福祉。为实现这一目标，中国呼呼各方秉持共商共建共享理念，推动国际人工智能伦理治理。
二、2021年12月，中国发布《关于规范人工智能军事应用的立场文件》，呼吁各方遵守国家或地区人工智能伦理道德准则。中国现结合自身在科技伦理领域的政策实践，参考国际社会相关有益成果，从人工智能技术监管、研发、使用及国际合作等方面提出以下主张：
（一）监管
各国政府应坚持伦理先行，建立并完善人工智能伦理准则、规范及问责机制，明确人工智能相关主体的职责和权力边界，充分尊重并保障各群体合法权益，及时回应国内和国际相关伦理关切。
各国政府应重视人工智能伦理与法律的基础理论问题研究,逐步建立并完善人工智能伦理规范、法律法规和政策体系，形成人工智能伦理指南，建立科技伦理审查和监管制度，加强人工智能安全评估和管控能力。
各国政府应增强底线思维和风险意识，加强研判人工智能技术的潜在伦理风险，逐步建立有效的风险预警机制，采取敏捷治理，分类分级管理，不断提升风险管控和处置能力。
各国政府应立足自身人工智能发展阶段及社会文化特点，遵循科技创新规律，逐步建立符合自身国情的人工智能伦理体系，健全多方参与、协同共治的人工智能伦理治理体制机制。
（二）研发
各国政府应要求研发主体加强对人工智能研发活动的自我约束，主动将伦理道德融入人工智能研发过程各环节，避免使用可能产生严重消极后果的不成熟技术，确保人工智能始终处于人类控制之下。
各国政府应要求研发主体努力确保人工智能研发过程的算法安全可控，在算法设计、实现、应用等环节，不断提升透明性、可解释性、可靠性，逐步实现可审核、可监督、可追溯、可预测、可信赖。
各国政府应要求研发主体努力提升人工智能研发过程的数据质量，在数据收集、存储、使用等环节，严格遵守所在国的数据安全规定、伦理道德及相关法律标准，提升数据的完整性、及时性、一致性、规范性和准确性等。
各国政府应要求研发主体加强对数据采集和算法开发伦理审查，充分考虑差异化诉求，避免可能存在的数据采集与算法偏见,努力实现人工智能系统的普惠性、公平性和非歧视性。
（三）使用
各国政府应禁止使用违背法律法规、伦理道德和标准规范的人工智能技术及相关应用，强化对已使用的人工智能产品与服务的质量监测和使用评估，研究制定应急机制和损失补偿措施。
各国政府应加强人工智能产品与服务使用前的论证和评估，推动人工智能伦理培训机制化，相关人员应充分了解人工智能技术的功能、特点、局限、潜在风险及后果，并具备必要的专业素质与技能。
各国政府应保障人工智能产品与服务使用中的个人隐私与数据安全，严格遵循国际或区域性规范处理个人信息，完善个人数据授权撤销机制，反对非法收集利用个人信息。
各国政府应重视公众人工智能伦理教育，保障公众知情权与有效参与，发挥科技相关社会团体作用，引导社会各界自觉遵守人工智能伦理准则与规范，提高人工智能伦理意识。
（四）国际合作
各国政府应鼓励在人工智能领域开展跨国家、跨领域、跨文化交流与协作，确保各国共享人工智能技术惠益，推动各国共同参与国际人工智能伦理重大议题探讨和规则制定，反对构建排他性集团、恶意阻挠他国技术发展的行为。
各国政府应加强对人工智能领域国际合作研究活动的伦理监管，相关科技活动应符合各方所在国家的人工智能伦理管理要求，并通过相应的人工智能伦理审查。
中国呼吁国际社会在普遍参与的基础上就人工智能伦理问题达成国际协议，在充分尊重各国人工智能治理原则和实践的前提下，推动形成具有广泛共识的国际人工智能治理框架和标准规范。

